<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>A Notebook</title>
  <subtitle>Exploring with Curiosity!</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://xijunlee.github.io/"/>
  <updated>2017-06-25T15:29:35.000Z</updated>
  <id>https://xijunlee.github.io/</id>
  
  <author>
    <name>Xijun LI</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>机器学习中常见激活函数总结</title>
    <link href="https://xijunlee.github.io/2017/06/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E8%A7%81%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E6%80%BB%E7%BB%93/"/>
    <id>https://xijunlee.github.io/2017/06/25/机器学习中常见激活函数总结/</id>
    <published>2017-06-25T13:58:32.000Z</published>
    <updated>2017-06-25T15:29:35.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>机器学习中很多场合都用到了激活函数 (Activation Function)，但激活函数主要是在神经网络中提出来的，很多场合下其实就是函数。这篇总结一下常见的激活函数以及它们的优缺点。</p>
<h2 id="激活函数起源与性质"><a href="#激活函数起源与性质" class="headerlink" title="激活函数起源与性质"></a>激活函数起源与性质</h2><img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/ActivationFunction/pic0.png">
<a id="more"></a>
<p>一个人工神经元就是对生物神经元的数学建模。人工神经元就是用一个数学模型简单模拟神经细胞。神经细胞有多个树突和一个伸长的轴突。一个神经元的轴突连接到其他神经元的树突，并向其传导神经脉冲。神经元会根据来自它的若干树突的信号决定是否从其轴突向其他神经元发出神经脉冲。而激活函数就是这个神经元的数学模型，它决定是否将经过变换后的上一层输入信号传递给下一层神经元。激活函数的性质有：</p>
<ol>
<li>非线性： 当激活函数是线性的时候，一个两层的神经网络就可以逼近基本上所有的函数了。但是，如果激活函数是恒等激活函数的时候（即f(x)=x），就不满足这个性质了，而且如果MLP使用的是恒等激活函数，那么其实整个网络跟单层神经网络是等价的。</li>
<li>可微性： 当优化方法是基于梯度的时候，这个性质是必须的。</li>
<li>单调性： 当激活函数是单调的时候，单层网络能够保证是凸函数。f(x)≈x： 当激活函数满足这个性质的时候，如果参数的初始化是random的很小的值，那么神经网络的训练将会很高效；如果不满足这个性质，那么就需要很用心的去设置初始值。</li>
<li>输出值的范围： 当激活函数输出值是 有限 的时候，基于梯度的优化方法会更加稳定，因为特征的表示受有限权值的影响更显著；当激活函数的输出是 无限的时候，模型的训练会更加高效，不过在这种情况小，一般需要更小的learning rate.</li>
</ol>
<p>常见的激活函数总结如下图：<br><img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/ActivationFunction/pic1.png"></p>
<h2 id="Sigmoid系激活函数"><a href="#Sigmoid系激活函数" class="headerlink" title="Sigmoid系激活函数"></a>Sigmoid系激活函数</h2><p>Sigmoid系激活函数是一大类函数，其函数形状是S型的，因此而得名。代表有Sigmoid函数和tanh函数。</p>
<p>$$sigmoid: f(x)=\frac{1}{1+e^{-x}}$$<br>$$tanh: f(x)=\frac{2}{1+e^{-2x}}-1=2Sigmoid(2x)-1$$</p>
<p>Sigmoid系是之前使用的最多的激活函数，它在物理意义上最为接近生物神经元，能够把输入的连续实值“压缩”到[0,1]或者[-1,1]。此外，[0,1]的输出还可以被表示作概率，或用于输入的归一化，代表性的如Sigmoid交叉熵损失函数。此外，Sigmoid函数还被用在逻辑斯蒂回归中，在那里，它被叫做逻辑斯蒂函数 (Logistic Function)。所以我怎么老是看到这个函数的身影，原来它在不同场景中穿的马甲不同。既然提到了回归，那么就再提一下逻辑斯蒂回归的一般形式Softmax回归中的Softmax函数。逻辑斯蒂回归是种类数k=2时的Softmax回归,有关二者更多详情请戳<a href="http://www.cnblogs.com/maybe2030/p/5678387.html" target="_blank" rel="external">这里</a>和<a href="http://ufldl.stanford.edu/wiki/index.php/Softmax回归" target="_blank" rel="external">这里</a>。</p>
<p>回到Sigmoid系函数。近年来，用它的人越来越少了。主要是因为它的一些缺点：<br>1.饱和性：从sigmoid函数图像中可以看到，其两侧增长十分缓慢，即越靠近两侧导数趋近于0。那么这在神经网络中训练的会带来梯度弥散 (Gradient Disperse) 的问题，使得训练一个神经网络十分缓慢，或者根本无法收敛。具体来说，在训练神经网络的反向传播算法中，需要计算梯度$\nabla=\sigma’\delta x$。其中$\sigma’$是sigmoid函数的导数。每经过一个sigmoid神经元，梯度就要乘上一个$\sigma’$。从下图可以看到，sigmoid函数导数的最大值是0.25。那么连续的乘以sigmoid的导数，会导致梯度越来越小。一般来说， sigmoid 网络在5层之内就会产生梯度消失现象这就是梯度弥散问题。这对于深层网络的训练是很大的问题，因此在如今大火的DNN中，sigmoid遭到抛弃。<br>2.sigmoid函数的输出均大于0：这使得输出不是0均值，这称为偏移现象，这会导致后一层的神经元将得到上一层输出的非0均值的信号作为输入。（关于这一点，我不是很理解）</p>
<p>tanh也是一种非常常见的激活函数。与sigmoid相比，它的输出均值是0，使得其收敛速度要比sigmoid快，减少迭代次数。然而，从途中可以看出，tanh一样具有软饱和性，从而造成梯度弥散。</p>
<h2 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h2><p>最近几年卷积神经网络中，激活函数往往不选择sigmoid或tanh函数，而是选择relu函数。Relu函数的定义是：</p>
<p>$$ReLU: f(x)=\max(0,x)$$</p>
<p>Relu函数作为激活函数，有下面几大优势：</p>
<p>1.速度快：和sigmoid函数需要计算指数和倒数相比，relu函数其实就是一个max(0,x)，计算代价小很多。<br>2.减轻梯度消失问题：relu函数在大于零的一侧其导数大于零，不会导致梯度变小。当然，激活函数仅仅是导致梯度减小的一个因素，但无论如何在这方面relu的表现强于sigmoid。使用relu激活函数可以让你训练更深的网络。</p>
<p>然而，随着训练的推进，部分输入会落入x&lt;0的区域，其梯度等于0，导致对应权重无法更新。这种现象被称为“神经元死亡”。与sigmoid类似，ReLU的输出均值也大于0，偏移现象和 神经元死亡会共同影响网络的收敛性。对此，相应的改进有Leaky-ReLU，ELU，见<a href="http://blog.csdn.net/u014595019/article/details/52562159" target="_blank" rel="external">参考链接</a>。</p>
<h2 id="Maxout"><a href="#Maxout" class="headerlink" title="Maxout"></a>Maxout</h2><p>$$Maxout: f(x)=\max(w^T_1x+b_1,w^T_2x+b_2,⋯,w^T_2x+b_2)$$</p>
<p>Maxout出现在ICML2013上，作者Goodfellow将maxout和dropout结合后，号称在MNIST, CIFAR-10, CIFAR-100, SVHN这4个数据上都取得了start-of-art的识别率。可以注意到，ReLU 和 Leaky ReLU 都是它的一个变形。这个激活函数有点大一统的感觉，因为maxout网络能够近似任意连续函数，且当w2,b2,…,wn,bn为0时，退化为ReLU。Maxout能够缓解梯度弥散，同时又规避了ReLU神经元死亡的缺点，但增加了参数和计算量。</p>
<hr>
<p>Reference<br><a href="http://blog.csdn.net/cyh_24/article/details/50593400" target="_blank" rel="external">http://blog.csdn.net/cyh_24/article/details/50593400</a><br><a href="http://blog.csdn.net/u014595019/article/details/52562159" target="_blank" rel="external">http://blog.csdn.net/u014595019/article/details/52562159</a><br><a href="https://www.zybuluo.com/hanbingtao/note/485480" target="_blank" rel="external">https://www.zybuluo.com/hanbingtao/note/485480</a><br><a href="http://ufldl.stanford.edu/wiki/index.php/Softmax回归" target="_blank" rel="external">http://ufldl.stanford.edu/wiki/index.php/Softmax回归</a><br><a href="http://www.cnblogs.com/maybe2030/p/5678387.html" target="_blank" rel="external">http://www.cnblogs.com/maybe2030/p/5678387.html</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h2&gt;&lt;p&gt;机器学习中很多场合都用到了激活函数 (Activation Function)，但激活函数主要是在神经网络中提出来的，很多场合下其实就是函数。这篇总结一下常见的激活函数以及它们的优缺点。&lt;/p&gt;
&lt;h2 id=&quot;激活函数起源与性质&quot;&gt;&lt;a href=&quot;#激活函数起源与性质&quot; class=&quot;headerlink&quot; title=&quot;激活函数起源与性质&quot;&gt;&lt;/a&gt;激活函数起源与性质&lt;/h2&gt;&lt;img src=&quot;http://xijun-album.oss-cn-hangzhou.aliyuncs.com/ActivationFunction/pic0.png&quot;&gt;
    
    </summary>
    
    
      <category term="Activation Function" scheme="https://xijunlee.github.io/tags/Activation-Function/"/>
    
  </entry>
  
  <entry>
    <title>卷积神经网络实践之MNIST手写数字体识别</title>
    <link href="https://xijunlee.github.io/2017/06/23/CNN%E5%AE%9E%E8%B7%B5%E4%B9%8B%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E4%BD%93%E8%AF%86%E5%88%AB/"/>
    <id>https://xijunlee.github.io/2017/06/23/CNN实践之手写数字体识别/</id>
    <published>2017-06-23T07:46:26.000Z</published>
    <updated>2017-07-02T12:56:30.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>之前一直都是只看理论，没有动手，现在终于把理论付诸实践了。话不多说，这篇博文记录一下我在kaggle上实践过程。</p>
<h2 id="任务描述"><a href="#任务描述" class="headerlink" title="任务描述"></a>任务描述</h2><p>MNIST (“Modified National Institute of Standards and Technology”) is the de facto “hello world” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.</p>
<a id="more"></a>
<p>In this competition, your goal is to correctly identify digits from a dataset of tens of thousands of handwritten images. We’ve curated a set of tutorial-style kernels which cover everything from regression to neural networks. We encourage you to experiment with different algorithms to learn first-hand what works well and how techniques compare.</p>
<h2 id="解决思路"><a href="#解决思路" class="headerlink" title="解决思路"></a>解决思路</h2><p>其实这就是个多分类问题，所以常见的分类器都能解决上述问题。kaggle上的大神们也给出了卷积神经网络以外的思路：比如PCA+SVM。类似的还有很多，比如可以PCA+RandomForest, PCA+Xgboost, PCA+blahblahblah … </p>
<p>但最牛逼的解决方案还是CNN，我自己写了一个PCA+SVM的kernel，得分比CNN低很多。当然，如果做好feature engeering和好好调参的话，应该还是能取得不错的效果。但是肯定不如CNN厉害，不然现在CNN为什么会在图像识别领域大火呢？</p>
<h2 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h2><p>要我手写一个CNN是不可能的，既太花时间，我也暂时没那个本事。所以，我就用了Keras+ TensorFlow来实现一个卷积神经网络。</p>
<p>官网介绍：<a href="https://keras.io" target="_blank" rel="external">Keras</a> is a high-level neural networks API, written in Python and capable of running on top of either TensorFlow, CNTK or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.</p>
<p>官网介绍：<a href="https://www.tensorflow.org" target="_blank" rel="external">TensorFlow</a> is an open source software library for numerical computation using data flow graphs. Nodes in the graph represent mathematical operations, while the graph edges represent the multidimensional data arrays (tensors) that flow between them. This flexible architecture lets you deploy computation to one or more CPUs or GPUs in a desktop, server, or mobile device without rewriting code. TensorFlow also includes TensorBoard, a data visualization toolkit.</p>
<p>Keras是一个高层次抽象的卷积神经网络python库，但它本身是不会做矩阵计算等任务的，需要以TensorFlow作为后端来进行复杂的底层计算。在TensorFlow的基础上，Keras能非常方便地调用各种api来完成卷积神经网络的搭建。下面，简单地记录一下安装Kera+TensorFlow的过程。</p>
<h3 id="TensorFlow安装-on-Ubuntu-without-GPU-support"><a href="#TensorFlow安装-on-Ubuntu-without-GPU-support" class="headerlink" title="TensorFlow安装 (on Ubuntu without GPU support)"></a>TensorFlow安装 (on Ubuntu without GPU support)</h3><p>这里，我用的系统是Ubuntu 14.04.1 LTS (GNU/Linux 3.13.0-32-generic x86_64), python是3.4.3，GCC是4.8.4，所以下面的安装就是基于以上环境。建议采用pip的方式安装TensorFlow，下面keras也一样，简直是太方便了。因为实验室服务器没有GPU，所以我就只能安装CPU版本的TensorFlow了。</p>
<p>1.创建虚拟环境</p>
<p>为不同的项目创建独立的python虚拟环境是一个良好的习惯。利用不同的python虚拟环境来做不同的事，以免不同项目的环境相互影响了。以下两行代码分别是安装python 2.7和python 3.4+虚拟环境的命令，任君选择。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ sudo apt-get install python-pip python-dev python-virtualenv    <span class="comment"># python 2.7</span></div><div class="line">$ sudo apt-get install python3-pip python3-dev python3-virtualenv <span class="comment"># python 3.4+</span></div></pre></td></tr></table></figure></p>
<p>2.启动虚拟环境<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ virtualenv --system-site-packages ~/tensorflow</div><div class="line">$ <span class="built_in">source</span> ~/tensorflow/bin/activate</div></pre></td></tr></table></figure></p>
<p>3.安装TensorFlow<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Python 2</span></div><div class="line">$ sudo pip install --upgrade tensorflow</div><div class="line"> </div><div class="line"><span class="comment"># Python 3</span></div><div class="line">$ sudo pip3 install --upgrade tensorflow</div></pre></td></tr></table></figure></p>
<h3 id="Keras安装"><a href="#Keras安装" class="headerlink" title="Keras安装"></a>Keras安装</h3><p>1.安装所需要的包和keras</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ pip install numpy scipy</div><div class="line">$ pip install scikit-learn</div><div class="line">$ pip install pillow</div><div class="line">$ pip install h5py</div><div class="line">$ pip install keras</div></pre></td></tr></table></figure>
<p>2.编辑配置文件keras.json，将keras的计算后端设置为TensorFlow：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vim ~/.keras/keras.json</div></pre></td></tr></table></figure></p>
<p>确保上述文件内容为:<br><figure class="highlight json"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">    <span class="attr">"image_dim_ordering"</span>: <span class="string">"tf"</span>, </div><div class="line">    <span class="attr">"epsilon"</span>: <span class="number">1e-07</span>, </div><div class="line">    <span class="attr">"floatx"</span>: <span class="string">"float32"</span>, </div><div class="line">    <span class="attr">"backend"</span>: <span class="string">"tensorflow"</span></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>image_dim_ordering：TensorFlow是使用NumPy数组 (height, width, depth)。如果你用Theano，数组表示方法(depth, height, width)。</p>
<p>打开python，输入以下代码<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> Keras</div></pre></td></tr></table></figure></p>
<p>如果出现以下代码，表示基于TensorFlow的Keras安装成功！！<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> keras</div><div class="line">Using TensorFlow backend.</div></pre></td></tr></table></figure></p>
<h2 id="实现与结果"><a href="#实现与结果" class="headerlink" title="实现与结果"></a>实现与结果</h2><p>这里给出我利用keras实现的一个多层卷积神经网络，源码戳<a href="https://github.com/xijunlee/kaggle-solution/blob/master/DigitRecognizer/DigitRec_CNN.py" target="_blank" rel="external">这里</a>，该网络的结构如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line">_________________________________________________________________</div><div class="line">Layer (type)                 Output Shape              Param #</div><div class="line">=================================================================</div><div class="line">conv2d_1 (Conv2D)            (None, 28, 28, 32)        320</div><div class="line">_________________________________________________________________</div><div class="line">conv2d_2 (Conv2D)            (None, 28, 28, 32)        9248</div><div class="line">_________________________________________________________________</div><div class="line">max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0</div><div class="line">_________________________________________________________________</div><div class="line">conv2d_3 (Conv2D)            (None, 14, 14, 64)        18496</div><div class="line">_________________________________________________________________</div><div class="line">conv2d_4 (Conv2D)            (None, 14, 14, 64)        36928</div><div class="line">_________________________________________________________________</div><div class="line">max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0</div><div class="line">_________________________________________________________________</div><div class="line">conv2d_5 (Conv2D)            (None, 7, 7, 128)         73856</div><div class="line">_________________________________________________________________</div><div class="line">conv2d_6 (Conv2D)            (None, 7, 7, 128)         147584</div><div class="line">_________________________________________________________________</div><div class="line">conv2d_7 (Conv2D)            (None, 7, 7, 128)         147584</div><div class="line">_________________________________________________________________</div><div class="line">conv2d_8 (Conv2D)            (None, 7, 7, 128)         147584</div><div class="line">_________________________________________________________________</div><div class="line">max_pooling2d_3 (MaxPooling2 (None, 3, 3, 128)         0</div><div class="line">_________________________________________________________________</div><div class="line">conv2d_9 (Conv2D)            (None, 3, 3, 256)         295168</div><div class="line">_________________________________________________________________</div><div class="line">conv2d_10 (Conv2D)           (None, 3, 3, 256)         590080</div><div class="line">_________________________________________________________________</div><div class="line">conv2d_11 (Conv2D)           (None, 3, 3, 256)         590080</div><div class="line">_________________________________________________________________</div><div class="line">conv2d_12 (Conv2D)           (None, 3, 3, 256)         590080</div><div class="line">_________________________________________________________________</div><div class="line">max_pooling2d_4 (MaxPooling2 (None, 1, 1, 256)         0</div><div class="line">_________________________________________________________________</div><div class="line">flatten_1 (Flatten)          (None, 256)               0</div><div class="line">_________________________________________________________________</div><div class="line">dropout_1 (Dropout)          (None, 256)               0</div><div class="line">_________________________________________________________________</div><div class="line">dense_1 (Dense)              (None, 128)               32896</div><div class="line">_________________________________________________________________</div><div class="line">dense_2 (Dense)              (None, 10)                1290</div><div class="line">=================================================================</div><div class="line">Total params: 2,681,194</div><div class="line">Trainable params: 2,681,194</div><div class="line">Non-trainable params: 0</div></pre></td></tr></table></figure></p>
<p>我是故意把这个搞的比较复杂，最后kaggle上LB得分为0.98971, rank 652/1924，很多人做到了score为1的地步……</p>
<p>我前两个卷积层为例说明一下卷积神经网络中参数个数的理解。</p>
<p>首先，我的输入是一个28x28的灰度图，那么输入层是一个28x28x1的结构，那个1是该层的深度。</p>
<p>conv2d_1：第一个卷积层，总共设置了32个filters(滤波器，也叫卷积核，这家伙也是有多个马甲的)。卷积核大小设置为3x3。那么经过32个filter的卷积后，输入层的图像变成了32个28x28的卷积层。（注意filter的数量等于该层的深度）。那么输入层到第一层卷积层的参数数量是怎么计算的呢？因为每个卷积核有3x3个参数，然后每个卷积核还要带一个bias参数，所以一个卷积核有3x3x1+1=10个参数。conv2d_1总共有32个卷积核，并且每个卷积核的深度是1，所以总共有(3x3x1+1)x32=320个参数。这个1看起来乘地没必要，但是它代表了每个卷积核的深度。卷积核的深度与上一层的输出的深度相等。</p>
<p>con2d_2：第二个卷积层，同样设置了32个filters，卷积核大小同样设置为3x3。conv2d_1的输出是28x28x32的结构，即深度为32的28x28的图像。自然，con2d_2的filter的深度也为32。经过con2d_2的32个filter后，卷积得到依旧是28x28x32的输出。参数的数量怎么计算呢？对于con2d_2的一个卷积核来说，其深度是32，每一层的大小是3x3，再外加一个bias参数，那么一个卷积核的参数数量便是3x3x32+1=289个。然后总共有32个卷积核，所以总共的参数数量是(3x3x32+1)x32=9248。</p>
<p>可能con2d_2的参数数量说明的让人头晕，更详细和生动的说明可以参见<a href="https://www.zybuluo.com/hanbingtao/note/485480" target="_blank" rel="external">博文</a>，里面有动图说明了对于深度大于1的卷积核的卷积操作。</p>
<h3 id="关于引入冲量"><a href="#关于引入冲量" class="headerlink" title="关于引入冲量"></a>关于引入冲量</h3><p>本小节内容转载自 @辛淼 CaffeCN社区（caffecn.cn）</p>
<p>随机梯度下降（SGD）是按batch来进行更新，通常来说下降速度比较快，但却容易造成另一个问题，就是更新过程不稳定，容易出现震荡。</p>
<p>引入momentum的idea是很直接的，就是在更新下降方向的时候不仅要考虑到当前的方向，也要考虑到上一次的更新方向，两者加权，某些情况下可以避免震荡。冲量，就是上一次更新方向所占的权值。</p>
<p>一个小的trick是，当刚开始训练的时候，把冲量设小，或者直接就置为0，然后慢慢增大冲量，有时候效果比较好。</p>
<h3 id="PCA-SVM的实现"><a href="#PCA-SVM的实现" class="headerlink" title="PCA+SVM的实现"></a>PCA+SVM的实现</h3><p>之后，我又尝试了PCA+SVM的模型，源码戳<a href="https://github.com/xijunlee/kaggle-solution/blob/master/DigitRecognizer/DigitRec_SVM.py" target="_blank" rel="external">这里</a>。因为没有专门去调参数，所以LB得分很低，才0.49743…… 不过，我想就算找到了最优参数，其效果也应该比不上卷积神经网络。</p>
<hr>
<p>Reference<br><a href="https://www.kaggle.com/poonaml/deep-neural-network-keras-way" target="_blank" rel="external">https://www.kaggle.com/poonaml/deep-neural-network-keras-way</a><br><a href="http://blog.topspeedsnail.com/archives/10427" target="_blank" rel="external">http://blog.topspeedsnail.com/archives/10427</a><br><a href="https://keras.io" target="_blank" rel="external">https://keras.io</a><br><a href="https://www.kaggle.com/somshubramajumdar/deep-convolutional-network-using-keras" target="_blank" rel="external">https://www.kaggle.com/somshubramajumdar/deep-convolutional-network-using-keras</a><br><a href="https://www.zybuluo.com/hanbingtao/note/485480" target="_blank" rel="external">https://www.zybuluo.com/hanbingtao/note/485480</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h2&gt;&lt;p&gt;之前一直都是只看理论，没有动手，现在终于把理论付诸实践了。话不多说，这篇博文记录一下我在kaggle上实践过程。&lt;/p&gt;
&lt;h2 id=&quot;任务描述&quot;&gt;&lt;a href=&quot;#任务描述&quot; class=&quot;headerlink&quot; title=&quot;任务描述&quot;&gt;&lt;/a&gt;任务描述&lt;/h2&gt;&lt;p&gt;MNIST (“Modified National Institute of Standards and Technology”) is the de facto “hello world” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.&lt;/p&gt;
    
    </summary>
    
    
      <category term="CNN" scheme="https://xijunlee.github.io/tags/CNN/"/>
    
  </entry>
  
  <entry>
    <title>正则表达式总结</title>
    <link href="https://xijunlee.github.io/2017/06/20/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%80%BB%E7%BB%93/"/>
    <id>https://xijunlee.github.io/2017/06/20/正则表达式总结/</id>
    <published>2017-06-20T13:47:48.000Z</published>
    <updated>2017-06-20T14:10:29.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>正则表达式笔记，特指python中的re模块。</p>
<h2 id="正则表达式相关注解"><a href="#正则表达式相关注解" class="headerlink" title="正则表达式相关注解"></a>正则表达式相关注解</h2><p>（1）数量词的贪婪模式与非贪婪模式</p>
<p>正则表达式通常用于在文本中查找匹配的字符串。Python里数量词默认是贪婪的（在少数语言里也可能是默认非贪婪），总是尝试匹配尽可能多的字符；非贪婪的则相反，总是尝试匹配尽可能少的字符。例如：正则表达式”ab<em>”如果用于查找”abbbc”，将找到”abbb”。而如果使用非贪婪的数量词”ab</em>?”，将找到”a”。</p>
<p>注：我们一般使用非贪婪模式来提取。</p>
<a id="more"></a>
<p>（2）反斜杠问题</p>
<p>与大多数编程语言相同，正则表达式里使用”\”作为转义字符，这就可能造成反斜杠困扰。假如你需要匹配文本中的字符”\”，那么使用编程语言表示的正则表达式里将需要4个反斜杠”\\”：前两个和后两个分别用于在编程语言里转义成反斜杠，转换成两个反斜杠后再在正则表达式里转义成一个反斜杠。</p>
<p>Python里的原生字符串很好地解决了这个问题，这个例子中的正则表达式可以使用r”\”表示。同样，匹配一个数字的”\d”可以写成r”\d”。</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/re_summary/pic1.png">
<h2 id="Python-Re模块"><a href="#Python-Re模块" class="headerlink" title="Python Re模块"></a>Python Re模块</h2><p>Python 自带了re模块，它提供了对正则表达式的支持。主要用到的方法列举如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#返回pattern对象</span></div><div class="line">re.compile(string[,flag])  </div><div class="line"><span class="comment">#以下为匹配所用函数</span></div><div class="line">re.match(pattern, string[, flags])</div><div class="line">re.search(pattern, string[, flags])</div><div class="line">re.split(pattern, string[, maxsplit])</div><div class="line">re.findall(pattern, string[, flags])</div><div class="line">re.finditer(pattern, string[, flags])</div><div class="line">re.sub(pattern, repl, string[, count])</div><div class="line">re.subn(pattern, repl, string[, count])</div></pre></td></tr></table></figure>
<p>在介绍这几个方法之前，我们先来介绍一下pattern的概念，pattern可以理解为一个匹配模式，那么我们怎么获得这个匹配模式呢？很简单，我们需要利用re.compile方法就可以。例如</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pattern = re.compile(<span class="string">r'hello'</span>)</div></pre></td></tr></table></figure>
<p>在参数中我们传入了原生字符串对象，通过compile方法编译生成一个pattern对象，然后我们利用这个对象来进行进一步的匹配。</p>
<p>另外大家可能注意到了另一个参数 flags，在这里解释一下这个参数的含义：</p>
<p>参数flag是匹配模式，取值可以使用按位或运算符’|’表示同时生效，比如re.I | re.M。</p>
<p>可选值有：</p>
<p> • re.I(全拼：IGNORECASE): 忽略大小写（括号内是完整写法，下同）<br> • re.M(全拼：MULTILINE): 多行模式，改变’^’和’$’的行为（参见上图）<br> • re.S(全拼：DOTALL): 点任意匹配模式，改变’.’的行为<br> • re.L(全拼：LOCALE): 使预定字符类 \w \W \b \B \s \S 取决于当前区域设定<br> • re.U(全拼：UNICODE): 使预定字符类 \w \W \b \B \s \S \d \D 取决于unicode定义的字符属性<br> • re.X(全拼：VERBOSE): 详细模式。这个模式下正则表达式可以是多行，忽略空白字符，并可以加入注释。<br>在刚才所说的另外几个方法例如 re.match 里我们就需要用到这个pattern了，下面我们一一介绍。</p>
<p>注：以下七个方法中的flags同样是代表匹配模式的意思，如果在pattern生成时已经指明了flags，那么在下面的方法中就不需要传入这个参数了。<br>（1）re.match(pattern, string[, flags])</p>
<p>这个方法将会从string（我们要匹配的字符串）的开头开始，尝试匹配pattern，一直向后匹配，如果遇到无法匹配的字符，立即返回None，如果匹配未结束已经到达string的末尾，也会返回None。两个结果均表示匹配失败，否则匹配pattern成功，同时匹配终止，不再对string向后匹配。下面我们通过一个例子理解一下</p>
<p>我们还看到最后打印出了result.group()，这个是什么意思呢？下面我们说一下关于match对象的的属性和方法<br>Match对象是一次匹配的结果，包含了很多关于此次匹配的信息，可以使用Match提供的可读属性或方法来获取这些信息。</p>
<p>属性：<br>1.string: 匹配时使用的文本。<br>2.re: 匹配时使用的Pattern对象。<br>3.pos: 文本中正则表达式开始搜索的索引。值与Pattern.match()和Pattern.seach()方法的同名参数相同。<br>4.endpos: 文本中正则表达式结束搜索的索引。值与Pattern.match()和Pattern.seach()方法的同名参数相同。<br>5.lastindex: 最后一个被捕获的分组在文本中的索引。如果没有被捕获的分组，将为None。<br>6.lastgroup: 最后一个被捕获的分组的别名。如果这个分组没有别名或者没有被捕获的分组，将为None。<br>方法：<br>1.group([group1, …]):<br>获得一个或多个分组截获的字符串；指定多个参数时将以元组形式返回。group1可以使用编号也可以使用别名；编号0代表整个匹配的子串；不填写参数时，返回group(0)；没有截获字符串的组返回None；截获了多次的组返回最后一次截获的子串。<br>2.groups([default]):<br>以元组形式返回全部分组截获的字符串。相当于调用group(1,2,…last)。default表示没有截获字符串的组以这个值替代，默认为None。<br>3.groupdict([default]):<br>返回以有别名的组的别名为键、以该组截获的子串为值的字典，没有别名的组不包含在内。default含义同上。<br>4.start([group]):<br>返回指定的组截获的子串在string中的起始索引（子串第一个字符的索引）。group默认值为0。<br>5.end([group]):<br>返回指定的组截获的子串在string中的结束索引（子串最后一个字符的索引+1）。group默认值为0。<br>6.span([group]):<br>返回(start(group), end(group))。<br>7.expand(template):<br>将匹配到的分组代入template中然后返回。template中可以使用\id或\g、\g引用分组，但不能使用编号0。\id与\g是等价的；但\10将被认为是第10个分组，如果你想表达\1之后是字符’0’，只能使用\g0。</p>
<p>（2）re.search(pattern, string[, flags])</p>
<p>search方法与match方法极其类似，区别在于match()函数只检测re是不是在string的开始位置匹配，search()会扫描整个string查找匹配，match（）只有在0位置匹配成功的话才有返回，如果不是开始位置匹配成功的话，match()就返回None。同样，search方法的返回对象同样match()返回对象的方法和属性。</p>
<p>（3）re.split(pattern, string[, maxsplit])</p>
<p>按照能够匹配的子串将string分割后返回列表。maxsplit用于指定最大分割次数，不指定将全部分割。</p>
<p>（4）re.findall(pattern, string[, flags])</p>
<p>搜索string，以列表形式返回全部能匹配的子串。<br>（5）re.finditer(pattern, string[, flags])</p>
<p>搜索string，返回一个顺序访问每一个匹配结果（Match对象）的迭代器。</p>
<p>（6）re.sub(pattern, repl, string[, count])</p>
<p>使用repl替换string中每一个匹配的子串后返回替换后的字符串。<br>当repl是一个字符串时，可以使用\id或\g、\g引用分组，但不能使用编号0。<br>当repl是一个方法时，这个方法应当只接受一个参数（Match对象），并返回一个字符串用于替换（返回的字符串中不能再引用分组）。<br>count用于指定最多替换次数，不指定时全部替换。</p>
<h2 id="Python-Re模块的另一种使用方式"><a href="#Python-Re模块的另一种使用方式" class="headerlink" title="Python Re模块的另一种使用方式"></a>Python Re模块的另一种使用方式</h2><p>在上面我们介绍了7个工具方法，例如match，search等等，不过调用方式都是 re.match，re.search的方式，其实还有另外一种调用方式，可以通过pattern.match，pattern.search调用，这样调用便不用将pattern作为第一个参数传入了，大家想怎样调用皆可。</p>
<p>函数API列表<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">match(string[, pos[, endpos]]) | re.match(pattern, string[, flags])</div><div class="line">search(string[, pos[, endpos]]) | re.search(pattern, string[, flags])</div><div class="line">split(string[, maxsplit]) | re.split(pattern, string[, maxsplit])</div><div class="line">findall(string[, pos[, endpos]]) | re.findall(pattern, string[, flags])</div><div class="line">finditer(string[, pos[, endpos]]) | re.finditer(pattern, string[, flags])</div><div class="line">sub(repl, string[, count]) | re.sub(pattern, repl, string[, count])</div><div class="line">subn(repl, string[, count]) |re.sub(pattern, repl, string[, count])</div></pre></td></tr></table></figure></p>
<hr>
<p>Reference:</p>
<p><a href="http://cuiqingcai.com/977.html" target="_blank" rel="external">http://cuiqingcai.com/977.html</a><br><a href="http://www.cnblogs.com/huxi/archive/2010/07/04/1771073.html" target="_blank" rel="external">http://www.cnblogs.com/huxi/archive/2010/07/04/1771073.html</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h2&gt;&lt;p&gt;正则表达式笔记，特指python中的re模块。&lt;/p&gt;
&lt;h2 id=&quot;正则表达式相关注解&quot;&gt;&lt;a href=&quot;#正则表达式相关注解&quot; class=&quot;headerlink&quot; title=&quot;正则表达式相关注解&quot;&gt;&lt;/a&gt;正则表达式相关注解&lt;/h2&gt;&lt;p&gt;（1）数量词的贪婪模式与非贪婪模式&lt;/p&gt;
&lt;p&gt;正则表达式通常用于在文本中查找匹配的字符串。Python里数量词默认是贪婪的（在少数语言里也可能是默认非贪婪），总是尝试匹配尽可能多的字符；非贪婪的则相反，总是尝试匹配尽可能少的字符。例如：正则表达式”ab&lt;em&gt;”如果用于查找”abbbc”，将找到”abbb”。而如果使用非贪婪的数量词”ab&lt;/em&gt;?”，将找到”a”。&lt;/p&gt;
&lt;p&gt;注：我们一般使用非贪婪模式来提取。&lt;/p&gt;
    
    </summary>
    
    
      <category term="RE" scheme="https://xijunlee.github.io/tags/RE/"/>
    
  </entry>
  
  <entry>
    <title>自然语言处理基础</title>
    <link href="https://xijunlee.github.io/2017/06/06/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%9F%BA%E7%A1%80/"/>
    <id>https://xijunlee.github.io/2017/06/06/自然语言处理基础/</id>
    <published>2017-06-06T03:01:32.000Z</published>
    <updated>2017-06-06T07:26:18.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>自然语言处理中基本和经典模型的总结</p>
<h2 id="TF-IDF"><a href="#TF-IDF" class="headerlink" title="TF-IDF"></a>TF-IDF</h2><p>对于一篇文档，TF-IDF（词频-逆文档频率）能为其中的词赋予权重，它度量的是词语与文本的相关性，而非简单的词频。因此TF-IDF能用来<strong>判断文章主题</strong>。对于一个文本而言，想要知道其主题或是想知道这篇文档是关于哪个方面的，那么最容易想到的方法就是提取关键字了。TF-IDF可以认为是分为两步来做这个事情：</p>
<a id="more"></a>
<p>（1）最基本的思路是提取该文本中出现次数最多的词。结果你肯定猜到了，出现次数最多的词是–”的”、”是”、”在”–这一类最常用的词。它们叫做”停用词” (stop words) ，这些词出现的次数最多，但是并不能体现文本的主题，那么这些词就要去掉，而要去找那些“真正”的主题词。对于一个词语i，统计其在文档j中出现的次数，记为tf_(i,j)，这就是词频 (TF, Term Frequency) 的统计了。</p>
<p>（2）在统计了文档中各个词的词频后，我们需要调整那些“停用词”的频率，来挑选出“真正”的关键词。对于一个拥有N个文本的语料库，统计词语i在语料库中包含词语i的文本数，记为df_i，那么idf_i=log(N/df_i)，注意到对数中是文本总数除以包含词语i的文本数。如果一个词在很多文本中都有出现，即df趋近于N，那么其idf就趋近于0。如果一个词只在很少文档中出现，即其df趋近于0，那么其idf就趋于无穷大。</p>
<p>（3）将词频tf_(i,j)乘以idf_i记得到词语i与文本j的相关性,即</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/NLP_foundation/p1.png">
<p>TF-IDF算法的优点是简单快速，结果比较符合实际情况。缺点是，单纯以”词频”衡量一个词的重要性，不够全面，有时重要的词可能出现次数并不多。而且，这种算法无法体现词的位置信息，出现位置靠前的词与出现位置靠后的词，都被视为重要性相同，这是不正确的。（一种解决方法是，对全文的第一段和每一段的第一句话，给予较大的权重。</p>
<hr>
<p>下面再给出一个<a href="http://www.ruanyifeng.com/blog/2013/03/tf-idf.html" target="_blank" rel="external">阮一峰</a>博客中的例子。</p>
<p>让我们从一个实例开始讲起。假定现在有一篇长文《中国的蜜蜂养殖》，我们准备用计算机提取它的关键词。</p>
<p>一个容易想到的思路，就是找到出现次数最多的词。如果某个词很重要，它应该在这篇文章中多次出现。于是，我们进行”词频”（Term Frequency，缩写为TF）统计。<br>结果你肯定猜到了，出现次数最多的词是—-“的”、”是”、”在”—-这一类最常用的词。它们叫做”停用词”（stop words），表示对找到结果毫无帮助、必须过滤掉的词。</p>
<p>假设我们把它们都过滤掉了，只考虑剩下的有实际意义的词。这样又会遇到了另一个问题，我们可能发现”中国”、”蜜蜂”、”养殖”这三个词的出现次数一样多。这是不是意味着，作为关键词，它们的重要性是一样的？</p>
<p>显然不是这样。因为”中国”是很常见的词，相对而言，”蜜蜂”和”养殖”不那么常见。如果这三个词在一篇文章的出现次数一样多，有理由认为，”蜜蜂”和”养殖”的重要程度要大于”中国”，也就是说，在关键词排序上面，”蜜蜂”和”养殖”应该排在”中国”的前面。</p>
<p>所以，我们需要一个重要性调整系数，衡量一个词是不是常见词。如果某个词比较少见，但是它在这篇文章中多次出现，那么它很可能就反映了这篇文章的特性，正是我们所需要的关键词。</p>
<p>用统计学语言表达，就是在词频的基础上，要对每个词分配一个”重要性”权重。最常见的词（”的”、”是”、”在”）给予最小的权重，较常见的词（”中国”）给予较小的权重，较少见的词（”蜜蜂”、”养殖”）给予较大的权重。这个权重叫做”逆文档频率”（Inverse Document Frequency，缩写为IDF），它的大小与一个词的常见程度成反比。</p>
<p>知道了”词频”（TF）和”逆文档频率”（IDF）以后，将这两个值相乘，就得到了一个词的TF-IDF值。某个词对文章的重要性越高，它的TF-IDF值就越大。所以，排在最前面的几个词，就是这篇文章的关键词。</p>
<p>下面就是这个算法的细节。</p>
<p>第一步，计算词频。</p>
<p>考虑到文章有长短之分，为了便于不同文章的比较，进行”词频”标准化。</p>
<p>第二步，计算逆文档频率。<br>这时，需要一个语料库（corpus），用来模拟语言的使用环境。</p>
<p>如果一个词越常见，那么分母就越大，逆文档频率就越小越接近0。分母之所以要加1，是为了避免分母为0（即所有文档都不包含该词）。log表示对得到的值取对数。<br>第三步，计算TF-IDF。</p>
<p>可以看到，TF-IDF与一个词在文档中的出现次数成正比，与该词在整个语言中的出现次数成反比。所以，自动提取关键词的算法就很清楚了，就是计算出文档的每个词的TF-IDF值，然后按降序排列，取排在最前面的几个词。</p>
<p>还是以《中国的蜜蜂养殖》为例，假定该文长度为1000个词，”中国”、”蜜蜂”、”养殖”各出现20次，则这三个词的”词频”（TF）都为0.02。然后，搜索Google发现，包含”的”字的网页共有250亿张，假定这就是中文网页总数。包含”中国”的网页共有62.3亿张，包含”蜜蜂”的网页为0.484亿张，包含”养殖”的网页为0.973亿张。则它们的逆文档频率（IDF）和TF-IDF如下：</p>
<p>从上表可见，”蜜蜂”的TF-IDF值最高，”养殖”其次，”中国”最低。（如果还计算”的”字的TF-IDF，那将是一个极其接近0的值。）所以，如果只选择一个词，”蜜蜂”就是这篇文章的关键词。</p>
<p>除了自动提取关键词，TF-IDF算法还可以用于许多别的地方。比如，信息检索时，对于每个文档，都可以分别计算一组搜索词（”中国”、”蜜蜂”、”养殖”）的TF-IDF，将它们相加，就可以得到整个文档的TF-IDF。这个值最高的文档就是与搜索词最相关的文档。</p>
<p>下面，再再给出一个利用TFIDF度量两个文本相似度的<a href="http://www.ruanyifeng.com/blog/2013/03/cosine_similarity.html" target="_blank" rel="external">方法</a>：</p>
<p>（1）使用TF-IDF算法，找出两篇文章的关键词；<br>（2）每篇文章各取出若干个关键词（比如20个），合并成一个集合，计算每篇文章对于这个集合中的词的词频（为了避免文章长度的差异，可以使用相对词频）；<br>（3）生成两篇文章各自的词频向量；<br>（4）计算两个向量的余弦相似度，值越大就表示越相似。</p>
<h2 id="词袋模型-Bag-of-Words"><a href="#词袋模型-Bag-of-Words" class="headerlink" title="词袋模型 (Bag of Words)"></a>词袋模型 (Bag of Words)</h2><p>词袋 (Bag of Words，简称BoW) 是一种统计某个词在一份文档中出现次数的算法。统计所得的词频数据可以用于比较文档并测量其相似性，具体应用包括搜索、文档分类、主题建模等。词袋法是为深度学习网络准备文本输入的方法。</p>
<p>词袋法会列出每个词及其在每份文档中出现的次数。实质上已经向量化的词和文档被存储到表格中，表格的每一行对应一个词，每一列对应一份文档，而每个单元格则是一项词频数。语料库中的每份文档都以长度相等的列来表示。这也就是<strong>词频向量</strong>，一种脱离了上下文的输出。</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/NLP_foundation/p2.png">
<p>通常在应用之前，每个词频向量都需要进行标准化，确保向量的所有元素之和为1。如此就相当于将每个词的频率转换为该词在文档中出现的概率。</p>
<h2 id="Word2vec"><a href="#Word2vec" class="headerlink" title="Word2vec"></a>Word2vec</h2><p>NLP（Natural Language Processing）问题要转化为机器学习的问题，首先就要把单词数学化表示,就是用n维实数向量来代表一个单词，常见的词向量有以下两种：</p>
<h3 id="One-hot-Representation"><a href="#One-hot-Representation" class="headerlink" title="One-hot Representation"></a>One-hot Representation</h3><p>例如： </p>
<p>“话筒”表示为 [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 …]</p>
<p>“麦克”表示为 [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 …]</p>
<p>One-hot表示使用了单词在词表中的编号信息，编码方式如下：向量长度为词表大小，单词在词表中的编号对应的那一个维度为1，其余为0。</p>
<p>One-hot表示存在两个问题：</p>
<p>（1）维度比较大,尤其在用于神经网络的一些算法时，出现“维数灾难”。</p>
<p>（2）词汇鸿沟：任意两个词之间都是孤立的，不能体现词和词之间的关系（因为编码过程仅仅使用了它们在词表中的编号信息）。</p>
<h3 id="Distributional-Representation"><a href="#Distributional-Representation" class="headerlink" title="Distributional Representation"></a>Distributional Representation</h3><p>例如： [0.792, −0.177, −0.107, 0.109, 0.542, …]，每个维度用一个实数值表示</p>
<p>克服了One-hot表示存在的两个问题：</p>
<p>（1）解决了维度大的问题：常见维度50或者100。</p>
<p>（2）解决了“词汇鸿沟”问题：可以通过计算向量之间的距离（欧式距离、余弦距离等）来体现词与词的相似性。</p>
<p>这样的词向量称为词嵌入（word-embedding），那么如何训练这样的词向量呢？我们可以通过训练语言模型的同时，得到词向量。</p>
<hr>
<p>Reference:</p>
<p><a href="http://www.ruanyifeng.com/blog/2013/03/tf-idf.html" target="_blank" rel="external">http://www.ruanyifeng.com/blog/2013/03/tf-idf.html</a><br><a href="http://www.ruanyifeng.com/blog/2013/03/cosine_similarity.html" target="_blank" rel="external">http://www.ruanyifeng.com/blog/2013/03/cosine_similarity.html</a><br><a href="https://deeplearning4j.org/cn/bagofwords-tf-idf" target="_blank" rel="external">https://deeplearning4j.org/cn/bagofwords-tf-idf</a><br><a href="http://www.nustm.cn/blog/index.php/archives/842" target="_blank" rel="external">http://www.nustm.cn/blog/index.php/archives/842</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h2&gt;&lt;p&gt;自然语言处理中基本和经典模型的总结&lt;/p&gt;
&lt;h2 id=&quot;TF-IDF&quot;&gt;&lt;a href=&quot;#TF-IDF&quot; class=&quot;headerlink&quot; title=&quot;TF-IDF&quot;&gt;&lt;/a&gt;TF-IDF&lt;/h2&gt;&lt;p&gt;对于一篇文档，TF-IDF（词频-逆文档频率）能为其中的词赋予权重，它度量的是词语与文本的相关性，而非简单的词频。因此TF-IDF能用来&lt;strong&gt;判断文章主题&lt;/strong&gt;。对于一个文本而言，想要知道其主题或是想知道这篇文档是关于哪个方面的，那么最容易想到的方法就是提取关键字了。TF-IDF可以认为是分为两步来做这个事情：&lt;/p&gt;
    
    </summary>
    
    
      <category term="NLP" scheme="https://xijunlee.github.io/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>集成学习总结</title>
    <link href="https://xijunlee.github.io/2017/06/03/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    <id>https://xijunlee.github.io/2017/06/03/集成学习总结/</id>
    <published>2017-06-03T08:18:51.000Z</published>
    <updated>2017-06-24T14:57:50.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>看了不少集成学习的资料，很多算法都有相似之处，看了之后没有进行比较和整理，太容易忘记了，所以这篇来做个笔记。</p>
<p>集成学习，（就我目前所学习到的）主要可以分为三大类，Boosting, Bagging, Stacking。Boosting的代表有AdaBoost, gbdt, xgboost。而Bagging的代表则是随机森林 (Random Forest)。Stacking 的话，好像还没有著名的代表，可以视其为一种集成的套路。</p>
<a id="more"></a>
<h2 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h2><p>首先，Boosting是一个迭代提升的过程，所以它肯定是串行的算法（尽管xgboost可以在节点分裂属性选择上做并行计算）。基于训练集，先训练弱学习器，然后根据前一个弱学习器分错的样本，改变样本的概率分布构成新的训练集，从而可以训练出一个更强的学习器。这样反复迭代提升，就能得到一系列分类器。最后，将这些分类器组合起来，就能构成一个很强的学习器。</p>
<h3 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h3><p>给定一个二分类的训练数据集</p>
<p>T={(x1,y1),…,(xN,yN)}</p>
<p>其中,x_i 是n维的, 类标y_i={-1,+1}</p>
<p>AdaBoost算法的步骤：<br>(1) 初始化训练数据的权值分布：D1=(w11,…,wi1,…,w1N),w1i=1/N,i=1,2,…,N(即初始时，每个样本视为一样的)<br>(2) 对m=1,2,…,M<br>(2a) 对具有权值分布Dm的训练数据集学习，得到一个基本分类器Gm(x)<br>(2b) 计算Gm(x)在训练数据集上的分类错误率:em=P(Gm(xi)!=yi)<br>(2c) 根据分类错误率计算Gm(x)的加权系数：am<br>(2d) 根据加权系数更新训练数据集的权值分布Dm+1<br>(3)以上学到了M个“弱”学习器，将这M个弱学习器加权求和：f(x)=sum(am*Gm(x)),最终的分类器为G(x)=sign(f(x))</p>
<p>总之，AdaBoost的主要思想就是在不改变训练数据的情况下，通过在迭代训练弱学习器中，不断提升被错分类样本的权重（也就是使被错分的样本在下一轮训练时得到更多的重视），不断减少正确分类样本的权重。最后通过加权线性组合M个弱分类器得到最终的分类器，正确率越高的弱分类器的投票权数越高，正确率低的弱分类器自然投票权数就低。</p>
<h3 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h3><p>GBDT的基本原理是boosting里面的 boosting tree（提升树），并使用gradient boost。GBDT中的树都是<strong>回归树</strong>，不是<strong>分类树</strong> ，因为<strong>gradient boost</strong> 需要按照<strong>损失函数</strong>的梯度近似的拟合残差，这样拟合的是连续数值，因此只有回归树。Gradient Boosting是一种Boosting的方法，其与传统的Boosting的区别是，每一次的计算是为了减少上一次的残差(residual)，而为了消除残差，可以在残差减少的梯度(Gradient)方向上建立一个新的模型。所以说，在Gradient Boosting中，每个新的模型的建立是为了使得之前模型的残差往梯度方向减少，与传统Boosting对正确、错误样本进行加权有着很大的区别。这个梯度代表上一轮学习器损失函数对预测值求导。与Boosting Tree的区别：Boosting Tree的适合于损失函数为<strong>平方损失</strong>或者<strong>指数损失</strong>。而Gradient Boosting适合<strong>各类损失函数</strong>（损失函数为：平方损失则相当于Boosting Tree拟合残差、损失函数为：使用指数损失则可以近似于Adaboost，但树是回归树）</p>
<p>下面是完整的GBDT介绍。</p>
<p>GBDT(Gradient Boosting Decision Tree) 又叫 MART（Multiple Additive Regression Tree)，是一种迭代的决策树算法，该算法由多棵决策树组成，所有树的结论累加起来做最终答案。它在被提出之初就和SVM一起被认为是泛化能力较强的算法。GBDT中的树是回归树（不是分类树），GBDT用来做回归预测，调整后也可以用于分类。GBDT的思想使其具有天然优势可以发现多种有区分性的特征以及特征组合。</p>
<h4 id="Regression-Decision-Tree：回归树"><a href="#Regression-Decision-Tree：回归树" class="headerlink" title="Regression Decision Tree：回归树"></a>Regression Decision Tree：回归树</h4><p>  回归树总体流程类似于分类树，区别在于，回归树的每一个节点都会得一个预测值，以年龄为例，该预测值等于属于这个节点的所有人年龄的平均值。分枝时穷举每一个feature的每个阈值找最好的分割点，但衡量最好的标准不再是最大熵，而是最小化平方误差。也就是被预测出错的人数越多，错的越离谱，平方误差就越大，通过最小化平方误差能够找到最可靠的分枝依据。分枝直到每个叶子节点上人的年龄都唯一或者达到预设的终止条件(如叶子个数上限)，若最终叶子节点上人的年龄不唯一，则以该节点上所有人的平均年龄做为该叶子节点的预测年龄。</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/Ensembling/p1.png">
<p>回归树算法如下图（截图来自《统计学习方法》5.5.1 CART生成）：</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/Ensembling/p2.png">
<p>请注意上图中的下标和上标,$x_i$表示第i个样本，$x^{(j)}$表示该样本的第j个feature。所以上图中的遍历划分变量j的意思是遍历feature和相应的s，找出使平方误差和最小的(j,s)。</p>
<h4 id="Boosting-Decision-Tree：提升树算法"><a href="#Boosting-Decision-Tree：提升树算法" class="headerlink" title="Boosting Decision Tree：提升树算法"></a>Boosting Decision Tree：提升树算法</h4><p>  提升树是迭代多棵回归树来共同决策。当采用平方误差损失函数时，每一棵回归树学习的是之前所有树的结论和残差，拟合得到一个当前的残差回归树，残差的意义如公式：残差 = 真实值 - 预测值 。提升树即是整个迭代过程生成的回归树的累加。<br>  举个例子，参考自一篇博客（参考文献 4），该博客举出的例子较直观地展现出多棵决策树线性求和过程以及残差的意义。<br>  训练一个提升树模型来预测年龄：<br>  训练集是4个人，A，B，C，D年龄分别是14，16，24，26。样本中有购物金额、上网时长、经常到百度知道提问等特征。提升树的过程如下：</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/Ensembling/p3.jpg">
<p>该例子很直观的能看到，预测值等于所有树值得累加，如A的预测值 = 树1左节点 值 15 + 树2左节点 -1 = 14。<br>  因此，给定当前模型 fm-1(x)，只需要简单的拟合当前模型的残差。现将回归问题的提升树算法叙述如下：</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/Ensembling/p4.png">
<h4 id="Gradient-Boosting-Decision-Tree：梯度提升决策树"><a href="#Gradient-Boosting-Decision-Tree：梯度提升决策树" class="headerlink" title="Gradient Boosting Decision Tree：梯度提升决策树"></a>Gradient Boosting Decision Tree：梯度提升决策树</h4><p>  提升树利用加法模型和前向分步算法实现学习的优化过程。当损失函数是平方损失和指数损失函数时，每一步的优化很简单，如平方损失函数学习残差回归树。</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/Ensembling/p5.png">
<p>但对于一般的损失函数，往往每一步优化没那么容易，如上图中的绝对值损失函数和Huber损失函数。针对这一问题，Freidman提出了梯度提升算法：利用最速下降的近似方法，即利用损失函数的负梯度在当前模型的值，作为回归问题中提升树算法的残差的近似值，拟合一个回归树。（注：鄙人私以为，与其说负梯度作为残差的近似值，不如说残差是负梯度的一种特例）算法如下（截图来自《The Elements of Statistical Learning》）：</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/Ensembling/p6.png">
<h2 id="xgboost"><a href="#xgboost" class="headerlink" title="xgboost"></a>xgboost</h2><p>xgboost类似于gbdt，但是很多地方经过了Tianqi Chen大牛的优化，因此不论是精度还是效率上都有了提升。与gbdt相比，具体的优点有：</p>
<p>1.损失函数是用泰勒展式二项逼近，而不是像gbdt里就是一阶导数<br>2.对树的结构进行了正则化约束，防止模型过度复杂，降低了过拟合的可能性<br>3.节点分裂的方式不同，gbdt是用的gini系数，xgboost是经过优化推导后的</p>
<p>xgboost是GB算法的高效实现，xgboost中的基学习器除了可以是CART（gbtree）也可以是线性分类器（gblinear）。下面所有的内容来自原始paper，包括公式。</p>
<p>(1) xgboost在目标函数中显示的加上了正则化项，基学习器为CART时，正则化项与树的叶子节点的数量T和叶子节点的值有关。</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/Ensembling/p7.png">
<p>(2) GB中使用Loss Function对f(x)的一阶导数计算出伪残差用于学习生成fm(x)，xgboost不仅使用到了一阶导数，还使用二阶导数。第t次的loss：</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/Ensembling/p8.png">
<p>对上式做二阶泰勒展开：</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/Ensembling/p9.png">
<p>(3) 上面提到CART回归树中寻找最佳分割点的衡量标准是<strong>最小化均方差</strong>，xgboost寻找分割点的标准是最大化Lsplit</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/Ensembling/p10.png">
<p>xgboost算法的步骤和GB基本相同，都是首先初始化为一个常数，gb是根据一阶导数ri，xgboost是根据一阶导数gi和二阶导数hi，迭代生成基学习器，相加更新学习器。</p>
<p>xgboost与gdbt除了上述三点的不同，xgboost在实现时还做了许多优化：</p>
<ol>
<li>在寻找最佳分割点时，考虑传统的<strong>枚举每个特征的所有可能分割点的贪心法效率太低</strong>，xgboost实现了一种近似的算法。大致的思想是根据<strong>百分位</strong>法列举几个可能成为分割点的候选者，然后从候选者中根据上面求分割点的公式计算找出最佳的分割点。</li>
<li>xgboost考虑了训练数据为稀疏值的情况，可以为缺失值或者指定的值指定分支的默认方向，这能大大提升算法的效率，paper提到50倍。</li>
<li>xgboost借鉴了随机森林中的列（特征）采样技术，即在某个节点分裂时，不是在当前节点中所有属性中选取最佳分裂属性，而是在当前属性集合中的某些属性中来选择最优分裂属性。这种方法降低了过拟合的可能性。</li>
<li><p>特征列排序后以块的形式存储在内存中，在迭代中可以<strong>重复使用</strong>；虽然boosting算法迭代<strong>必须串行</strong>，但是在<strong>处理每个特征列</strong>时可以做到并行。</p>
</li>
<li><p>按照特征列方式存储能优化寻找最佳的分割点，但是当以行计算梯度数据时会导致内存的不连续访问，严重时会导致cache miss，降低算法效率。paper中提到，可先将数据收集到线程内部的buffer，然后再计算，提高算法的效率。</p>
</li>
<li>xgboost还考虑了当数据量比较大，内存不够时怎么有效的使用磁盘，主要是结合多线程、数据压缩、分片的方法，尽可能的提高算法的效率。</li>
</ol>
<h3 id="知乎上关于xgboost-gbdt讨论的经典问答"><a href="#知乎上关于xgboost-gbdt讨论的经典问答" class="headerlink" title="知乎上关于xgboost/gbdt讨论的经典问答"></a>知乎上关于xgboost/gbdt讨论的经典问答</h3><p>【问】xgboost/gbdt在调参时为什么树的深度很少就能达到很高的精度？<br>  用xgboost/gbdt在在调参的时候把树的最大深度调成6就有很高的精度了。但是用DecisionTree/RandomForest的时候需要把树的深度调到15或更高。用RandomForest所需要的树的深度和DecisionTree一样我能理解，因为它是用bagging的方法把DecisionTree组合在一起，相当于做了多次DecisionTree一样。但是xgboost/gbdt仅仅用梯度上升法就能用6个节点的深度达到很高的预测精度，使我惊讶到怀疑它是黑科技了。请问下xgboost/gbdt是怎么做到的？它的节点和一般的DecisionTree不同吗？<br>【答】<br>  这是一个非常好的问题，题主对各算法的学习非常细致透彻，问的问题也关系到这两个算法的本质。这个问题其实并不是一个很简单的问题，我尝试用我浅薄的机器学习知识对这个问题进行回答。<br>  一句话的解释，来自周志华老师的机器学习教科书（ 机器学习-周志华）：Boosting主要关注降低偏差，因此Boosting能基于泛化性能相当弱的学习器构建出很强的集成；Bagging主要关注降低方差，因此它在不剪枝的决策树、神经网络等学习器上效用更为明显。<br>  随机森林(random forest)和GBDT都是属于集成学习（ensemble learning)的范畴。集成学习下有两个重要的策略Bagging和Boosting。<br>  Bagging算法是这样做的：每个分类器都随机从原样本中做有放回的采样，然后分别在这些采样后的样本上训练分类器，然后再把这些分类器组合起来。简单的多数投票一般就可以。其代表算法是随机森林。Boosting的意思是这样，他通过迭代地训练一系列的分类器，每个分类器采用的样本分布都和上一轮的学习结果有关。其代表算法是AdaBoost, GBDT。<br>  其实就机器学习算法来说，其泛化误差可以分解为两部分，偏差（bias)和方差(variance)。这个可由下图的式子导出（这里用到了概率论公式D(X)=E(X^2)-[E(X)]^2）。偏差指的是算法的期望预测与真实预测之间的偏差程度，反应了模型本身的拟合能力；方差度量了同等大小的训练集的变动导致学习性能的变化，刻画了数据扰动所导致的影响。这个有点儿绕，不过你一定知道过拟合。<br>  如下图所示，当模型越复杂时，拟合的程度就越高，模型的训练偏差就越小。但此时如果换一组数据可能模型的变化就会很大，即模型的方差很大。所以模型过于复杂的时候会导致过拟合。</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/Ensembling/p11.png">
<p>  当模型越简单时，即使我们再换一组数据，最后得出的学习器和之前的学习器的差别就不那么大，模型的方差很小。还是因为模型简单，所以偏差会很大。</p>
<p>  也就是说，当我们训练一个模型时，偏差和方差都得照顾到，漏掉一个都不行。<br>  对于Bagging算法来说，由于我们会并行地训练很多不同的分类器的目的就是降低这个方差(variance) ,因为采用了相互独立的基分类器多了以后，h的值自然就会靠近.所以对于每个基分类器来说，目标就是如何降低这个偏差（bias),所以我们会采用深度很深甚至不剪枝的决策树。<br>  对于Boosting来说，每一步我们都会在上一轮的基础上更加拟合原数据，所以可以保证偏差（bias）,所以对于每个基分类器来说，问题就在于如何选择variance更小的分类器，即更简单的分类器，所以我们选择了深度很浅的决策树。</p>
<p>【问】机器学习算法中GBDT和XGBOOST的区别有哪些？<br>【答】<br>传统GBDT以CART作为基分类器，xgboost还支持线性分类器，这个时候xgboost相当于带L1和L2正则化项的逻辑斯蒂回归（分类问题）或者线性回归（回归问题）。</p>
<p>传统GBDT在优化时只用到一阶导数信息，xgboost则对代价函数进行了二阶泰勒展开，同时用到了一阶和二阶导数。顺便提一下，xgboost工具支持自定义代价函数，只要函数可一阶和二阶求导。</p>
<p>xgboost在代价函数里加入了正则项，用于控制模型的复杂度。正则项里包含了树的叶子节点个数、每个叶子节点上输出的score的L2模的平方和。从Bias-variance tradeoff角度来讲，正则项降低了模型的variance，使学习出来的模型更加简单，防止过拟合，这也是xgboost优于传统GBDT的一个特性。</p>
<p>Shrinkage（缩减），相当于学习速率（xgboost中的eta）。xgboost在进行完一次迭代后，会将叶子节点的权重乘上该系数，主要是为了削弱每棵树的影响，让后面有更大的学习空间。实际应用中，一般把eta设置得小一点，然后迭代次数设置得大一点。（补充：传统GBDT的实现也有学习速率）</p>
<p>列抽样（column subsampling）即特征抽样。xgboost借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算，这也是xgboost异于传统gbdt的一个特性。</p>
<p>对缺失值的处理。对于特征的值有缺失的样本，xgboost可以自动学习出它的分裂方向。</p>
<p>xgboost工具支持并行。boosting不是一种串行的结构吗?怎么并行的？注意xgboost的并行不是tree粒度的并行，xgboost也是一次迭代完才能进行下一次迭代的（第t次迭代的代价函数里包含了前面t-1次迭代的预测值）。xgboost的并行是在特征粒度上的。我们知道，决策树的学习最耗时的一个步骤就是对特征的值进行排序（因为要确定最佳分割点），xgboost在训练之前，预先对数据进行了排序，然后保存为block结构，后面的迭代中重复地使用这个结构，大大减小计算量。这个block结构也使得并行成为了可能，在进行节点的分裂时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以开多线程进行。<br>可并行的近似直方图算法。树节点在进行分裂时，我们需要计算每个特征的每个分割点对应的增益，即用贪心法枚举所有可能的分割点。当数据无法一次载入内存或者在分布式情况下，贪心算法效率就会变得很低，所以xgboost还提出了一种可并行的近似直方图算法，用于高效地生成候选的分割点。</p>
<p>多种语言封装支持。</p>
<p>【问】为什么基于 tree-ensemble 的机器学习方法，在实际的 kaggle 比赛中效果非常好？<br>【答】<br>作者：马超<br>链接：<a href="https://www.zhihu.com/question/51818176/answer/127637712" target="_blank" rel="external">https://www.zhihu.com/question/51818176/answer/127637712</a><br>来源：知乎<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
<p>通常，解释一个机器学习模型的表现是一件很复杂事情，而这篇文章尽可能用最直观的方式来解释这一问题。我主要从三个方面来回答楼主这个问题。</p>
<ol>
<li>理论模型 （站在 vc-dimension 的角度）</li>
<li>实际数据</li>
<li>系统的实现 （主要基于 xgboost）<br>通常决定一个机器学习模型能不能取得好的效果，以上三个方面的因素缺一不可。</li>
</ol>
<p>（1）站在理论模型的角度统计机器学习里经典的 vc-dimension 理论告诉我们：一个机器学习模型想要取得好的效果，这个模型需要满足以下两个条件：</p>
<ol>
<li>模型在我们的训练数据上的表现要不错，也就是 trainning error 要足够小。</li>
<li>模型的 vc-dimension 要低。换句话说，就是模型的自由度不能太大，以防overfit.当然，这是我用大白话描述出来的，真正的 vc-dimension 理论需要经过复杂的数学推导，推出 vc-bound. vc-dimension 理论其实是从另一个角度刻画了一个我们所熟知的概念，那就是 bias variance trade-off.</li>
</ol>
<p>好，现在开始让我们想象一个机器学习任务。对于这个任务，一定会有一个 “上帝函数” 可以完美的拟合所有数据（包括训练数据，以及未知的测试数据）。很可惜，这个函数我们肯定是不知道的 （不然就不需要机器学习了）。我们只可能选择一个 “假想函数” 来 逼近 这个 “上帝函数”，我们通常把这个 “假想函数” 叫做 hypothesis.</p>
<p>在这些 hypothesis 里，我们可以选择 svm, 也可以选择 logistic regression. 可以选择单棵决策树，也可以选择 tree-ensemble (gbdt, random forest).  现在的问题就是，为什么 tree-ensemble 在实际中的效果很好呢？</p>
<p>区别就在于 “模型的可控性”。</p>
<p>先说结论，tree-ensemble 这样的模型的可控性是好的，而像 LR  这样的模型的可控性是不够好的（或者说，可控性是没有 tree-ensemble 好的）。为什么会这样？别急，听我慢慢道来。</p>
<p>我们之前说，当我们选择一个 hypothsis 后，就需要在训练数据上进行训练，从而逼近我们的 “上帝函数”。我们都知道，对于 LR 这样的模型。如果 underfit，我们可以通过加 feature，或者通过高次的特征转换来使得我们的模型在训练数据上取得足够高的正确率。而对于 tree-enseble 来说，我们解决这一问题的方法是通过训练更多的 “弱弱” 的 tree.  所以，这两类模型都可以把 training error 做的足够低，也就是说模型的表达能力都是足够的。但是这样就完事了吗？没有，我们还需要让我们的模型的 vc-dimension 低一些。而这里，重点来了。在 tree-ensemble 模型中，通过加 tree 的方式，对于模型的 vc-dimension 的改变是比较小的。而在 LR 中，初始的维数设定，或者说特征的高次转换对于 vc-dimension 的影响都是更大的。换句话说，tree-ensemble 总是用一些 “弱弱” 的树联合起来去逼近 “上帝函数”，一次一小步，总能拟合的比较好。而对于 LR 这样的模型，我们很难去猜到这个“上帝函数”到底长什么样子（到底是2次函数还是3次函数？上帝函数如果是介于2次和3次之间怎么办呢？）。所以，一不小心我们设定的多项式维数高了，模型就 “刹不住车了”。俗话说的好，步子大了，总会扯着蛋。这也就是我们之前说的，tree-ensemble 模型的可控性更好，也即更不容易 overfit.</p>
<p>（2）站在数据的角度</p>
<p>除了理论模型之外, 实际的数据也对我们的算法最终能取得好的效果息息相关。kaggle 比赛选择的都是真实世界中的问题。所以数据多多少少都是有噪音的。而基于树的算法通常抗噪能力更强。比如在树模型中，我们很容易对缺失值进行处理。除此之外，基于树的模型对于 categorical feature 也更加友好。</p>
<p>除了数据噪音之外，feature 的多样性也是 tree-ensemble 模型能够取得更好效果的原因之一。通常在一个kaggle任务中，我们可能有年龄特征，收入特征，性别特征等等从不同 channel 获得的特征。而特征的多样性也正是为什么工业界很少去使用 svm 的一个重要原因之一，因为 svm 本质上是属于一个几何模型，这个模型需要去定义 instance 之间的 kernel 或者 similarity （对于linear svm 来说，这个similarity 就是内积）。这其实和我们在之前说过的问题是相似的，我们无法预先设定一个很好的similarity。这样的数学模型使得 svm 更适合去处理 “同性质”的特征，例如图像特征提取中的 lbp 。而从不同 channel 中来的 feature 则更适合 tree-based model, 这些模型对数据的 distributation 通常并不敏感。</p>
<p>（3）站在系统实现的角度</p>
<p>除了有合适的模型和数据，一个良好的机器学习系统实现往往也是算法最终能否取得好的效果的关键。一个好的机器学习系统实现应该具备以下特征：</p>
<ol>
<li>正确高效的实现某种模型。我真的见过有些机器学习的库实现某种算法是错误的。而高效的实现意味着可以快速验证不同的模型和参数。</li>
<li>系统具有灵活、深度的定制功能。</li>
<li>系统简单易用。</li>
<li>系统具有可扩展性, 可以从容处理更大的数据。</li>
</ol>
<p>到目前为止，xgboost 是我发现的唯一一个能够很好的满足上述所有要求的 machine learning package. 在此感谢青年才俊 陈天奇。</p>
<p>在效率方面，xgboost 高效的 c++ 实现能够通常能够比其它机器学习库更快的完成训练任务。</p>
<p>在灵活性方面，xgboost 可以深度定制每一个子分类器，并且可以灵活的选择 loss function（logistic，linear，softmax 等等）。除此之外，xgboost还提供了一系列在机器学习比赛中十分有用的功能，例如 early-stop， cv 等等在易用性方面，xgboost 提供了各种语言的封装，使得不同语言的用户都可以使用这个优秀的系统。</p>
<p>最后，在可扩展性方面，xgboost 提供了分布式训练（底层采用 rabit 接口），并且其分布式版本可以跑在各种平台之上，例如 mpi, yarn, spark 等等。</p>
<p>有了这么多优秀的特性，自然这个系统会吸引更多的人去使用它来参加 kaggle 比赛。</p>
<p>综上所述，理论模型，实际的数据，良好的系统实现，都是使得 tree-ensemble 在实际的 kaggle 比赛中“屡战屡胜”的原因。</p>
<h2 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h2><p>Bagging的代表算法是随机森林，简单说下随机森林的步骤：</p>
<p>(1) 对训练样本进行bootstrap采样，即有放回的采样，获得M个采样集合；<br>(2) 在这M个采样集合上训练处M个弱决策树。注意到，在决策树生成中还用到了列采样的技巧，原本决策树中节点分裂时，是选择当前节点中所有属性的最优属性进行划分的，但是列采样的技巧是在所有属性中的子集中选最优属性进行划分。这样做可以进一步降低过拟合的可能性；<br>(3) 对这M个训练出来的弱决策树进行集成。</p>
<h2 id="Stacking"><a href="#Stacking" class="headerlink" title="Stacking"></a>Stacking</h2><p>Stacking还没有代表性的算法，我姑且把它理解成一个集成的思想吧。具体做法是：</p>
<p>(1) 先将训练集D拆成k个大小相似但互不相交的子集D1,D2,…,Dk；<br>(2) 令Dj’= D - Dj，在Dj’上训练一个弱学习器Lj。将Dj作为测试集，获得Lj在Dj上的输出Dj’’；<br>(3) 步骤2可以得到k个弱学习器以及k个相应的输出Dj’’,这个k个输出加上原本的类标构成新的训练集Dn；<br>(4) 在Dn训练次学习器L，L即为最后的学习器。</p>
<p>以上Stacking只做了一层，据kaggle上的大神反馈，Stacking可以做好多层，会有神奇的效果。</p>
<p>下面给出kaggle中一个Stacking的实例，就是入门级的titanic那道题单层stacking的源码（只给出了stacking 的过程，前面特征工程处理的代码被省略掉了）。Stacking后的xgboost（得分:0.77990)比我之前只用xgboost时(得分:0.77512)提高了一点，排名上升了396……</p>
<p>Log on 2017-6-22: Stacking了两次之后，得分从单次stacking的0.77990上升到了0.79904</p>
<p>Log on 2017-6-22: Stacking了三次之后，得分从两次stacking的0.77990降低到了0.78469。所以，Stacking并不是越多层越好，反而会变坏。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Load in our libraries</span></div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> re</div><div class="line"><span class="keyword">import</span> sklearn</div><div class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</div><div class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> pdb</div><div class="line"><span class="comment">#%matplotlib inline</span></div><div class="line"></div><div class="line"><span class="comment"># Going to use these 5 base models for the stacking</span></div><div class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier</div><div class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</div><div class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> KFold;</div><div class="line"></div><div class="line"><span class="comment">#The code of feature engineering are emitted due to the space limitation.</span></div><div class="line"></div><div class="line"><span class="comment"># Some useful parameters which will come in handy later on</span></div><div class="line">ntrain = train.shape[<span class="number">0</span>]</div><div class="line">ntest = test.shape[<span class="number">0</span>]</div><div class="line">SEED = <span class="number">0</span> <span class="comment"># for reproducibility</span></div><div class="line">NFOLDS = <span class="number">5</span> <span class="comment"># set folds for out-of-fold prediction</span></div><div class="line">kf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)</div><div class="line"></div><div class="line"><span class="comment"># Class to extend the Sklearn classifier</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">SklearnHelper</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, clf, seed=<span class="number">0</span>, params=None)</span>:</span></div><div class="line">        params[<span class="string">'random_state'</span>] = seed</div><div class="line">        self.clf = clf(**params)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, x_train, y_train)</span>:</span></div><div class="line">        self.clf.fit(x_train, y_train)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, x)</span>:</span></div><div class="line">        <span class="keyword">return</span> self.clf.predict(x)</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self,x,y)</span>:</span></div><div class="line">        <span class="keyword">return</span> self.clf.fit(x,y)</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">feature_importances</span><span class="params">(self,x,y)</span>:</span></div><div class="line">        print(self.clf.fit(x,y).feature_importances_)</div><div class="line">    </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_oof</span><span class="params">(clf, x_train, y_train, x_test)</span>:</span></div><div class="line">    oof_train = np.zeros((ntrain,))</div><div class="line">    oof_test = np.zeros((ntest,))</div><div class="line">    oof_test_skf = np.empty((NFOLDS, ntest))</div><div class="line">    <span class="comment">#pdb.set_trace()</span></div><div class="line">    <span class="keyword">for</span> i, (train_index, test_index) <span class="keyword">in</span> enumerate(kf):</div><div class="line">        x_tr = x_train[train_index]</div><div class="line">        y_tr = y_train[train_index]</div><div class="line">        x_te = x_train[test_index]</div><div class="line"></div><div class="line">        clf.train(x_tr, y_tr)</div><div class="line"></div><div class="line">        oof_train[test_index] = clf.predict(x_te)</div><div class="line">        oof_test_skf[i, :] = clf.predict(x_test)</div><div class="line"></div><div class="line">    oof_test[:] = oof_test_skf.mean(axis=<span class="number">0</span>)</div><div class="line">    <span class="keyword">return</span> oof_train.reshape(<span class="number">-1</span>, <span class="number">1</span>), oof_test.reshape(<span class="number">-1</span>, <span class="number">1</span>)</div><div class="line"></div><div class="line"><span class="comment"># Put in our parameters for said classifiers</span></div><div class="line"><span class="comment"># Random Forest parameters</span></div><div class="line">rf_params = &#123;</div><div class="line">    <span class="string">'n_jobs'</span>: <span class="number">-1</span>,</div><div class="line">    <span class="string">'n_estimators'</span>: <span class="number">500</span>,</div><div class="line">     <span class="string">'warm_start'</span>: <span class="keyword">True</span>, </div><div class="line">     <span class="comment">#'max_features': 0.2,</span></div><div class="line">    <span class="string">'max_depth'</span>: <span class="number">6</span>,</div><div class="line">    <span class="string">'min_samples_leaf'</span>: <span class="number">2</span>,</div><div class="line">    <span class="string">'max_features'</span> : <span class="string">'sqrt'</span>,</div><div class="line">    <span class="string">'verbose'</span>: <span class="number">0</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment"># Extra Trees Parameters</span></div><div class="line">et_params = &#123;</div><div class="line">    <span class="string">'n_jobs'</span>: <span class="number">-1</span>,</div><div class="line">    <span class="string">'n_estimators'</span>:<span class="number">500</span>,</div><div class="line">    <span class="comment">#'max_features': 0.5,</span></div><div class="line">    <span class="string">'max_depth'</span>: <span class="number">8</span>,</div><div class="line">    <span class="string">'min_samples_leaf'</span>: <span class="number">2</span>,</div><div class="line">    <span class="string">'verbose'</span>: <span class="number">0</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment"># AdaBoost parameters</span></div><div class="line">ada_params = &#123;</div><div class="line">    <span class="string">'n_estimators'</span>: <span class="number">500</span>,</div><div class="line">    <span class="string">'learning_rate'</span> : <span class="number">0.75</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment"># Gradient Boosting parameters</span></div><div class="line">gb_params = &#123;</div><div class="line">    <span class="string">'n_estimators'</span>: <span class="number">500</span>,</div><div class="line">     <span class="comment">#'max_features': 0.2,</span></div><div class="line">    <span class="string">'max_depth'</span>: <span class="number">5</span>,</div><div class="line">    <span class="string">'min_samples_leaf'</span>: <span class="number">2</span>,</div><div class="line">    <span class="string">'verbose'</span>: <span class="number">0</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment"># Support Vector Classifier parameters </span></div><div class="line">svc_params = &#123;</div><div class="line">    <span class="string">'kernel'</span> : <span class="string">'linear'</span>,</div><div class="line">    <span class="string">'C'</span> : <span class="number">0.025</span></div><div class="line">    &#125;</div><div class="line"></div><div class="line"><span class="comment"># Create 5 objects that represent our 4 models</span></div><div class="line">rf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)</div><div class="line">et = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)</div><div class="line">ada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)</div><div class="line">gb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)</div><div class="line">svc = SklearnHelper(clf=SVC, seed=SEED, params=svc_params)</div><div class="line"></div><div class="line"><span class="comment"># Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models</span></div><div class="line">y_train = train[<span class="string">'Survived'</span>].ravel()</div><div class="line">train = train.drop([<span class="string">'Survived'</span>], axis=<span class="number">1</span>)</div><div class="line">x_train = train.values <span class="comment"># Creates an array of the train data</span></div><div class="line">x_test = test.values <span class="comment"># Creats an array of the test data</span></div><div class="line"></div><div class="line"><span class="comment"># Create our OOF train and test predictions. These base results will be used as new features</span></div><div class="line">et_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) <span class="comment"># Extra Trees</span></div><div class="line">rf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) <span class="comment"># Random Forest</span></div><div class="line">ada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) <span class="comment"># AdaBoost </span></div><div class="line">gb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) <span class="comment"># Gradient Boost</span></div><div class="line">svc_oof_train, svc_oof_test = get_oof(svc,x_train, y_train, x_test) <span class="comment"># Support Vector Classifier</span></div><div class="line"><span class="comment">#pdb.set_trace()</span></div><div class="line">print(<span class="string">"Training is complete"</span>)</div><div class="line"></div><div class="line">x_train = np.concatenate(( et_oof_train, rf_oof_train, ada_oof_train, gb_oof_train, svc_oof_train), axis=<span class="number">1</span>)</div><div class="line">x_test = np.concatenate(( et_oof_test, rf_oof_test, ada_oof_test, gb_oof_test, svc_oof_test), axis=<span class="number">1</span>)</div><div class="line"></div><div class="line"><span class="comment"># The second level xgboost classifer</span></div><div class="line"></div><div class="line">gbm = xgb.XGBClassifier(</div><div class="line">    <span class="comment">#learning_rate = 0.02,</span></div><div class="line"> n_estimators= <span class="number">2000</span>,</div><div class="line"> max_depth= <span class="number">4</span>,</div><div class="line"> min_child_weight= <span class="number">2</span>,</div><div class="line"> <span class="comment">#gamma=1,</span></div><div class="line"> gamma=<span class="number">0.9</span>,                        </div><div class="line"> subsample=<span class="number">0.8</span>,</div><div class="line"> colsample_bytree=<span class="number">0.8</span>,</div><div class="line"> objective= <span class="string">'binary:logistic'</span>,</div><div class="line"> nthread= <span class="number">-1</span>,</div><div class="line"> scale_pos_weight=<span class="number">1</span>).fit(x_train, y_train)</div><div class="line">predictions = gbm.predict(x_test)</div></pre></td></tr></table></figure>
<hr>
<p>Reference:</p>
<p>《The Elements of Statistical Learning》<br>《统计学习方法》<br>《Practical Lessons from Predicting Clicks on Ads at Facebook》<br><a href="http://blog.csdn.net/puqutogether/article/details/44593647" target="_blank" rel="external">http://blog.csdn.net/puqutogether/article/details/44593647</a><br><a href="http://blog.csdn.net/suranxu007/article/details/49910323" target="_blank" rel="external">http://blog.csdn.net/suranxu007/article/details/49910323</a><br><a href="http://blog.csdn.net/lilyth_lilyth/article/details/48032119" target="_blank" rel="external">http://blog.csdn.net/lilyth_lilyth/article/details/48032119</a><br><a href="http://www.searchtb.com/2010/12/an-introduction-to-treelink.html" target="_blank" rel="external">http://www.searchtb.com/2010/12/an-introduction-to-treelink.html</a><br><a href="https://www.zhihu.com/question/45487317" target="_blank" rel="external">https://www.zhihu.com/question/45487317</a><br><a href="http://wakemeup.space/?p=187" target="_blank" rel="external">http://wakemeup.space/?p=187</a><br><a href="http://www.jianshu.com/p/005a4e6ac775" target="_blank" rel="external">http://www.jianshu.com/p/005a4e6ac775</a><br><a href="https://www.zhihu.com/question/41354392/answer/98658997" target="_blank" rel="external">https://www.zhihu.com/question/41354392/answer/98658997</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h2&gt;&lt;p&gt;看了不少集成学习的资料，很多算法都有相似之处，看了之后没有进行比较和整理，太容易忘记了，所以这篇来做个笔记。&lt;/p&gt;
&lt;p&gt;集成学习，（就我目前所学习到的）主要可以分为三大类，Boosting, Bagging, Stacking。Boosting的代表有AdaBoost, gbdt, xgboost。而Bagging的代表则是随机森林 (Random Forest)。Stacking 的话，好像还没有著名的代表，可以视其为一种集成的套路。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Ensembling" scheme="https://xijunlee.github.io/tags/Ensembling/"/>
    
  </entry>
  
  <entry>
    <title>关于Python语法的一些笔记（持续更新）</title>
    <link href="https://xijunlee.github.io/2017/04/16/%E5%85%B3%E4%BA%8EPython%E8%AF%AD%E6%B3%95%E7%9A%84%E4%B8%80%E4%BA%9B%E7%AC%94%E8%AE%B0/"/>
    <id>https://xijunlee.github.io/2017/04/16/关于Python语法的一些笔记/</id>
    <published>2017-04-16T12:56:37.000Z</published>
    <updated>2017-06-21T08:54:14.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>记录一些Python使用过程中的没见过或者优化的使用方法……</p>
<h3 id="什么是args和-kwargs？"><a href="#什么是args和-kwargs？" class="headerlink" title="什么是args和*kwargs？"></a>什么是<strong>args和*</strong>kwargs？</h3><p>先来看个例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">foo</span><span class="params">(*args, **kwargs)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'args = '</span>, args</div><div class="line">    <span class="keyword">print</span> <span class="string">'kwargs = '</span>, kwargs</div><div class="line">    <span class="keyword">print</span> <span class="string">'---------------------------------------'</span></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    foo(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</div><div class="line">    foo(a=<span class="number">1</span>,b=<span class="number">2</span>,c=<span class="number">3</span>)</div><div class="line">    foo(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>, a=<span class="number">1</span>,b=<span class="number">2</span>,c=<span class="number">3</span>)</div><div class="line">    foo(<span class="string">'a'</span>, <span class="number">1</span>, <span class="keyword">None</span>, a=<span class="number">1</span>, b=<span class="string">'2'</span>, c=<span class="number">3</span>)</div></pre></td></tr></table></figure>
<a id="more"></a>
<p>输出结果如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">args =  (<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>) </div><div class="line">kwargs =  &#123;&#125; </div><div class="line">--------------------------------------- </div><div class="line">args =  () </div><div class="line">kwargs =  &#123;<span class="string">'a'</span>: <span class="number">1</span>, <span class="string">'c'</span>: <span class="number">3</span>, <span class="string">'b'</span>: <span class="number">2</span>&#125; </div><div class="line">--------------------------------------- </div><div class="line">args =  (<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>) </div><div class="line">kwargs =  &#123;<span class="string">'a'</span>: <span class="number">1</span>, <span class="string">'c'</span>: <span class="number">3</span>, <span class="string">'b'</span>: <span class="number">2</span>&#125; </div><div class="line">--------------------------------------- </div><div class="line">args =  (<span class="string">'a'</span>, <span class="number">1</span>, <span class="keyword">None</span>) </div><div class="line">kwargs =  &#123;<span class="string">'a'</span>: <span class="number">1</span>, <span class="string">'c'</span>: <span class="number">3</span>, <span class="string">'b'</span>: <span class="string">'2'</span>&#125; </div><div class="line">---------------------------------------</div></pre></td></tr></table></figure></p>
<p>可以看到，这两个是python中的可变参数。<em>args表示任何多个无名参数，它是一个tuple；**kwargs表示关键字参数，它是一个dict。并且同时使用</em>args和<strong>kwargs时，必须*args参数列要在</strong>kwargs前，像foo(a=1, b=’2’, c=3, a’, 1, None, )这样调用的话，会提示语法错误“SyntaxError: non-keyword arg after keyword arg”。</p>
<p> 还有一个很漂亮的用法，就是创建字典：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">kw_dict</span><span class="params">(**kwargs)</span>:</span></div><div class="line">    <span class="keyword">return</span> kwargs</div><div class="line"><span class="keyword">print</span> kw_dict(a=<span class="number">1</span>,b=<span class="number">2</span>,c=<span class="number">3</span>) == &#123;<span class="string">'a'</span>:<span class="number">1</span>, <span class="string">'b'</span>:<span class="number">2</span>, <span class="string">'c'</span>:<span class="number">3</span>&#125;</div></pre></td></tr></table></figure></p>
<p>其实python中就带有dict类，使用dict(a=1,b=2,c=3)即可创建一个字典了。</p>
<h3 id="lambda表达式以及实例"><a href="#lambda表达式以及实例" class="headerlink" title="lambda表达式以及实例"></a>lambda表达式以及实例</h3><p>lambda表达式可以理解成为匿名函数，其功能就是定义了一个函数，不过这个函数形式非常简单，通常是一行。过于复杂的函数还是正经定义的好。</p>
<h4 id="sorted函数中使用lambda表达式的例子："><a href="#sorted函数中使用lambda表达式的例子：" class="headerlink" title="sorted函数中使用lambda表达式的例子："></a>sorted函数中使用lambda表达式的例子：</h4><p>下面这个例子在很多list排序中使用到，故单独列出来。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">points = [[<span class="number">10</span>,<span class="number">16</span>], [<span class="number">2</span>,<span class="number">8</span>], [<span class="number">1</span>,<span class="number">6</span>], [<span class="number">7</span>,<span class="number">12</span>]]</div><div class="line"><span class="comment">#用sorted函数来为list中的元素按照元素的第二位进行排序，key是排序的比较关键字，这里通过lambda表达式来给出关键字。</span></div><div class="line">points = sorted(points, key = <span class="keyword">lambda</span> x: x[<span class="number">1</span>])</div></pre></td></tr></table></figure>
<h4 id="简单例子"><a href="#简单例子" class="headerlink" title="简单例子:"></a>简单例子:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">g = <span class="keyword">lambda</span> x:x+<span class="number">1</span></div></pre></td></tr></table></figure>
<p>执行结果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">g(<span class="number">1</span>)</div><div class="line">&gt;&gt;&gt;<span class="number">2</span></div><div class="line">g(<span class="number">2</span>)</div><div class="line">&gt;&gt;&gt;<span class="number">3</span></div></pre></td></tr></table></figure></p>
<p>另外一种使用方式:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">lambda</span> x:x+<span class="number">1</span>(<span class="number">1</span>)</div><div class="line">&gt;&gt;&gt;<span class="number">2</span></div></pre></td></tr></table></figure></p>
<p>可以这样认为,lambda作为一个表达式，定义了一个匿名函数，上例的代码x为入口参数，x+1为函数体。非常容易理解，在这里lambda简化了函数定义的书写形式。使得代码更为简洁，但是使用函数的定义方式更为直观，易理解。</p>
<p>Python中，也有几个定义好的全局函数方便使用的，filter, map, reduce：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>foo = [<span class="number">2</span>, <span class="number">18</span>, <span class="number">9</span>, <span class="number">22</span>, <span class="number">17</span>, <span class="number">24</span>, <span class="number">8</span>, <span class="number">12</span>, <span class="number">27</span>]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">print</span> filter(<span class="keyword">lambda</span> x: x % <span class="number">3</span> == <span class="number">0</span>, foo)</div><div class="line">[<span class="number">18</span>, <span class="number">9</span>, <span class="number">24</span>, <span class="number">12</span>, <span class="number">27</span>]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">print</span> map(<span class="keyword">lambda</span> x: x * <span class="number">2</span> + <span class="number">10</span>, foo)</div><div class="line">[<span class="number">14</span>, <span class="number">46</span>, <span class="number">28</span>, <span class="number">54</span>, <span class="number">44</span>, <span class="number">58</span>, <span class="number">26</span>, <span class="number">34</span>, <span class="number">64</span>]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">print</span> reduce(<span class="keyword">lambda</span> x, y: x + y, foo)</div><div class="line"><span class="number">139</span></div></pre></td></tr></table></figure></p>
<h3 id="range和xrange的区别"><a href="#range和xrange的区别" class="headerlink" title="range和xrange的区别"></a>range和xrange的区别</h3><p><strong>range</strong><br>    函数说明：range([start,] stop[, step])，根据start与stop指定的范围以及step设定的步长，生成一个<strong>list</strong>。<br>range示例:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>range(<span class="number">5</span>) </div><div class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>] </div><div class="line"><span class="meta">&gt;&gt;&gt; </span>range(<span class="number">1</span>,<span class="number">5</span>) </div><div class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>] </div><div class="line"><span class="meta">&gt;&gt;&gt; </span>range(<span class="number">0</span>,<span class="number">6</span>,<span class="number">2</span>)</div><div class="line">[<span class="number">0</span>, <span class="number">2</span>, <span class="number">4</span>]</div></pre></td></tr></table></figure></p>
<p><strong>xrange</strong><br>    函数说明：用法与range完全相同，所不同的是生成的不是一个数组，而是一个<strong>generator</strong>。<br>xrange示例:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>xrange(<span class="number">5</span>)</div><div class="line">xrange(<span class="number">5</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>list(xrange(<span class="number">5</span>))</div><div class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>xrange(<span class="number">1</span>,<span class="number">5</span>)</div><div class="line">xrange(<span class="number">1</span>, <span class="number">5</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>list(xrange(<span class="number">1</span>,<span class="number">5</span>))</div><div class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>xrange(<span class="number">0</span>,<span class="number">6</span>,<span class="number">2</span>)</div><div class="line">xrange(<span class="number">0</span>, <span class="number">6</span>, <span class="number">2</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>list(xrange(<span class="number">0</span>,<span class="number">6</span>,<span class="number">2</span>))</div><div class="line">[<span class="number">0</span>, <span class="number">2</span>, <span class="number">4</span>]</div></pre></td></tr></table></figure></p>
<p>由上面的示例可以知道：要生成很大的数字序列的时候，用xrange会比range性能优很多，因为不需要一上来就开辟一块很大的内存空间，这两个基本上都是在循环的时候用：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">100</span>): </div><div class="line">	<span class="keyword">print</span> i </div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">0</span>, <span class="number">100</span>): </div><div class="line">	<span class="keyword">print</span> i</div></pre></td></tr></table></figure>
<p>这两个输出的结果都是一样的，实际上有很多不同，range会直接生成一个list对象：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">a = range(<span class="number">0</span>,<span class="number">100</span>) </div><div class="line"><span class="keyword">print</span> type(a) </div><div class="line"><span class="keyword">print</span> a </div><div class="line"><span class="keyword">print</span> a[<span class="number">0</span>], a[<span class="number">1</span>]</div></pre></td></tr></table></figure></p>
<p>输出结果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">&lt;type <span class="string">'list'</span>&gt;</div><div class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>, <span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>, <span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>, <span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>, <span class="number">30</span>, <span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>, <span class="number">34</span>, <span class="number">35</span>, <span class="number">36</span>, <span class="number">37</span>, <span class="number">38</span>, <span class="number">39</span>, <span class="number">40</span>, <span class="number">41</span>, <span class="number">42</span>, <span class="number">43</span>, <span class="number">44</span>, <span class="number">45</span>, <span class="number">46</span>, <span class="number">47</span>, <span class="number">48</span>, <span class="number">49</span>, <span class="number">50</span>, <span class="number">51</span>, <span class="number">52</span>, <span class="number">53</span>, <span class="number">54</span>, <span class="number">55</span>, <span class="number">56</span>, <span class="number">57</span>, <span class="number">58</span>, <span class="number">59</span>, <span class="number">60</span>, <span class="number">61</span>, <span class="number">62</span>, <span class="number">63</span>, <span class="number">64</span>, <span class="number">65</span>, <span class="number">66</span>, <span class="number">67</span>, <span class="number">68</span>, <span class="number">69</span>, <span class="number">70</span>, <span class="number">71</span>, <span class="number">72</span>, <span class="number">73</span>, <span class="number">74</span>, <span class="number">75</span>, <span class="number">76</span>, <span class="number">77</span>, <span class="number">78</span>, <span class="number">79</span>, <span class="number">80</span>, <span class="number">81</span>, <span class="number">82</span>, <span class="number">83</span>, <span class="number">84</span>, <span class="number">85</span>, <span class="number">86</span>, <span class="number">87</span>, <span class="number">88</span>, <span class="number">89</span>, <span class="number">90</span>, <span class="number">91</span>, <span class="number">92</span>, <span class="number">93</span>, <span class="number">94</span>, <span class="number">95</span>, <span class="number">96</span>, <span class="number">97</span>, <span class="number">98</span>, <span class="number">99</span>]</div><div class="line"><span class="number">0</span> <span class="number">1</span></div></pre></td></tr></table></figure></p>
<p>而xrange则不会直接生成一个list，而是每次调用返回其中的一个值：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">a = xrange(<span class="number">0</span>,<span class="number">100</span>) </div><div class="line"><span class="keyword">print</span> type(a) </div><div class="line"><span class="keyword">print</span> a </div><div class="line"><span class="keyword">print</span> a[<span class="number">0</span>], a[<span class="number">1</span>]</div></pre></td></tr></table></figure></p>
<p>输出结果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">&lt;type <span class="string">'xrange'</span>&gt;</div><div class="line">xrange(<span class="number">100</span>)</div><div class="line"><span class="number">0</span> <span class="number">1</span></div></pre></td></tr></table></figure></p>
<p>所以<strong>xrange做循环的性能比range好，尤其是返回很大的时候，尽量用xrange吧</strong>，除非你是要返回一个列表。</p>
<h3 id="for循环中的"><a href="#for循环中的" class="headerlink" title="for循环中的_"></a>for循环中的<code>_</code></h3><p>一段代码:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> xrange(<span class="number">10</span>):</div><div class="line">	block</div></pre></td></tr></table></figure></p>
<p>如果循环中block不需要用到迭代值的话，我们可以不用给迭代值命名，用<code>_</code>就好。</p>
<h3 id="if-else语句的简单赋值"><a href="#if-else语句的简单赋值" class="headerlink" title="if-else语句的简单赋值"></a>if-else语句的简单赋值</h3><p>示例:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">a = <span class="number">20</span> <span class="keyword">if</span> b == <span class="number">2</span> <span class="keyword">else</span> <span class="number">3</span> <span class="comment">#如果b==2,则a被赋值为20，否则被赋值为3</span></div></pre></td></tr></table></figure></p>
<p>很多其他语言，如C++, Java都有这种赋值语句:<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">a = b==<span class="number">2</span>? <span class="number">20</span>:<span class="number">3</span></div></pre></td></tr></table></figure></p>
<hr>
<p>Reference:</p>
<p><a href="http://www.cnblogs.com/fengmk2/archive/2008/04/21/1163766.html" target="_blank" rel="external">http://www.cnblogs.com/fengmk2/archive/2008/04/21/1163766.html</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h2&gt;&lt;p&gt;记录一些Python使用过程中的没见过或者优化的使用方法……&lt;/p&gt;
&lt;h3 id=&quot;什么是args和-kwargs？&quot;&gt;&lt;a href=&quot;#什么是args和-kwargs？&quot; class=&quot;headerlink&quot; title=&quot;什么是args和*kwargs？&quot;&gt;&lt;/a&gt;什么是&lt;strong&gt;args和*&lt;/strong&gt;kwargs？&lt;/h3&gt;&lt;p&gt;先来看个例子：&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;foo&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(*args, **kwargs)&lt;/span&gt;:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&#39;args = &#39;&lt;/span&gt;, args&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&#39;kwargs = &#39;&lt;/span&gt;, kwargs&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&#39;---------------------------------------&#39;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; __name__ == &lt;span class=&quot;string&quot;&gt;&#39;__main__&#39;&lt;/span&gt;:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    foo(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    foo(a=&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;,b=&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;,c=&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    foo(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;, a=&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;,b=&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;,c=&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    foo(&lt;span class=&quot;string&quot;&gt;&#39;a&#39;&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;keyword&quot;&gt;None&lt;/span&gt;, a=&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, b=&lt;span class=&quot;string&quot;&gt;&#39;2&#39;&lt;/span&gt;, c=&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;)&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Python" scheme="https://xijunlee.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>卷积神经网络为什么叫卷积呢？</title>
    <link href="https://xijunlee.github.io/2017/04/11/CNN/"/>
    <id>https://xijunlee.github.io/2017/04/11/CNN/</id>
    <published>2017-04-11T14:45:16.000Z</published>
    <updated>2017-04-11T15:30:25.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>之前读过好一些关于卷积神经网络的入门文章，看完了之后还是觉得似懂非懂。特别是<strong>卷积网络为什么叫卷积</strong>呢？上次吃饭居然还跟小红他们就这个问题聊了一下。今天碰巧刷知乎刷到<a href="https://zhuanlan.zhihu.com/p/25249694" target="_blank" rel="external">这篇文章</a>，作者对CNN做了非常生动的解释，是我目前看到的关于CNN最好的中文解释。当然了，作者还就卷积网络中卷积层对图像特征的提取和池化层的降维做了很好的解释。文章最后又对一个已经学习好的CNN中的卷积层和全连接层进行了可视化，这让我这样的小白能非常直观地看出CNN到底最后学出了什么特征。这篇博文整理了原文中关于解释<strong>卷积神经网络为什么叫卷积</strong>的描述，更多内容可以直接去<a href="https://zhuanlan.zhihu.com/p/25249694" target="_blank" rel="external">原文</a>中。</p>
<h2 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h2><p>我们在 2 维上说话。有两个$\mathcal{R}^2\rightarrow \mathcal{R}$的函数 f(x, y) 和 g(x, y) 。所谓 f 和 g 的卷积就是一个新的 $\mathcal{R}^2\rightarrow \mathcal{R}$的函数 c(x, y) 。通过下式得到：</p>
<a id="more"></a>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/intro_to_cnn/eq1.png">
<p>这式子的含义是：遍览从负无穷到正无穷的全部 s 和 t 值，把 g 在 (x-s, y-t) 上的值乘以 f 在 (s, t) 上的值之后再“加和”到一起（积分意义上），得到 c 在 (x, y) 上的值。说白了卷积就是一种“加权求和”，f 为权。以 (x, y) 为中心，把 g 距离中心 (-s, -t) 位置上的值乘上 f 在 (s, t) 的值，最后加到一起。把卷积公式写成离散形式就更清楚了：</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/intro_to_cnn/eq2.png">
<p>第二个等号成立是因为在这里我们每隔单位长度 1 一采样，$\Delta s$和$\Delta t$都是 1 。可以令 G 表示一幅 100 x 100 大小的灰度图像。G(x, y) 取值 [0,255] 区间内的整数，是图像在 (x, y) 的灰度值。x 和 y 坐标取 [0, 99] ，其它位置上 G 值全取 0 。令 F 在 s 和 t 取 {-1, 0, 1} 的位置为特定值，其他位置全取 0 。F 可以看作是一个 3 x 3 的网格。如图 1.1</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/intro_to_cnn/1.1.png">
<p>图 1.1</p>
<p>图 1.1 中 G 每个小格子里的值就是图像在 (x, y) 的灰度值。F 每个小格子里的值就是 F 在 (s, t) 的取值。</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/intro_to_cnn/1.2.jpg">
<p>图 1.2</p>
<p>如图 1.2 所示，将 F 的中心 (0, 0) 对准 G 的 (6, 6) 。把 F 和 G 对应的 9 个位置上各自的值相乘，再将 9 个乘积加在一起，就得到了卷积值 C(6, 6) 。对 G 的每一个位置求 C 值，就得到了一幅新的图像。其中注意三点：</p>
<p>F 是上下左右翻转后再与 G 对准的。因为卷积公式中 F(s, t) 乘上的是 G(x-s, y-t) 。比如 F(-1, -1) 乘上的是 G(7, 7) ；<br>如果 F 的所有值之和不等于 1.0，则 C 值有可能不落在 [0, 255] 区间内，那就不是一个合法的图像灰度值。所以如果需要让结果是一幅图像，就得将 F 归一化——令它的所有位置之和等于 1.0 ；<br>对于 G 边缘上的点，有可能它的周围位置超出了图像边缘。此时可以把图像边缘之外的值当做 0 。或者只计算其周围都不超边缘的点的 C 。这样计算出来的图像就比原图像小一些。在上例中是小了一圈，如果 F 覆盖范围更大，那么小的圈数更多。<br>上述操作其实就是对数字图像进行离散卷积操作，又叫滤波。F 称作卷积核或滤波器。不同的滤波器起不同的作用。想象一下，如果 F 的大小是 3 x 3 ，每个格子里的值都是 1/9 。那么滤波就相当于对原图像每一个点计算它周围 3 x 3 范围内 9 个图像点的灰度平均值。这应该是一种模糊。看看效果。</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/intro_to_cnn/1.3.png">
<p>图 1.3</p>
<p>左图是 lena 灰度原图。中图用 3 x 3 值都为 1/9 的滤波器去滤，得到一个轻微模糊的图像。模糊程度不高是因为滤波器覆盖范围小。右图选取了 9 x 9 值为 1/81 的滤波器，模糊效果就较明显了。滤波器还有许多其他用处。例如下面这个滤波器：</p>
<p>+—+—+—+<br>| -1 |  0 |  1 |<br>+—+—+—+<br>| -2 |  0 |  2 |<br>+—+—+—+<br>| -1 |  0 |  1 |<br>+—+—+—+<br>注意该滤波器没有归一化（和不是 1.0 ），故滤出来的值可能不在 [0, 255] 之内。通过减去最小值、除以最大／最小值之差、再乘以 255 并取整，把结果值归一到 [0, 255] 之内，使之成为一幅灰度图像。现在尝试用它来滤 lena 图。</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/intro_to_cnn/1.4.png">
<p>图 1.4</p>
<p>该滤波器把图像的边缘检测出来了。它就是 Sobel 算子。边缘检测、图像模糊等等都是人们设计出来的、有专门用途的滤波器。如果搞一个 9 x 9 的随机滤波器，会是什么效果呢？</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/intro_to_cnn/1.5.png">
<p>图 1.5</p>
<p>如上图，效果也类似于模糊。因为把一个像素点的值用它周围 9 x 9 范围的值随机加权求和，相当于“捣浆糊”。但可以看出模糊得并不润滑。</p>
<p>这时我们不禁要想，如果不是由人来设计一个滤波器，而是从一个随机滤波器开始，根据某种目标、用某种方法去逐渐调整它，直到它接近我们想要的样子，可行么？这就是卷积神经网络（Convolutional Neural Network, CNN）的思想了。可调整的<strong>滤波器</strong>是 CNN 的<strong>“卷积”</strong>那部分；如何<strong>调整滤波器</strong>则是 CNN 的<strong>“神经网络”</strong>那部分。</p>
<h2 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h2><p>现在把卷积滤波器和神经网络两个思想结合起来。卷积滤波器无非就是一套权值。而神经网络也可以有（除全连接外的）其它拓扑结构。可以构造如图 3.1 所示意的神经网络。</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/intro_to_cnn/3.1.jpg">
<p>图 3.1</p>
<p>该神经网络接受 n x n 个输入，产生 n x n 个输出。图中左边的平面包含 n x n 个格子，每个格子中是一个 [0, 255] 的整数值。它就是输入图像，也是这个神经网络的输入。右边的平面也是 n x n 个格子，每个格子是一个神经元。每个神经元连接到输入上它对应位置周围 3 x 3 范围内的值。每个连接有一个权值。所有神经元都如此连接（图中只画了一个，出了输入图像边缘的连接就认为连接到常数 0 ）。右边层的 n x n 个神经元的输出就是该神经网络的输出。</p>
<p>这个神经网络有两点与全连接神经网络不同。首先它不是全连接的。右层的神经元并非连接上全部输入，而是只连接了一部分。这里的一部分就是输入图像的一个局部区域。我们常听说 CNN 能够把握图像局部特征就是这个意思。这样一来权值少了很多，因为连接就少了。权值其实还更少，因为每一个神经元的 9 个权值都是和其他神经元共享的。全部 n x n 个神经元都用这共同的一组 9 个权值，并且不要偏置值。那么这个神经网络其实一共只有 9 个参数需要调整。</p>
<p>看了第一节的同学们都看出来了，这个神经网络不就是一个卷积滤波器么？只不过卷积核的参数未定，需要我们去训练——它是一个“可训练滤波器”。这个神经网络其实就是一个只有一个卷积层、且该卷积层只有一个滤波器（通道）的 CNN 。</p>
<p>试着用 Sobel 算子滤出来的图片作为目标值去训练这个神经网络。给神经网络的输入是灰度 lena 图，目标输出是经过 Sobel 算子滤波的 lena 图，见图 1.4 。这唯一的一对输入输出图片就构成了训练集。神经网络权值随机初始化，训练 2000 轮。如图 3.7 。</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/intro_to_cnn/3.2.jpg">
<p>图 3.2</p>
<p>从左上到右下依次为：初始随机滤波器输出、每个 200 轮训练后的滤波器输出（ 10 幅）、最后一幅是 Sobel 算子的输出，也就是用作训练的目标图像。可以看到经过最初 200 轮后，神经网络的输出就已经和 Sobel 算子的输出看不出什么差别了。后面那些轮的输出基本一样。输入与输出的均方误差 mse 随着训练轮次的变化。如图 3.3 。</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/intro_to_cnn/3.3.jpg">
<p>图 3.3</p>
<p>1500 轮过后，mse 基本就是 0 了。训练完成后网络的权值是：</p>
<p>+——————-+——————–+——————–+<br>| 1.2886529   |  0.04068733  |  -1.3082279  |<br>+——————-+——————–+——————–+<br>| 1.43157125  |  0.01173212  |  -1.45389295 |<br>+——————-+——————–+——————–+<br>| 1.34158182  |  -0.07245208 |  -1.27504027 |<br>+——————-+——————–+——————–+<br>与 Sobel 算子比较一下：</p>
<p>+—+—+—+<br>| -1 |  0 |  1 |<br>+—+—+—+<br>| -2 |  0 |  2 |<br>+—+—+—+<br>| -1 |  0 |  1 |<br>+—+—+—+</p>
<p>注意训练出来的滤波器负数列在右侧而不是左侧。因为计算卷积是把滤波器上下左右翻转反着扣上去的。这并不重要，本质是相同的。关键是一正列、一负列，中间零值列。非零值列三个值之比近似 1:2:1 。我们得到的就是一个近似的 Sobel 算子。我们以训练神经网络的方式把一个随机滤波器训练成了 Sobel 算子。这就是优化的魔力（代码见本文最后）。</p>
<p>在 CNN 中，这样的滤波器层叫做卷积层。一个卷积层可以有多个滤波器，每一个叫做一个通道，或者叫做一个 feature map 。可以给卷积层的输出施加某个激活函数：Sigmoid 、Tanh 等等。激活函数也构成 CNN 的一层——激活层，这样的层没有可训练的参数。</p>
<p>还有一种层叫做 Pooling 层（池化层）。它也没有参数，起到降维的作用。将输入切分成不重叠的一些 n x n 区域。每一个区域就包含 n x n 个值。从这 n x n 个值计算出一个值。计算方法可以是求平均、取最大等等。假设 n = 2，那么 4 个输入变成一个输出。输出图像就是输入图像的 1/4 大小。若把 2 维的层展平成一维向量，后面可再连接一个全连接前向神经网络。</p>
<p>通过把这些组件进行组合就得到了一个 CNN 。它直接以原始图像为输入，以最终的回归或分类问题的结论为输出，内部兼有滤波图像处理和函数拟合，所有参数放在一起训练。这就是卷积神经网络。</p>
<p>以上提供了一个理解 CNN 的视角。CNN 的发明并非沿着此思路。像 NN 本身一样，CNN 的思想来源于对生物视觉神经系统的研究。</p>
<hr>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference:"></a>Reference:</h2><p>［1］<a href="https://link.zhihu.com/?target=https%3A//book.douban.com/subject/26732914/" target="_blank" rel="external">《最优化导论》（美）Edwin K. P. Chong（美） Stanislaw H. Zak</a></p>
<p>［2］<a href="https://link.zhihu.com/?target=https%3A//book.douban.com/subject/1115600/" target="_blank" rel="external">《神经网络设计》（美）Martin T. Hagan（美）Howard B. Demuth（美）Mark Beale</a></p>
<p>［3］<a href="https://link.zhihu.com/?target=https%3A//book.douban.com/subject/1102235/" target="_blank" rel="external">《机器学习》（美）Tom Mitchell</a></p>
<p>［4］<a href="https://link.zhihu.com/?target=https%3A//book.douban.com/subject/2068931/" target="_blank" rel="external">《神经计算原理》（美）Fredric M. Han（美）Ivica Kostanic</a></p>
<p>［5］<a href="https://link.zhihu.com/?target=https%3A//book.douban.com/subject/3587732/" target="_blank" rel="external">《人工智能——复杂问题求解的结构和策略》（美）George F. Luger</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h2&gt;&lt;p&gt;之前读过好一些关于卷积神经网络的入门文章，看完了之后还是觉得似懂非懂。特别是&lt;strong&gt;卷积网络为什么叫卷积&lt;/strong&gt;呢？上次吃饭居然还跟小红他们就这个问题聊了一下。今天碰巧刷知乎刷到&lt;a href=&quot;https://zhuanlan.zhihu.com/p/25249694&quot;&gt;这篇文章&lt;/a&gt;，作者对CNN做了非常生动的解释，是我目前看到的关于CNN最好的中文解释。当然了，作者还就卷积网络中卷积层对图像特征的提取和池化层的降维做了很好的解释。文章最后又对一个已经学习好的CNN中的卷积层和全连接层进行了可视化，这让我这样的小白能非常直观地看出CNN到底最后学出了什么特征。这篇博文整理了原文中关于解释&lt;strong&gt;卷积神经网络为什么叫卷积&lt;/strong&gt;的描述，更多内容可以直接去&lt;a href=&quot;https://zhuanlan.zhihu.com/p/25249694&quot;&gt;原文&lt;/a&gt;中。&lt;/p&gt;
&lt;h2 id=&quot;卷积&quot;&gt;&lt;a href=&quot;#卷积&quot; class=&quot;headerlink&quot; title=&quot;卷积&quot;&gt;&lt;/a&gt;卷积&lt;/h2&gt;&lt;p&gt;我们在 2 维上说话。有两个$\mathcal{R}^2\rightarrow \mathcal{R}$的函数 f(x, y) 和 g(x, y) 。所谓 f 和 g 的卷积就是一个新的 $\mathcal{R}^2\rightarrow \mathcal{R}$的函数 c(x, y) 。通过下式得到：&lt;/p&gt;
    
    </summary>
    
    
      <category term="CNN" scheme="https://xijunlee.github.io/tags/CNN/"/>
    
  </entry>
  
  <entry>
    <title>A Summary of Bit Manipulation (reposted from leetcode discussion)</title>
    <link href="https://xijunlee.github.io/2017/04/01/efficiently/"/>
    <id>https://xijunlee.github.io/2017/04/01/efficiently/</id>
    <published>2017-04-01T05:46:11.000Z</published>
    <updated>2017-04-01T10:33:26.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="WIKI"><a href="#WIKI" class="headerlink" title="WIKI"></a>WIKI</h2><p>Bit manipulation is the act of algorithmically manipulating bits or other pieces of data shorter than a word. Computer programming tasks that require bit manipulation include low-level device control, error detection and correction algorithms, data compression, encryption algorithms, and optimization. For most other tasks, modern programming languages allow the programmer to work directly with abstractions instead of bits that represent those abstractions. Source code that does bit manipulation makes use of the bitwise operations: AND, OR, XOR, NOT, and bit shifts.</p>
<p>Bit manipulation, in some cases, can obviate or reduce the need to loop over a data structure and can give many-fold speed ups, as bit manipulations are processed in parallel, but the code can become more difficult to write and maintain.</p>
<a id="more"></a>
<h2 id="DETAILS"><a href="#DETAILS" class="headerlink" title="DETAILS"></a>DETAILS</h2><h3 id="Basics"><a href="#Basics" class="headerlink" title="Basics"></a>Basics</h3><p>At the heart of bit manipulation are the bit-wise operators &amp; (and), | (or), ~ (not) and ^ (exclusive-or, xor) and shift operators a &lt;&lt; b and a &gt;&gt; b.</p>
<blockquote>
<p>There is no boolean operator counterpart to bitwise exclusive-or, but there is a simple explanation. The exclusive-or operation takes two inputs and returns a 1 if either one or the other of the inputs is a 1, but not if both are. That is, if both inputs are 1 or both inputs are 0, it returns 0. Bitwise exclusive-or, with the operator of a caret, ^, performs the exclusive-or operation on each pair of bits. Exclusive-or is commonly abbreviated XOR.</p>
</blockquote>
<ol>
<li>Set union A | B</li>
<li>Set intersection A &amp; B</li>
<li>Set subtraction A &amp; ~B</li>
<li>Set negation ALL_BITS ^ A or ~A</li>
<li>Set bit A |= 1 &lt;&lt; bit</li>
<li>Clear bit A &amp;= ~(1 &lt;&lt; bit)</li>
<li>Test bit (A &amp; 1 &lt;&lt; bit) != 0</li>
<li>Extract last bit A&amp;-A or A&amp;~(A-1) or x^(x&amp;(x-1))</li>
<li>Remove last bit A&amp;(A-1)</li>
<li>Get all 1-bits ~0</li>
</ol>
<h3 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h3><p>Count the number of ones in the binary representation of the given number</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">count_one</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</div><div class="line">    <span class="keyword">while</span>(n) &#123;</div><div class="line">        n = n&amp;(n<span class="number">-1</span>);</div><div class="line">        count++;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> count;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Is power of four (actually map-checking, iterative and recursive methods can do the same)</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">bool</span> <span class="title">isPowerOfFour</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> !(n&amp;(n<span class="number">-1</span>)) &amp;&amp; (n&amp;<span class="number">0x55555555</span>);</div><div class="line">    <span class="comment">//check the 1-bit location;</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="tricks"><a href="#tricks" class="headerlink" title="^ tricks"></a><code>^</code> tricks</h3><p>Use <code>^</code> to remove even exactly same numbers and save the odd, or save the distinct bits and remove the same.</p>
<h4 id="SUM-OF-TWO-INTEGERS"><a href="#SUM-OF-TWO-INTEGERS" class="headerlink" title="SUM OF TWO INTEGERS"></a>SUM OF TWO INTEGERS</h4><p>Use <code>^</code> and <code>&amp;</code> to add two integers</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">getSum</span><span class="params">(<span class="keyword">int</span> a, <span class="keyword">int</span> b)</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> b==<span class="number">0</span>? a:getSum(a^b, (a&amp;b)&lt;&lt;<span class="number">1</span>); <span class="comment">//be careful about the terminating condition;</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="MISSING-NUMBER"><a href="#MISSING-NUMBER" class="headerlink" title="MISSING NUMBER"></a>MISSING NUMBER</h4><p>Given an array containing n distinct numbers taken from 0, 1, 2, …, n, find the one that is missing from the array. For example, Given nums = [0, 1, 3] return 2. (Of course, you can do this by math.)</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">missingNumber</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</div><div class="line">    <span class="keyword">int</span> ret = <span class="number">0</span>;</div><div class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.size(); ++i) &#123;</div><div class="line">        ret ^= i;</div><div class="line">        ret ^= nums[i];</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> ret^=nums.size();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="tricks-1"><a href="#tricks-1" class="headerlink" title="| tricks"></a><code>|</code> tricks</h3><p>Keep as many 1-bits as possible</p>
<p>Find the largest power of 2 (most significant bit in binary form), which is less than or equal to the given number N.</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">long</span> <span class="title">largest_power</span><span class="params">(<span class="keyword">long</span> N)</span> </span>&#123;</div><div class="line">    <span class="comment">//changing all right side bits to 1.</span></div><div class="line">    N = N | (N&gt;&gt;<span class="number">1</span>);</div><div class="line">    N = N | (N&gt;&gt;<span class="number">2</span>);</div><div class="line">    N = N | (N&gt;&gt;<span class="number">4</span>);</div><div class="line">    N = N | (N&gt;&gt;<span class="number">8</span>);</div><div class="line">    N = N | (N&gt;&gt;<span class="number">16</span>);</div><div class="line">    <span class="keyword">return</span> (N+<span class="number">1</span>)&gt;&gt;<span class="number">1</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="REVERSE-BITS"><a href="#REVERSE-BITS" class="headerlink" title="REVERSE BITS"></a>REVERSE BITS</h4><p>Reverse bits of a given 32 bits unsigned integer.</p>
<p>Solution</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">uint32_t</span> reverseBits(<span class="keyword">uint32_t</span> n) &#123;</div><div class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> mask = <span class="number">1</span>&lt;&lt;<span class="number">31</span>, res = <span class="number">0</span>;</div><div class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">32</span>; ++i) &#123;</div><div class="line">        <span class="keyword">if</span>(n &amp; <span class="number">1</span>) res |= mask;</div><div class="line">        mask &gt;&gt;= <span class="number">1</span>;</div><div class="line">        n &gt;&gt;= <span class="number">1</span>;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> res;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">uint32_t</span> reverseBits(<span class="keyword">uint32_t</span> n) &#123;</div><div class="line">	<span class="keyword">uint32_t</span> mask = <span class="number">1</span>, ret = <span class="number">0</span>;</div><div class="line">	<span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">32</span>; ++i)&#123;</div><div class="line">		ret &lt;&lt;= <span class="number">1</span>;</div><div class="line">		<span class="keyword">if</span>(mask &amp; n) ret |= <span class="number">1</span>;</div><div class="line">		mask &lt;&lt;= <span class="number">1</span>;</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">return</span> ret;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="amp-tricks"><a href="#amp-tricks" class="headerlink" title="&amp; tricks"></a><code>&amp;</code> tricks</h3><p>Just selecting certain bits</p>
<p>Reversing the bits in integer</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">x = ((x &amp; <span class="number">0xaaaaaaaa</span>) &gt;&gt; <span class="number">1</span>) | ((x &amp; <span class="number">0x55555555</span>) &lt;&lt; <span class="number">1</span>);</div><div class="line">x = ((x &amp; <span class="number">0xcccccccc</span>) &gt;&gt; <span class="number">2</span>) | ((x &amp; <span class="number">0x33333333</span>) &lt;&lt; <span class="number">2</span>);</div><div class="line">x = ((x &amp; <span class="number">0xf0f0f0f0</span>) &gt;&gt; <span class="number">4</span>) | ((x &amp; <span class="number">0x0f0f0f0f</span>) &lt;&lt; <span class="number">4</span>);</div><div class="line">x = ((x &amp; <span class="number">0xff00ff00</span>) &gt;&gt; <span class="number">8</span>) | ((x &amp; <span class="number">0x00ff00ff</span>) &lt;&lt; <span class="number">8</span>);</div><div class="line">x = ((x &amp; <span class="number">0xffff0000</span>) &gt;&gt; <span class="number">16</span>) | ((x &amp; <span class="number">0x0000ffff</span>) &lt;&lt; <span class="number">16</span>);</div></pre></td></tr></table></figure>
<h4 id="BITWISE-AND-OF-NUMBERS-RANGE"><a href="#BITWISE-AND-OF-NUMBERS-RANGE" class="headerlink" title="BITWISE AND OF NUMBERS RANGE"></a>BITWISE AND OF NUMBERS RANGE</h4><p>Given a range [m, n] where 0 &lt;= m &lt;= n &lt;= 2147483647, return the bitwise AND of all numbers in this range, inclusive. For example, given the range [5, 7], you should return 4.</p>
<p>Solution<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">rangeBitwiseAnd</span><span class="params">(<span class="keyword">int</span> m, <span class="keyword">int</span> n)</span> </span>&#123;</div><div class="line">    <span class="keyword">int</span> a = <span class="number">0</span>;</div><div class="line">    <span class="keyword">while</span>(m != n) &#123;</div><div class="line">        m &gt;&gt;= <span class="number">1</span>;</div><div class="line">        n &gt;&gt;= <span class="number">1</span>;</div><div class="line">        a++;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> m&lt;&lt;a; </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h4 id="NUMBER-OF-1-BITS"><a href="#NUMBER-OF-1-BITS" class="headerlink" title="NUMBER OF 1 BITS"></a>NUMBER OF 1 BITS</h4><p>Write a function that takes an unsigned integer and returns the number of ’1’ bits it has (also known as the Hamming weight).</p>
<p>Solution<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">hammingWeight</span><span class="params">(<span class="keyword">uint32_t</span> n)</span> </span>&#123;</div><div class="line">	<span class="keyword">int</span> count = <span class="number">0</span>;</div><div class="line">	<span class="keyword">while</span>(n) &#123;</div><div class="line">		n = n&amp;(n<span class="number">-1</span>);</div><div class="line">		count++;</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">return</span> count;</div><div class="line">&#125;</div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">hammingWeight</span><span class="params">(<span class="keyword">uint32_t</span> n)</span> </span>&#123;</div><div class="line">    ulong mask = <span class="number">1</span>;</div><div class="line">    <span class="keyword">int</span> count = <span class="number">0</span>;</div><div class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">32</span>; ++i)&#123; <span class="comment">//31 will not do, delicate;</span></div><div class="line">        <span class="keyword">if</span>(mask &amp; n) count++;</div><div class="line">        mask &lt;&lt;= <span class="number">1</span>;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> count;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<hr>
<p>Reference:</p>
<p><a href="https://discuss.leetcode.com/topic/50315/a-summary-how-to-use-bit-manipulation-to-solve-problems-easily-and-efficiently" target="_blank" rel="external">https://discuss.leetcode.com/topic/50315/a-summary-how-to-use-bit-manipulation-to-solve-problems-easily-and-efficiently</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;WIKI&quot;&gt;&lt;a href=&quot;#WIKI&quot; class=&quot;headerlink&quot; title=&quot;WIKI&quot;&gt;&lt;/a&gt;WIKI&lt;/h2&gt;&lt;p&gt;Bit manipulation is the act of algorithmically manipulating bits or other pieces of data shorter than a word. Computer programming tasks that require bit manipulation include low-level device control, error detection and correction algorithms, data compression, encryption algorithms, and optimization. For most other tasks, modern programming languages allow the programmer to work directly with abstractions instead of bits that represent those abstractions. Source code that does bit manipulation makes use of the bitwise operations: AND, OR, XOR, NOT, and bit shifts.&lt;/p&gt;
&lt;p&gt;Bit manipulation, in some cases, can obviate or reduce the need to loop over a data structure and can give many-fold speed ups, as bit manipulations are processed in parallel, but the code can become more difficult to write and maintain.&lt;/p&gt;
    
    </summary>
    
    
      <category term="bit manipulation" scheme="https://xijunlee.github.io/tags/bit-manipulation/"/>
    
  </entry>
  
  <entry>
    <title>sklearn中SVM调参说明及经验总结</title>
    <link href="https://xijunlee.github.io/2017/03/29/sklearn%E4%B8%ADSVM%E8%B0%83%E5%8F%82%E8%AF%B4%E6%98%8E%E5%8F%8A%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93/"/>
    <id>https://xijunlee.github.io/2017/03/29/sklearn中SVM调参说明及经验总结/</id>
    <published>2017-03-29T12:47:23.000Z</published>
    <updated>2017-03-29T13:11:26.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>之前只停留在理论上，没有实际沉下心去调参，实际去做了后，发现调参是个大工程（玄学）。于是这篇来总结一下<code>sklearn</code>中svm的参数说明以及调参经验。方便以后查询和回忆。</p>
<h2 id="常用核函数"><a href="#常用核函数" class="headerlink" title="常用核函数"></a>常用核函数</h2><p>1.linear核函数: $$K(x_i,x_j)=x_i^Tx_j$$<br><a id="more"></a><br>2.polynomial核函数: $$K(x_i,x_j)=(\gamma x_i^Tx_j + r)^d, d&gt;1$$<br>3.RBF核函数（高斯核函数）: $$K(x_i,x_j)=exp(-\gamma ||x_i-x_j||^2),\gamma&gt;0$$<br>4.sigmoid核函数: $$K(x_i,x_j)=tanh(\gamma x_i^Tx_j + r ), \gamma&gt;0, r&lt;0$$</p>
<h2 id="sklearn-svm-相关参数的官方说明"><a href="#sklearn-svm-相关参数的官方说明" class="headerlink" title="sklearn svm 相关参数的官方说明"></a>sklearn svm 相关参数的官方说明</h2><p>Parameters:<br><code>C</code> : float, optional (default=1.0). Penalty parameter C of the error term.<br><code>kernel</code> : string, optional (default=’rbf’). Specifies the kernel type to be used in the algorithm. It must be one of ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ or a callable. If none is given, ‘rbf’ will be used. If a callable is given it is used to pre-compute the kernel matrix from data matrices; that matrix should be an array of shape (n_samples, n_samples).<br><code>degree</code> : int, optional (default=3). Degree of the polynomial kernel function (‘poly’). Ignored by all other kernels.<br><code>gamma</code> : float, optional (default=’auto’). Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’. If gamma is ‘auto’ then 1/n_features will be used instead.<br><code>coef0</code> : float, optional (default=0.0). Independent term in kernel function. It is only significant in ‘poly’ and ‘sigmoid’.<br><code>probability</code> : boolean, optional (default=False). Whether to enable probability estimates. This must be enabled prior to calling fit, and will slow down that method.<br><code>shrinking</code> : boolean, optional (default=True). Whether to use the shrinking heuristic.<br><code>tol</code> : float, optional (default=1e-3). Tolerance for stopping criterion.<br><code>cache_size</code> : float, optional. Specify the size of the kernel cache (in MB).<br><code>class_weight</code> : {dict, ‘balanced’}, optional. Set the parameter C of class i to class_weight[i]<em>C for SVC. If not given, all classes are supposed to have weight one. The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes </em> np.bincount(y))<br><code>verbose</code> : bool, default: False. Enable verbose output. Note that this setting takes advantage of a per-process runtime setting in libsvm that, if enabled, may not work properly in a multithreaded context.<br><code>max_iter</code> : int, optional (default=-1). Hard limit on iterations within solver, or -1 for no limit.<br><code>decision_function_shape</code> : ‘ovo’, ‘ovr’ or None, default=None. Whether to return a one-vs-rest (‘ovr’) decision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (‘ovo’) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2). The default of None will currently behave as ‘ovo’ for backward compatibility and raise a deprecation warning, but will change ‘ovr’ in 0.19.<br>New in version 0.17: decision_function_shape=’ovr’ is recommended.<br>Changed in version 0.17: Deprecated decision_function_shape=’ovo’ and None.<br><code>random_state</code> : int seed, RandomState instance, or None (default). The seed of the pseudo random number generator to use when shuffling the data for probability estimation.</p>
<h2 id="libsvm中参数说明"><a href="#libsvm中参数说明" class="headerlink" title="libsvm中参数说明"></a>libsvm中参数说明</h2><p>因为sklearn底层是调用libsvm的，因此sklearn中svm参数说明是可以直接参考libsvm中的。</p>
<p>1.linear核函数: $$K(x_i,x_j)=x_i^Tx_j$$<br>2.polynomial核函数: $$K(x_i,x_j)=(\gamma x_i^Tx_j + r)^d, d&gt;1$$<br>3.RBF核函数（高斯核函数）: $$K(x_i,x_j)=exp(-\gamma ||x_i-x_j||^2),\gamma&gt;0$$<br>4.sigmoid核函数: $$K(x_i,x_j)=tanh(\gamma x_i^Tx_j + r ), \gamma&gt;0, r&lt;0$$</p>
<p>首先介绍下与核函数相对应的参数：<br>1）对于线性核函数，没有专门需要设置的参数<br>2）对于多项式核函数，有三个参数。-d用来设置多项式核函数的最高次项次数，也就是公式中的d，默认值是3。-g用来设置核函数中的gamma参数设置，也就是公式中的gamma，默认值是1/k（特征数）。-r用来设置核函数中的coef0，也就是公式中的第二个r，默认值是0。<br>3）对于RBF核函数，有一个参数。-g用来设置核函数中的gamma参数设置，也就是公式中gamma，默认值是1/k（k是特征数）。<br>4）对于sigmoid核函数，有两个参数。-g用来设置核函数中的gamma参数设置，也就是公式中gamma，默认值是1/k（k是特征数）。-r用来设置核函数中的coef0，也就是公式中的第二个r，默认值是0。</p>
<p><strong> 具体来说说rbf核函数中C和gamma </strong>：</p>
<p>SVM模型有两个非常重要的参数C与gamma。其中 C是惩罚系数，即对误差的宽容度。c越高，说明越不能容忍出现误差,容易过拟合。C越小，容易欠拟合。C过大或过小，泛化能力变差</p>
<p>gamma是选择RBF函数作为kernel后，该函数自带的一个参数。隐含地决定了数据映射到新的特征空间后的分布，gamma越大，支持向量越少，gamma值越小，支持向量越多。支持向量的个数影响训练与预测的速度。</p>
<p>这里面大家需要注意的就是gamma的物理意义，大家提到很多的RBF的幅宽，它会影响每个支持向量对应的高斯的作用范围，从而影响泛化性能。我的理解：如果gamma设的太大，方差会很小，方差很小的高斯分布长得又高又瘦， 会造成只会作用于支持向量样本附近，对于未知样本分类效果很差，存在训练准确率可以很高，(如果让方差无穷小，则理论上，高斯核的SVM可以拟合任何非线性数据，但容易过拟合)而测试准确率不高的可能，就是通常说的过训练；而如果设的过小，则会造成平滑效应太大，无法在训练集上得到特别高的准确率，也会影响测试集的准确率。</p>
<p>此外，可以明确的两个结论是：<br>结论1：样本数目少于特征维度并不一定会导致过拟合，这可以参考余凯老师的这句评论：<br>“这不是原因啊，呵呵。用RBF kernel, 系统的dimension实际上不超过样本数，与特征维数没有一个trivial的关系。”</p>
<p>结论2：RBF核应该可以得到与线性核相近的效果（按照理论，RBF核可以模拟线性核），可能好于线性核，也可能差于，但是，不应该相差太多。<br>当然，很多问题中，比如维度过高，或者样本海量的情况下，大家更倾向于用线性核，因为效果相当，但是在速度和模型大小方面，线性核会有更好的表现。</p>
<hr>
<p>Reference:</p>
<p><a href="http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC" target="_blank" rel="external">http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC</a></p>
<p><a href="http://blog.csdn.net/lqhbupt/article/details/8610443" target="_blank" rel="external">http://blog.csdn.net/lqhbupt/article/details/8610443</a></p>
<p><a href="http://blog.csdn.net/lujiandong1/article/details/46386201" target="_blank" rel="external">http://blog.csdn.net/lujiandong1/article/details/46386201</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h2&gt;&lt;p&gt;之前只停留在理论上，没有实际沉下心去调参，实际去做了后，发现调参是个大工程（玄学）。于是这篇来总结一下&lt;code&gt;sklearn&lt;/code&gt;中svm的参数说明以及调参经验。方便以后查询和回忆。&lt;/p&gt;
&lt;h2 id=&quot;常用核函数&quot;&gt;&lt;a href=&quot;#常用核函数&quot; class=&quot;headerlink&quot; title=&quot;常用核函数&quot;&gt;&lt;/a&gt;常用核函数&lt;/h2&gt;&lt;p&gt;1.linear核函数: $$K(x_i,x_j)=x_i^Tx_j$$&lt;br&gt;
    
    </summary>
    
    
      <category term="SVM" scheme="https://xijunlee.github.io/tags/SVM/"/>
    
  </entry>
  
  <entry>
    <title>reddit上有趣的SVM图解</title>
    <link href="https://xijunlee.github.io/2017/03/13/reddit%E4%B8%8A%E7%9B%B4%E8%A7%82%E6%9C%89%E8%B6%A3%E7%9A%84SVM%E8%A7%A3%E9%87%8A/"/>
    <id>https://xijunlee.github.io/2017/03/13/reddit上直观有趣的SVM解释/</id>
    <published>2017-03-13T05:26:10.000Z</published>
    <updated>2017-03-13T05:45:24.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>这是目前看到过的对SVM的最直观的解释，原题目名还叫作<a href="https://www.reddit.com/r/MachineLearning/comments/15zrpp/please_explain_support_vector_machines_svm_like_i/" target="_blank" rel="external">Please explain Support Vector Machines (SVM) like I am a 5 year old</a>。于是，稍微整理下放到博客里。我个人认为，它对SVM中<code>kernel function</code>解释地相当形象。</p>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>Found <a href="https://www.reddit.com/r/MachineLearning/comments/15zrpp/please_explain_support_vector_machines_svm_like_i/" target="_blank" rel="external">this</a> on Reddit <a href="https://www.reddit.com/r/MachineLearning/" target="_blank" rel="external">r/machinelearning</a></p>
<p>(In related news, there’s a machine learning subreddit. Wow.)</p>
<a id="more"></a>
<p><a href="https://en.wikipedia.org/wiki/Support_vector_machine" target="_blank" rel="external">Support Vector Machines</a> (warning: Wikipedia dense article alert in previous link!) are learning models used for classification: which individuals in a population belong where? So… how do SVM and the mysterious “kernel” work?</p>
<p>The user curious_thoughts asked for an explanation of SVMs like s/he was a five year old. User copperking stepped up to the plate:</p>
<p>We have 2 colors of balls on the table that we want to separate.</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/svm_reddit/svm1.png">
<p>We get a stick and put it on the table, this works pretty well right?</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/svm_reddit/svm2.png">
<p>Some villain comes and places more balls on the table, it kind of works but one of the balls is on the wrong side and there is probably a better place to put the stick now.</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/svm_reddit/svm3.png">
<p>SVMs try to put the stick in the best possible place by having as big a gap on either side of the stick as possible.</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/svm_reddit/svm4.png">
<p>Now when the villain returns the stick is still in a pretty good spot.</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/svm_reddit/svm5.png">
<p>There is another trick in the SVM toolbox that is even more important. Say the villain has seen how good you are with a stick so he gives you a new challenge.</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/svm_reddit/svm6.png">
<p>There’s no stick in the world that will let you split those balls well, so what do you do? You flip the table of course! Throwing the balls into the air. Then, with your pro ninja skills, you grab a sheet of paper and slip it between the balls.</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/svm_reddit/svm6.png">
<p>Now, looking at the balls from where the villain is standing, they balls will look split by some curvy line.</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/svm_reddit/svm7.png">
<p>Boring adults the call balls data, the stick a classifier, the biggest gap trick optimization, call flipping the table kernelling and the piece of paper a hyperplane.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h2&gt;&lt;p&gt;这是目前看到过的对SVM的最直观的解释，原题目名还叫作&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/15zrpp/please_explain_support_vector_machines_svm_like_i/&quot;&gt;Please explain Support Vector Machines (SVM) like I am a 5 year old&lt;/a&gt;。于是，稍微整理下放到博客里。我个人认为，它对SVM中&lt;code&gt;kernel function&lt;/code&gt;解释地相当形象。&lt;/p&gt;
&lt;h2 id=&quot;正文&quot;&gt;&lt;a href=&quot;#正文&quot; class=&quot;headerlink&quot; title=&quot;正文&quot;&gt;&lt;/a&gt;正文&lt;/h2&gt;&lt;p&gt;Found &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/15zrpp/please_explain_support_vector_machines_svm_like_i/&quot;&gt;this&lt;/a&gt; on Reddit &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/&quot;&gt;r/machinelearning&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;(In related news, there’s a machine learning subreddit. Wow.)&lt;/p&gt;
    
    </summary>
    
    
      <category term="Support Vector Machine" scheme="https://xijunlee.github.io/tags/Support-Vector-Machine/"/>
    
  </entry>
  
  <entry>
    <title>GitMemo: Working with Git on Windows</title>
    <link href="https://xijunlee.github.io/2017/02/21/GitMemo-Working-with-Git-on-Windows-repost/"/>
    <id>https://xijunlee.github.io/2017/02/21/GitMemo-Working-with-Git-on-Windows-repost/</id>
    <published>2017-02-21T13:41:38.000Z</published>
    <updated>2017-02-21T14:11:44.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Preamble"><a href="#Preamble" class="headerlink" title="Preamble"></a>Preamble</h2><p>Setting up Git can be tricky on Windows compared to Linux or Mac, but if you follow the steps in this guide, you should have no problems using Git on Windows. This guide will take you through the steps to install and configure Git and connect it to remote repositories to clone, push, and pull. </p>
<a id="more"></a>
<h2 id="Choosing-a-Git-distribution"><a href="#Choosing-a-Git-distribution" class="headerlink" title="Choosing a Git distribution"></a>Choosing a Git distribution</h2><p>There are two competing Git packages for Windows: a <a href="http://www.cygwin.com" target="_blank" rel="external">Cygwin-based</a> Git and a version called <a href="https://git-for-windows.github.io" target="_blank" rel="external">msysGit</a>. I will describe how to install the msysGit package. I recommend installing msysGit because I’ve found it’s easier to work with than the Cygwin based installation.</p>
<h2 id="Installing-Git"><a href="#Installing-Git" class="headerlink" title="Installing Git"></a>Installing Git</h2><p>Once you have downloaded the msysGit executable, double click on it to start the installation wizard. Leave the default directory options. When you get to the “Adjusting your Path environment” setting, select the “Run Git from the Windows Command Prompt” option. Choosing this option will make it easy for you to run Git commands from the Windows Command Prompt (command line) if you choose. Command Prompt is a simple tool, where you can run commands, switch through folders, manage files and it can be ran by selecting RUN… in START menu, and executing <code>cmd</code>command.</p>
<p><strong> Note </strong> : I recommend that you better choose the default options when installing <code>msysGit</code> for saving your time and mind.</p>
<p>You will notice that for the rest of this article we will use Git Bash for running Git commands. The Git Bash tool works in the same way as the default Windows’ Command Prompt, but has some special features. With Git Bash you’ll be able to use a number of UNIX command line tools along with access to Git, and we recommend it since it’s often simpler to use than the Windows Command Prompt.</p>
<p>You can run it by right clicking your mouse on the desktop, and selecting Git Bash from pop up window.</p>
<p><strong> Important note </strong>: The most common problems when setting up Git on Windows are related to SSH keys. Git uses SSH keys to securely access your repositories, and in Windows SSH keys are often searched on the wrong path when you try to use Git.</p>
<p>If you use an older version of msysGit, you may encounter a step called “Choosing the SSH executables”. If you encounter that dialog, we recommend that you choose the “Use OpenSSH” option.</p>
<p>After you have successfully installed Git on Windows, you’ll need to provide secure communication with your Git repositories by creating and installing SSH keys.</p>
<h2 id="Installing-SSH-keys-on-Windows"><a href="#Installing-SSH-keys-on-Windows" class="headerlink" title="Installing SSH keys on Windows"></a>Installing SSH keys on Windows</h2><p>To access your Git repositories you will need to create and install SSH keys. You can do this using OpenSSH and generate SSH keys with <code>ssh-keygen</code></p>
<h3 id="Using-OpenSSH-and-generating-SSH-keys-with-ssh-keygen"><a href="#Using-OpenSSH-and-generating-SSH-keys-with-ssh-keygen" class="headerlink" title="Using OpenSSH and generating SSH keys with ssh-keygen"></a>Using OpenSSH and generating SSH keys with ssh-keygen</h3><p>To communicate with the remote Git repository from your Windows computer, you will need to generate an SSH key pair for that computer. This process requires only a few steps, but you do first need to install <code>msysGit</code> using the full installer as described above.</p>
<h4 id="Generating-a-key-pair"><a href="#Generating-a-key-pair" class="headerlink" title="Generating a key pair"></a>Generating a key pair</h4><p>To do this you need to run Git Bash, which can be found in your START menu. Run the command:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ssh-keygen -t rsa -C youremail@xxx.xxx</div></pre></td></tr></table></figure>
<p>Next, there will be several messages that asks you to set pass phrase. You could keep entering <code>return</code> key to skip these askings.</p>
<p>Now that the keys are generated, open the file id_rsa.pub (found in the default location from the previous step) with a text editor. The contents of this file is your new public key. If you copy it to your clipboard, you can add it to your git SSH keys.</p>
<p>Your SSH public key should look something like this:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAyyA8wePstPC69PeuHFtOwyTecByonsHFAjHbVnZ+h0dpomvLZxUtbknNj3+</div><div class="line">c7MPYKqKBOx9gUKV/diR/mIDqsb405MlrI1kmNR9zbFGYAAwIH/Gxt0Lv5ffwaqsz7cECHBbMojQGEz3IH3twEvDfF6cu5p</div><div class="line">00QfP0MSmEi/eB+W+h30NGdqLJCziLDlp409jAfXbQm/4Yx7apLvEmkaYSrb5f/pfvYv1FEV1tS8/J7DgdHUAWo6gyGUUSZ</div><div class="line">JgsyHcuJT7v9Tf0xwiFWOWL9WsWXa9fCKqTeYnYJhHlqfinZRnT/+jkz0OZ7YmXo6j4Hyms3RCOqenIX1W6gnIn+eQIkw==</div><div class="line">Mac Pro</div></pre></td></tr></table></figure>
<h3 id="Adding-your-SSH-public-key-to-your-git-SSH-keys"><a href="#Adding-your-SSH-public-key-to-your-git-SSH-keys" class="headerlink" title="Adding your SSH public key to your git SSH keys"></a>Adding your SSH public key to your git SSH keys</h3><p>1.Log your git account in, and click your avatar. Then, click <code>Setting</code> and find <code>SSH and GPG keys</code>.</p>
<p>2.Click <code>New SSH key</code>, copy your SSH public key in <code>Key</code> input area, and give this SSH key name in <code>Title</code> input area.</p>
<h3 id="Checking-your-connection"><a href="#Checking-your-connection" class="headerlink" title="Checking your connection"></a>Checking your connection</h3><p>Enter the following code to check whether you access to github successfully:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ssh git@github.com</div></pre></td></tr></table></figure>
<p>You will see:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">The authenticity of host <span class="string">'github.com (207.97.227.239)'</span> can<span class="string">'t be established.</span></div><div class="line">    RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.</div><div class="line">    Are you sure you want to continue connecting (yes/no)?</div></pre></td></tr></table></figure>
<p>Enter <code>Yes</code>, you will see:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Hi your name! You<span class="string">'ve successfully authenticated, but GitHub does not provide shell access.</span></div></pre></td></tr></table></figure>
<p>If you see above code, that indicates you have accessed github successfully!</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Preamble&quot;&gt;&lt;a href=&quot;#Preamble&quot; class=&quot;headerlink&quot; title=&quot;Preamble&quot;&gt;&lt;/a&gt;Preamble&lt;/h2&gt;&lt;p&gt;Setting up Git can be tricky on Windows compared to Linux or Mac, but if you follow the steps in this guide, you should have no problems using Git on Windows. This guide will take you through the steps to install and configure Git and connect it to remote repositories to clone, push, and pull. &lt;/p&gt;
    
    </summary>
    
    
      <category term="git" scheme="https://xijunlee.github.io/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>爬虫练手(一)：爬下新浪爱问所有问题！</title>
    <link href="https://xijunlee.github.io/2017/02/16/%E7%88%AC%E8%99%AB%E7%BB%83%E6%89%8B%E4%B8%80%EF%BC%9A%E7%88%AC%E4%B8%8B%E6%96%B0%E6%B5%AA%E7%88%B1%E9%97%AE%E6%89%80%E6%9C%89%E9%97%AE%E9%A2%98%EF%BC%81/"/>
    <id>https://xijunlee.github.io/2017/02/16/爬虫练手一：爬下新浪爱问所有问题！/</id>
    <published>2017-02-16T07:33:43.000Z</published>
    <updated>2017-02-16T08:42:20.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>老早就想写爬虫了，只奈何以前总是空有一颗写爬虫的心。很多事情不可能全部都准备好才动手做，而是在边做的过程中边学。看着<a href="http://cuiqingcai.com/1052.html" target="_blank" rel="external">大神的博客</a>，学了五天，写了几个小demo，遂准备自己动手从头写一个爬虫来练手。这篇博文不是教程，相当于一个<code>readme</code>文档吧。</p>
<h2 id="爬的对象-–-新浪爱问"><a href="#爬的对象-–-新浪爱问" class="headerlink" title="爬的对象 – 新浪爱问"></a>爬的对象 – 新浪爱问</h2><p>选择<a href="http://iask.sina.com.cn" target="_blank" rel="external">新浪爱问</a>作为爬虫对象的原因如下：</p>
<ol>
<li>大神博客中虽然有对该网站爬的教程，但是因为网站改版了，大神的正则表达式代码失效，很多读者都在求代码。既然没人来做，那就我来做好了；</li>
<li>这个网站比较简单，不需要密码登录验证，不反爬虫。这对于我这么一个爬虫新手，是相当友好的练手对象。</li>
</ol>
<a id="more"></a>
<h2 id="爬的目标"><a href="#爬的目标" class="headerlink" title="爬的目标"></a>爬的目标</h2><p>爱问某一个专题下所有问题，以及问题下的最佳答案（当然，有的问题也可能没有最佳答案）</p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>我是用<code>python</code>实现的这个爬虫（人生苦短，我用python。实现起来真是高效到没朋友）</p>
<h3 id="需要挖掘的部分"><a href="#需要挖掘的部分" class="headerlink" title="需要挖掘的部分"></a>需要挖掘的部分</h3><img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/iask_spider/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-02-16%2015.56.22.png">
<p>从上图可以看出，我必须要挖出来的有两部分：<code>每一页的链接</code>，<code>每一页的所有问题</code>。进一步延伸，在爬下每一页的某一个问题后，要进入该问题详情页面中将最佳答案的内容爬下来。</p>
<h3 id="使用的库"><a href="#使用的库" class="headerlink" title="使用的库"></a>使用的库</h3><ol>
<li><p><code>urllib</code> &amp; <code>urllib2</code> – 这两个库是用来访问网页获得网页源码的，具体使用方法见最后的代码或者官方文档。</p>
</li>
<li><p><code>re</code> &amp; <code>bs4</code> – 这两个库用来解析网页源码，挖出我所需要的<code>每一页的链接</code>，<code>每一页的所有问题</code></p>
</li>
</ol>
<h3 id="具体实现的几个重要函数"><a href="#具体实现的几个重要函数" class="headerlink" title="具体实现的几个重要函数"></a>具体实现的几个重要函数</h3><p>一、获得网页源码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#传入url，获取该页的代码</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getPage</span><span class="params">(self,pageStr)</span>:</span></div><div class="line"></div><div class="line">   	<span class="keyword">try</span>:</div><div class="line">      		url = self.baseURL + pageStr</div><div class="line">       	request = urllib2.Request(url)</div><div class="line">       	response = urllib2.urlopen(request)</div><div class="line">       	<span class="keyword">return</span> response</div><div class="line">   	<span class="keyword">except</span> urllib2.URLError, e:</div><div class="line">       	<span class="keyword">if</span> hasattr(e,<span class="string">"reason"</span>):</div><div class="line">        		<span class="keyword">print</span> <span class="string">u"连接新浪爱问失败,错误原因"</span>,e.reason</div><div class="line">           	<span class="keyword">return</span> <span class="keyword">None</span></div></pre></td></tr></table></figure>
<p>上述代码中，<code>baseURL</code>是新浪爱问的基地址，需要初始化实例的过程中传入，<code>pageStr</code>是待访问页面的定位符。<code>baseURL+pageStr</code>即为页面最终的网址。我之所以这么做，是因为该网站下所有网页都是有一个相同的基地址<code>baseURL</code>，而不同的专题页面都有不同的定位符<code>pageStr</code>。</p>
<p>二、解析网页源码中的链接</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getContent</span><span class="params">(self)</span>:</span></div><div class="line"></div><div class="line">   	<span class="comment">#获得起始页的源码</span></div><div class="line">   	</div><div class="line">   	<span class="comment">#page = self.getPage(self.startPage).read().decode("utf-8")</span></div><div class="line">   	page = self.getPage(self.startPage).read()</div><div class="line">   	<span class="comment">#pdb.set_trace()</span></div><div class="line"></div><div class="line">   	<span class="comment">#获得1-100页的源码</span></div><div class="line">   	<span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,self.endNum):</div><div class="line">   		<span class="keyword">print</span> (<span class="string">"正在获得第%d页的源码..."</span> %(i))</div><div class="line">   		self.file.write(<span class="string">"第%d页的问题\n"</span> %(i))</div><div class="line">   		<span class="comment">#解析当前页源码</span></div><div class="line">   		soup = BeautifulSoup(page,<span class="string">"lxml"</span>)</div><div class="line">   		<span class="comment">#获得当前页的地址</span></div><div class="line">   		current = soup.find(<span class="string">"a"</span>, string=i)</div><div class="line">   		<span class="comment">#获得当前页的问题</span></div><div class="line">   		questions = soup.find_all(<span class="string">'div'</span>, class_=<span class="string">'question-title'</span>)</div><div class="line">   		<span class="comment">#处理当前页的问题</span></div><div class="line">   		<span class="keyword">print</span> (<span class="string">"正在处理第%d页的问题..."</span> %(i))</div><div class="line">   		self.handleQuestions(questions)</div><div class="line">   		</div><div class="line">   		<span class="comment">#处理完当前页，跳到下一页</span></div><div class="line">   		page = self.getPage(current[<span class="string">'href'</span>]).read()</div><div class="line">   		</div><div class="line">   	self.file.close()</div></pre></td></tr></table></figure>
<p>我利用<code>beautiful soup</code>来帮助解析获得当前页的链接，这个需要观察网页源码的代码特征，才能利用<code>beautiful soup</code>完成这一工作。</p>
<p>三、解析网页源码中的问题内容以及可能的最佳答案</p>
<p>前面已经利用<code>beautiful soup</code>提取出网页中的问题，现在进入问题详情页面，利用正则表达式来提取出网页源码中的问题内容和可能的最佳答案。说具题外话虽然是匹配出来了，但是我觉着我对正则表达式的理解还是很浅，还是需要多练。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">handleQuestions</span><span class="params">(self,questions)</span>:</span></div><div class="line"></div><div class="line">   	<span class="comment">#处理questions中的每一个question</span></div><div class="line">   	<span class="keyword">for</span> question <span class="keyword">in</span> questions:</div><div class="line">   			<span class="keyword">for</span> a <span class="keyword">in</span> question.children:</div><div class="line">   				aString = str(a).strip()</div><div class="line">   				pattern = re.compile(<span class="string">'&lt;a href="(.*?)".*?&gt;(.*?)&lt;/a&gt;'</span>,re.S)</div><div class="line">   				check = re.search(pattern,aString)</div><div class="line">   				<span class="keyword">if</span> check:</div><div class="line">   					items = re.findall(pattern,aString)</div><div class="line">   					<span class="comment">#获得问题详情链接和问题内容</span></div><div class="line">   					item = items[<span class="number">0</span>]</div><div class="line">   					href = item[<span class="number">0</span>]</div><div class="line">   					questionStr = item[<span class="number">1</span>]</div><div class="line">   					</div><div class="line">   					ansPage = self.getPage(href).read()</div><div class="line">   					ansStr = self.getAnswer(ansPage)</div><div class="line"></div><div class="line">   					self.file.write(<span class="string">"Q:"</span>+questionStr+<span class="string">"\n"</span>)</div><div class="line">   					self.file.write(<span class="string">"A:"</span>+ansStr+<span class="string">"\n\n"</span>)</div><div class="line">   				</div><div class="line"></div><div class="line">   <span class="function"><span class="keyword">def</span> <span class="title">getAnswer</span><span class="params">(self,page)</span>:</span></div><div class="line">   	pattern = re.compile(<span class="string">'&lt;div class="good_answer.*?&lt;div&gt;.*?&lt;span&gt;(.*?)&lt;/span&gt;'</span>,re.S)</div><div class="line">   	check = re.search(pattern,page)</div><div class="line">   	ansStr = <span class="string">''</span></div><div class="line">   	<span class="keyword">if</span> check:</div><div class="line">   		items = re.findall(pattern,page)</div><div class="line">   		ansStr = self.formatTool.replace(items[<span class="number">0</span>])</div><div class="line">   	</div><div class="line">   	<span class="keyword">return</span> ansStr</div></pre></td></tr></table></figure>
<p>四、格式处理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">FormatTool</span>:</span></div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line"></div><div class="line">		self.removeIMG = re.compile(<span class="string">'&lt;img.*?&gt;'</span>,re.S)</div><div class="line">		self.removeBR = re.compile(<span class="string">'&lt;br&gt;|&lt;br/&gt;'</span>,re.S)</div><div class="line">		self.removeBP = re.compile(<span class="string">' &#123;7&#125;'</span>,re.S)</div><div class="line">		self.removeLink = re.compile(<span class="string">'&lt;a.*?&gt;.*?&lt;/a&gt;'</span>,re.S)</div><div class="line">		self.removeDIV = re.compile(<span class="string">'&lt;div.*?&gt;.*?&lt;/div&gt;'</span>,re.S)</div><div class="line">		self.removePre1 = re.compile(<span class="string">'&lt;pre&gt;'</span>,re.S)</div><div class="line">		self.removePre2 = re.compile(<span class="string">'&lt;/pre&gt;'</span>,re.S)</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">replace</span><span class="params">(self,content)</span>:</span></div><div class="line"></div><div class="line">		content = re.sub(self.removeBR,<span class="string">"\n"</span>,content)</div><div class="line">		content = re.sub(self.removeLink,<span class="string">""</span>,content)</div><div class="line">		content = re.sub(self.removeDIV,<span class="string">""</span>,content)</div><div class="line">		content = re.sub(self.removePre1,<span class="string">""</span>,content)</div><div class="line">		content = re.sub(self.removePre2,<span class="string">""</span>,content)</div><div class="line"></div><div class="line">		<span class="keyword">return</span> content.strip()</div></pre></td></tr></table></figure>
<p>前面利用正则表达式匹配出的问题内容和答案中，可能还会存在一些链接和图片的代码，需要再次利用正则表达式来剔除，使格式变得更好看。</p>
<h2 id="代码以及部分结果"><a href="#代码以及部分结果" class="headerlink" title="代码以及部分结果"></a>代码以及部分结果</h2><p>我挖到的结果部分展示如下:(<a href="https://github.com/xijunlee/PythonSpider/blob/master/iask_question_and_answer.txt" target="_blank" rel="external">完整结果戳这里，虽然应该是没什么卵用</a>)</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line">第<span class="number">1</span>页的问题</div><div class="line">Q:怎样下载真实的宜聚网</div><div class="line">A:可以去官网、V信或者APP Store。</div><div class="line"></div><div class="line">Q:请问深圳超算中心测试云的信息评测主要包括哪些呢？</div><div class="line">A:主要包括业主方项目验收；</div><div class="line">基金项目验收；</div><div class="line">科研项目验收；</div><div class="line">全流程测试；</div><div class="line">系统安全检查；</div><div class="line">系统性能测试</div><div class="line"></div><div class="line">Q:宜聚网和钻库网谁更出色</div><div class="line">A:宜聚网是专注车贷的，所以我觉得它可能好一点，实物抵押安全性高，加上收益也还不错。</div><div class="line"></div><div class="line">Q:有人了解现在的一元云购平台吗？那个比较好呢？</div><div class="line">A:星喜夺宝很好，这是由深圳市星喜夺宝网络科技有限公司注入巨资打造的新型购物平台，实力非常的雄厚，提供的奖品非常的丰富高端。</div><div class="line"></div><div class="line">Q: 	WILO威乐天猫有他们的旗舰店吗？ </div><div class="line">A:有的有促销活动呢  </div><div class="line"></div><div class="line"></div><div class="line">...</div><div class="line"></div><div class="line">Q:听朋友说vipabc在网上注册就会送很多好东西？</div><div class="line">真的吗？现在还有这种活动吗？ </div><div class="line">A:vipabc经常会搞一些这类活动，只要在网上报名，免费试听一节体验课程，就有机会获得各种奖品，让大家一边了解vipabc的教学模式，一边还能获得更多奖品和实惠，一举多得。</div><div class="line"></div><div class="line">Q:长城厨电和长城电脑的关系，你们知道吗？</div><div class="line">A:关系很简单，就是都属于用长城这个民族品牌的国有控股企业，家里的燃气灶就是长城厨电的产品，真的是很好用。 </div><div class="line"></div><div class="line">....</div><div class="line"></div><div class="line">Q:Html5 Canvas是做什么的，清除屏幕可以做吗?</div><div class="line">A:“在粤嵌的学习中，我们需要清除部分或者全部的屏幕，类似于j2me的setcilp函数，在html </div><div class="line">canvas中有两种方法可以清除屏幕，一种是clearRect和整个屏幕宽度高度技巧。不同的是clearRect可以实现部分的屏幕的清除也可以实现清除全屏的方法，而重设屏幕宽高只能清除部分的屏幕。“ </div><div class="line"></div><div class="line">....</div></pre></td></tr></table></figure>
<p>最后还是采用面向对象的编程风格整理了所有实现代码，如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python</span></div><div class="line"><span class="comment"># coding=utf-8</span></div><div class="line"><span class="keyword">import</span> urllib</div><div class="line"><span class="keyword">import</span> urllib2</div><div class="line"><span class="keyword">import</span> re</div><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</div><div class="line"><span class="keyword">import</span> pdb</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">IASKSpider</span>:</span></div><div class="line"> </div><div class="line">    <span class="comment">#初始化，传入基地址和开始页</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,baseUrl,startPage,endNum)</span>:</span></div><div class="line"></div><div class="line">        self.baseURL = baseUrl</div><div class="line">        self.startPage = startPage</div><div class="line">        self.formatTool = FormatTool()</div><div class="line">   </div><div class="line">        self.endNum = endNum</div><div class="line">        self.file = open(<span class="string">"iask_question_and_answer.txt"</span>,<span class="string">'w+'</span>)</div><div class="line"></div><div class="line">    <span class="comment">#传入url，获取该页的代码</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getPage</span><span class="params">(self,pageStr)</span>:</span></div><div class="line"></div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            url = self.baseURL + pageStr</div><div class="line">            request = urllib2.Request(url)</div><div class="line">            response = urllib2.urlopen(request)</div><div class="line">            <span class="comment">#print response.read()</span></div><div class="line">            <span class="keyword">return</span> response</div><div class="line">        <span class="keyword">except</span> urllib2.URLError, e:</div><div class="line">            <span class="keyword">if</span> hasattr(e,<span class="string">"reason"</span>):</div><div class="line">                <span class="keyword">print</span> <span class="string">u"连接新浪爱问失败,错误原因"</span>,e.reason</div><div class="line">                <span class="keyword">return</span> <span class="keyword">None</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getContent</span><span class="params">(self)</span>:</span></div><div class="line"></div><div class="line">    	<span class="comment">#获得起始页的源码</span></div><div class="line">    	</div><div class="line">    	<span class="comment">#page = self.getPage(self.startPage).read().decode("utf-8")</span></div><div class="line">    	page = self.getPage(self.startPage).read()</div><div class="line">    	<span class="comment">#pdb.set_trace()</span></div><div class="line"></div><div class="line">    	<span class="comment">#获得1-100页的源码</span></div><div class="line">    	<span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,self.endNum):</div><div class="line">    		<span class="keyword">print</span> (<span class="string">"正在获得第%d页的源码..."</span> %(i))</div><div class="line">    		self.file.write(<span class="string">"第%d页的问题\n"</span> %(i))</div><div class="line">    		<span class="comment">#解析当前页源码</span></div><div class="line">    		soup = BeautifulSoup(page,<span class="string">"lxml"</span>)</div><div class="line">    		<span class="comment">#获得当前页的地址</span></div><div class="line">    		current = soup.find(<span class="string">"a"</span>, string=i)</div><div class="line">    		<span class="comment">#获得当前页的问题</span></div><div class="line">    		questions = soup.find_all(<span class="string">'div'</span>, class_=<span class="string">'question-title'</span>)</div><div class="line">    		<span class="comment">#处理当前页的问题</span></div><div class="line">    		<span class="keyword">print</span> (<span class="string">"正在处理第%d页的问题..."</span> %(i))</div><div class="line">    		self.handleQuestions(questions)</div><div class="line">    		</div><div class="line">    		<span class="comment">#处理完当前页，跳到下一页</span></div><div class="line">    		page = self.getPage(current[<span class="string">'href'</span>]).read()</div><div class="line">    		</div><div class="line">    	self.file.close()</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">handleQuestions</span><span class="params">(self,questions)</span>:</span></div><div class="line"></div><div class="line">    	<span class="comment">#处理questions中的每一个question</span></div><div class="line">    	<span class="keyword">for</span> question <span class="keyword">in</span> questions:</div><div class="line">    			<span class="keyword">for</span> a <span class="keyword">in</span> question.children:</div><div class="line">    				aString = str(a).strip()</div><div class="line">    				pattern = re.compile(<span class="string">'&lt;a href="(.*?)".*?&gt;(.*?)&lt;/a&gt;'</span>,re.S)</div><div class="line">    				check = re.search(pattern,aString)</div><div class="line">    				<span class="keyword">if</span> check:</div><div class="line">    					items = re.findall(pattern,aString)</div><div class="line">    					<span class="comment">#获得问题详情链接和问题内容</span></div><div class="line">    					item = items[<span class="number">0</span>]</div><div class="line">    					href = item[<span class="number">0</span>]</div><div class="line">    					questionStr = item[<span class="number">1</span>]</div><div class="line">    					</div><div class="line">    					ansPage = self.getPage(href).read()</div><div class="line">    					ansStr = self.getAnswer(ansPage)</div><div class="line"></div><div class="line">    					self.file.write(<span class="string">"Q:"</span>+questionStr+<span class="string">"\n"</span>)</div><div class="line">    					self.file.write(<span class="string">"A:"</span>+ansStr+<span class="string">"\n\n"</span>)</div><div class="line">    				</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getAnswer</span><span class="params">(self,page)</span>:</span></div><div class="line">    	pattern = re.compile(<span class="string">'&lt;div class="good_answer.*?&lt;div&gt;.*?&lt;span&gt;(.*?)&lt;/span&gt;'</span>,re.S)</div><div class="line">    	check = re.search(pattern,page)</div><div class="line">    	ansStr = <span class="string">''</span></div><div class="line">    	<span class="keyword">if</span> check:</div><div class="line">    		items = re.findall(pattern,page)</div><div class="line">    		ansStr = self.formatTool.replace(items[<span class="number">0</span>])</div><div class="line">    	</div><div class="line">    	<span class="keyword">return</span> ansStr</div><div class="line"></div><div class="line">   </div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">FormatTool</span>:</span></div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line"></div><div class="line">		self.removeIMG = re.compile(<span class="string">'&lt;img.*?&gt;'</span>,re.S)</div><div class="line">		self.removeBR = re.compile(<span class="string">'&lt;br&gt;|&lt;br/&gt;'</span>,re.S)</div><div class="line">		self.removeBP = re.compile(<span class="string">' &#123;7&#125;'</span>,re.S)</div><div class="line">		self.removeLink = re.compile(<span class="string">'&lt;a.*?&gt;.*?&lt;/a&gt;'</span>,re.S)</div><div class="line">		self.removeDIV = re.compile(<span class="string">'&lt;div.*?&gt;.*?&lt;/div&gt;'</span>,re.S)</div><div class="line">		self.removePre1 = re.compile(<span class="string">'&lt;pre&gt;'</span>,re.S)</div><div class="line">		self.removePre2 = re.compile(<span class="string">'&lt;/pre&gt;'</span>,re.S)</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">replace</span><span class="params">(self,content)</span>:</span></div><div class="line"></div><div class="line">		content = re.sub(self.removeBR,<span class="string">"\n"</span>,content)</div><div class="line">		content = re.sub(self.removeLink,<span class="string">""</span>,content)</div><div class="line">		content = re.sub(self.removeDIV,<span class="string">""</span>,content)</div><div class="line">		content = re.sub(self.removePre1,<span class="string">""</span>,content)</div><div class="line">		content = re.sub(self.removePre2,<span class="string">""</span>,content)</div><div class="line"></div><div class="line">		<span class="keyword">return</span> content.strip()</div><div class="line"> </div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line"></div><div class="line">	baseURL = <span class="string">'http://iask.sina.com.cn'</span></div><div class="line">	startPage = <span class="string">'/c/74-all-1-new.html'</span></div><div class="line">	iaskSpider = IASKSpider(baseURL,startPage,<span class="number">101</span>)</div><div class="line">	iaskSpider.getContent()</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h2&gt;&lt;p&gt;老早就想写爬虫了，只奈何以前总是空有一颗写爬虫的心。很多事情不可能全部都准备好才动手做，而是在边做的过程中边学。看着&lt;a href=&quot;http://cuiqingcai.com/1052.html&quot;&gt;大神的博客&lt;/a&gt;，学了五天，写了几个小demo，遂准备自己动手从头写一个爬虫来练手。这篇博文不是教程，相当于一个&lt;code&gt;readme&lt;/code&gt;文档吧。&lt;/p&gt;
&lt;h2 id=&quot;爬的对象-–-新浪爱问&quot;&gt;&lt;a href=&quot;#爬的对象-–-新浪爱问&quot; class=&quot;headerlink&quot; title=&quot;爬的对象 – 新浪爱问&quot;&gt;&lt;/a&gt;爬的对象 – 新浪爱问&lt;/h2&gt;&lt;p&gt;选择&lt;a href=&quot;http://iask.sina.com.cn&quot;&gt;新浪爱问&lt;/a&gt;作为爬虫对象的原因如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;大神博客中虽然有对该网站爬的教程，但是因为网站改版了，大神的正则表达式代码失效，很多读者都在求代码。既然没人来做，那就我来做好了；&lt;/li&gt;
&lt;li&gt;这个网站比较简单，不需要密码登录验证，不反爬虫。这对于我这么一个爬虫新手，是相当友好的练手对象。&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="spider" scheme="https://xijunlee.github.io/tags/spider/"/>
    
  </entry>
  
  <entry>
    <title>python虚拟环境安装与使用(转)</title>
    <link href="https://xijunlee.github.io/2017/02/10/python%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/"/>
    <id>https://xijunlee.github.io/2017/02/10/python虚拟环境安装与使用/</id>
    <published>2017-02-10T03:15:15.000Z</published>
    <updated>2017-02-13T13:39:27.000Z</updated>
    
    <content type="html"><![CDATA[<p>在开发<code>Python</code>应用程序的时候，系统安装的<code>Python3</code>只有一个版本：3.4。所有第三方的包都会被<code>pip</code>安装到<code>Python3</code>的<code>site-packages</code>目录下。</p>
<p>如果我们要同时开发多个应用程序，那这些应用程序都会共用一个<code>Python</code>，就是安装在系统的Python 3。如果应用A需要<code>jinja 2.7</code>，而应用B需要<code>jinja 2.6</code>怎么办？</p>
<p>这种情况下，每个应用可能需要各自拥有一套“独立”的<code>Python</code>运行环境。<code>virtualenv</code>就是用来为一个应用创建一套“隔离”的<code>Python</code>运行环境。</p>
<p>首先，我们用<code>pip</code>安装<code>virtualenv</code>：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ pip3 install virtualenv</div></pre></td></tr></table></figure>
<a id="more"></a>
<p>然后，假定我们要开发一个新的项目，需要一套独立的Python运行环境，可以这么做：</p>
<p>第一步，创建目录：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Mac:~ michael$ mkdir myproject</div><div class="line">Mac:~ michael$ <span class="built_in">cd</span> myproject/</div><div class="line">Mac:myproject michael$</div></pre></td></tr></table></figure>
<p>第二步，创建一个独立的<code>Python</code>运行环境，命名为<code>venv</code>：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Mac:myproject michael$ virtualenv --no-site-packages venv</div><div class="line">Using base prefix <span class="string">'/usr/local/.../Python.framework/Versions/3.4'</span>New python executable <span class="keyword">in</span> venv/bin/python3.4Also creating executable <span class="keyword">in</span> venv/bin/python</div><div class="line">Installing setuptools, pip, wheel...done.</div></pre></td></tr></table></figure>
<p>命令<code>virtualenv</code>就可以创建一个独立的<code>Python</code>运行环境，我们还加上了参数<code>--no-site-packages</code>，这样，已经安装到系统Python环境中的所有第三方包都不会复制过来，这样，我们就得到了一个不带任何第三方包的“干净”的<code>Python</code>运行环境。</p>
<p>新建的<code>Python</code>环境被放到当前目录下的<code>venv</code>目录。有了<code>venv</code>这个<code>Python</code>环境，可以用<code>source</code>进入该环境：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Mac:myproject michael$ <span class="built_in">source</span> venv/bin/activate</div><div class="line">(venv)Mac:myproject michael$</div></pre></td></tr></table></figure>
<p>注意到命令提示符变了，有个<code>(venv)</code>前缀，表示当前环境是一个名为<code>venv</code>的<code>Python</code>环境。</p>
<p>下面正常安装各种第三方包，并运行<code>python</code>命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">(venv)Mac:myproject michael$ pip install jinja2</div><div class="line">...</div><div class="line">Successfully installed jinja2-2.7.3 markupsafe-0.23</div><div class="line">(venv)Mac:myproject michael$ python myapp.py</div><div class="line">...</div></pre></td></tr></table></figure>
<p>在<code>venv</code>环境下，用<code>pip</code>安装的包都被安装到<code>venv</code>这个环境下，系统<code>Python</code>环境不受任何影响。也就是说，<code>venv</code>环境是专门针对myproject这个应用创建的。</p>
<p>退出当前的<code>venv</code>环境，使用<code>deactivate</code>命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">(venv)Mac:myproject michael$ deactivate </div><div class="line">Mac:myproject michael$</div></pre></td></tr></table></figure>
<p>此时就回到了正常的环境，现在pip或python均是在系统Python环境下执行。</p>
<p>完全可以针对每个应用创建独立的Python运行环境，这样就可以对每个应用的Python环境进行隔离。</p>
<p>virtualenv是如何创建“独立”的Python运行环境的呢？原理很简单，就是把系统Python复制一份到virtualenv的环境，用命令<code>source venv/bin/activate</code>进入一个virtualenv环境时，virtualenv会修改相关环境变量，让命令<code>python</code>和<code>pip</code>均指向当前的virtualenv环境。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>virtualenv为应用提供了隔离的Python运行环境，解决了不同应用间多版本的冲突问题。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在开发&lt;code&gt;Python&lt;/code&gt;应用程序的时候，系统安装的&lt;code&gt;Python3&lt;/code&gt;只有一个版本：3.4。所有第三方的包都会被&lt;code&gt;pip&lt;/code&gt;安装到&lt;code&gt;Python3&lt;/code&gt;的&lt;code&gt;site-packages&lt;/code&gt;目录下。&lt;/p&gt;
&lt;p&gt;如果我们要同时开发多个应用程序，那这些应用程序都会共用一个&lt;code&gt;Python&lt;/code&gt;，就是安装在系统的Python 3。如果应用A需要&lt;code&gt;jinja 2.7&lt;/code&gt;，而应用B需要&lt;code&gt;jinja 2.6&lt;/code&gt;怎么办？&lt;/p&gt;
&lt;p&gt;这种情况下，每个应用可能需要各自拥有一套“独立”的&lt;code&gt;Python&lt;/code&gt;运行环境。&lt;code&gt;virtualenv&lt;/code&gt;就是用来为一个应用创建一套“隔离”的&lt;code&gt;Python&lt;/code&gt;运行环境。&lt;/p&gt;
&lt;p&gt;首先，我们用&lt;code&gt;pip&lt;/code&gt;安装&lt;code&gt;virtualenv&lt;/code&gt;：&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;$ pip3 install virtualenv&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="python virtual environment" scheme="https://xijunlee.github.io/tags/python-virtual-environment/"/>
    
  </entry>
  
  <entry>
    <title>linux下杀死进程（kill）的N种方法(转)</title>
    <link href="https://xijunlee.github.io/2017/02/05/linux%E4%B8%8B%E6%9D%80%E6%AD%BB%E8%BF%9B%E7%A8%8B%EF%BC%88kill%EF%BC%89%E7%9A%84N%E7%A7%8D%E6%96%B9%E6%B3%95/"/>
    <id>https://xijunlee.github.io/2017/02/05/linux下杀死进程（kill）的N种方法/</id>
    <published>2017-02-05T12:39:52.000Z</published>
    <updated>2017-02-10T03:21:37.000Z</updated>
    
    <content type="html"><![CDATA[<p>首先说明这是转载的，作为笔记整理成下文。</p>
<h2 id="常规篇："><a href="#常规篇：" class="headerlink" title="常规篇："></a>常规篇：</h2><p>首先，用ps查看进程，方法如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ ps -ef</div></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">……</div><div class="line">smx       1822     1  0 11:38 ?        00:00:49 gnome-terminal</div><div class="line">smx       1823  1822  0 11:38 ?        00:00:00 gnome-pty-helper</div><div class="line">smx       1824  1822  0 11:38 pts/0    00:00:02 bash</div><div class="line">smx       1827     1  4 11:38 ?        00:26:28 /usr/lib/firefox-3.6.18/firefox-bin</div><div class="line">smx       1857  1822  0 11:38 pts/1    00:00:00 bash</div><div class="line">smx       1880  1619  0 11:38 ?        00:00:00 update-notifier</div><div class="line">……</div><div class="line">smx      11946  1824  0 21:41 pts/0    00:00:00 ps -ef</div></pre></td></tr></table></figure>
<a id="more"></a>
<p>或者：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ ps -aux</div></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">……</div><div class="line"></div><div class="line">smx       1822  0.1  0.8  58484 18152 ?        Sl   11:38   0:49 gnome-terminal</div><div class="line">smx       1823  0.0  0.0   1988   712 ?        S    11:38   0:00 gnome-pty-helper</div><div class="line">smx       1824  0.0  0.1   6820  3776 pts/0    Ss   11:38   0:02 bash</div><div class="line">smx       1827  4.3  5.8 398196 119568 ?       Sl   11:38  26:13 /usr/lib/firefox-3.6.18/firefox-bin</div><div class="line">smx       1857  0.0  0.1   6688  3644 pts/1    Ss   11:38   0:00 bash</div><div class="line">smx       1880  0.0  0.6  41536 12620 ?        S    11:38   0:00 update-notifier</div><div class="line">……</div><div class="line">smx      11953  0.0  0.0   2716  1064 pts/0    R+   21:42   0:00 ps -aux</div></pre></td></tr></table></figure>
<p>此时如果我想杀了火狐的进程就在终端输入：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ <span class="built_in">kill</span> <span class="_">-s</span> 9 1827</div></pre></td></tr></table></figure>
<p>其中<code>-s 9</code> 制定了传递给进程的信号是９，即强制、尽快终止进程。</p>
<p>1827则是上面ps查到的火狐的PID。</p>
<p>简单吧，但有个问题，进程少了则无所谓，进程多了，就会觉得痛苦了，无论是<code>ps -ef</code> 还是<code>ps -aux</code>，每次都要在一大串进程信息里面查找到要杀的进程，看的眼都花了。</p>
<h2 id="进阶篇："><a href="#进阶篇：" class="headerlink" title="进阶篇："></a>进阶篇：</h2><h3 id="改进１："><a href="#改进１：" class="headerlink" title="改进１："></a>改进１：</h3><p>把ps的查询结果通过管道给grep查找包含特定字符串的进程。管道符“|”用来隔开两个命令，管道符左边命令的输出会作为管道符右边命令的输入。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ ps -ef | grep firefox</div><div class="line">smx       1827     1  4 11:38 ?        00:27:33 /usr/lib/firefox-3.6.18/firefox-bin</div><div class="line">smx      12029  1824  0 21:54 pts/0    00:00:00 grep --color=auto firefox</div></pre></td></tr></table></figure>
<p>这次就清爽了。然后就是</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$kill</span> <span class="_">-s</span> 9 1827</div></pre></td></tr></table></figure>
<p>还是嫌打字多？</p>
<h3 id="改进２——使用pgrep："><a href="#改进２——使用pgrep：" class="headerlink" title="改进２——使用pgrep："></a>改进２——使用pgrep：</h3><p>一看到pgrep首先会想到什么？没错，grep！pgrep的p表明了这个命令是专门用于进程查询的grep。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ pgrep firefox</div><div class="line">1827</div></pre></td></tr></table></figure>
<p>看到了什么？没错火狐的PID，接下来又要打字了：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$kill</span> <span class="_">-s</span> 9 1827</div></pre></td></tr></table></figure>
<h3 id="改进３——使用pidof："><a href="#改进３——使用pidof：" class="headerlink" title="改进３——使用pidof："></a>改进３——使用pidof：</h3><p>看到pidof想到啥？没错pid of xx，字面翻译过来就是 xx的PID。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ pidof firefox-bin</div><div class="line">1827</div></pre></td></tr></table></figure>
<p>和pgrep相比稍显不足的是，pidof必须给出进程的全名。然后就是老生常谈：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$kill</span> <span class="_">-s</span> 9 1827</div></pre></td></tr></table></figure>
<p>无论使用ps 然后慢慢查找进程PID 还是用grep查找包含相应字符串的进程，亦或者用pgrep直接查找包含相应字符串的进程ＰＩＤ，然后手动输入给ｋｉｌｌ杀掉，都稍显麻烦。有没有更方便的方法？有！</p>
<h3 id="改进４："><a href="#改进４：" class="headerlink" title="改进４："></a>改进４：</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$ps</span> -ef | grep firefox | grep -v grep | cut -c 9-15 | xargs <span class="built_in">kill</span> <span class="_">-s</span> 9</div></pre></td></tr></table></figure>
<p>说明：</p>
<p><code>grep firefox</code>的输出结果是，所有含有关键字<code>firefox</code>的进程。</p>
<p><code>grep -v grep</code>是在列出的进程中去除含有关键字<code>grep</code>的进程。</p>
<p><code>cut -c 9-15</code>是截取输入行的第9个字符到第15个字符，而这正好是进程号PID。</p>
<p><code>xargs kill -s 9</code>中的xargs命令是用来把前面命令的输出结果（PID）作为<code>kill -s 9</code>命令的参数，并执行该命令。<code>kill -s 9</code>会强行杀掉指定进程。</p>
<p>难道你不想抱怨点什么？没错太长了</p>
<h3 id="改进５："><a href="#改进５：" class="headerlink" title="改进５："></a>改进５：</h3><p>知道pgrep和pidof两个命令，干嘛还要打那么长一串！</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ pgrep firefox | xargs <span class="built_in">kill</span> <span class="_">-s</span> 9</div></pre></td></tr></table></figure>
<h3 id="改进６："><a href="#改进６：" class="headerlink" title="改进６："></a>改进６：</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ ps -ef | grep firefox | awk <span class="string">'&#123;print $2&#125;'</span> | xargs <span class="built_in">kill</span> -9</div><div class="line"><span class="built_in">kill</span>: No such process</div></pre></td></tr></table></figure>
<p>有一个比较郁闷的地方，进程已经正确找到并且终止了，但是执行完却提示找不到进程。</p>
<p>其中<code>awk &#39;{print $2}&#39;</code> 的作用就是打印（print）出第二列的内容。根据常规篇，可以知道ps输出的第二列正好是PID。就把进程相应的PID通过xargs传递给kill作参数，杀掉对应的进程。</p>
<h3 id="改进７："><a href="#改进７：" class="headerlink" title="改进７："></a>改进７：</h3><p>难道每次都要调用xargs把PID传递给kill？答案是否定的：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$kill</span> <span class="_">-s</span> 9 `ps -aux | grep firefox | awk <span class="string">'&#123;print $2&#125;'</span>`</div></pre></td></tr></table></figure>
<h3 id="改进８："><a href="#改进８：" class="headerlink" title="改进８："></a>改进８：</h3><p>没错，命令依然有点长，换成pgrep。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$kill</span> <span class="_">-s</span> 9 `pgrep firefox`</div></pre></td></tr></table></figure>
<h3 id="改进9——pkill："><a href="#改进9——pkill：" class="headerlink" title="改进9——pkill："></a>改进9——pkill：</h3><p>看到pkill想到了什么？没错pgrep和kill！pkill＝pgrep+kill。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$pkill</span> -９ firefox</div></pre></td></tr></table></figure>
<p>说明：”-9” 即发送的信号是9，pkill与kill在这点的差别是：pkill无须 “ｓ”，终止信号等级直接跟在 “-“ 后面。之前我一直以为是 “-s 9”，结果每次运行都无法终止进程。</p>
<h3 id="改进10——killall："><a href="#改进10——killall：" class="headerlink" title="改进10——killall："></a>改进10——killall：</h3><p>killall和pkill是相似的,不过如果给出的进程名不完整，killall会报错。pkill或者pgrep只要给出进程名的一部分就可以终止进程。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$killall</span> -9 firefox</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;首先说明这是转载的，作为笔记整理成下文。&lt;/p&gt;
&lt;h2 id=&quot;常规篇：&quot;&gt;&lt;a href=&quot;#常规篇：&quot; class=&quot;headerlink&quot; title=&quot;常规篇：&quot;&gt;&lt;/a&gt;常规篇：&lt;/h2&gt;&lt;p&gt;首先，用ps查看进程，方法如下：&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;$ ps -ef&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;……&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;smx       1822     1  0 11:38 ?        00:00:49 gnome-terminal&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;smx       1823  1822  0 11:38 ?        00:00:00 gnome-pty-helper&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;smx       1824  1822  0 11:38 pts/0    00:00:02 bash&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;smx       1827     1  4 11:38 ?        00:26:28 /usr/lib/firefox-3.6.18/firefox-bin&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;smx       1857  1822  0 11:38 pts/1    00:00:00 bash&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;smx       1880  1619  0 11:38 ?        00:00:00 update-notifier&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;……&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;smx      11946  1824  0 21:41 pts/0    00:00:00 ps -ef&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="linux" scheme="https://xijunlee.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>2016年度总结</title>
    <link href="https://xijunlee.github.io/2017/01/24/2016%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"/>
    <id>https://xijunlee.github.io/2017/01/24/2016年度总结/</id>
    <published>2017-01-24T08:06:28.000Z</published>
    <updated>2017-01-24T07:22:42.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>本来该篇应该在<code>2017-1-1</code>写出来的，但那时和高中老友在杭州玩😂，回上海后也忘了这茬，所以拖到了现在。虽然现在已经公历<code>2017-1-24</code>，但是标题还是取成“2016年度总结”，因为从农历看的话，现在还没有到2017嘛。之前还从未写过年度总结，所以这篇2016年度总结顺带也总结一下2015。之所以想写年度总结，其实也是受到师兄师姐的启发，梳理和盘点一下，发现一年下来还真是没做什么事情，以此激励自己明年好好把握时间。</p>
<a id="more"></a>
<h2 id="2015：转变"><a href="#2015：转变" class="headerlink" title="2015：转变"></a>2015：转变</h2><p>2015年，可以用“转变”二字来形容。一是从本科顺利毕业了，开始了研究生生涯；二是从广州来到了上海；三是从数学专业转到了软件工程专业。换学校，换专业，整个人的思维也跟着变了。</p>
<p>2015上半年，得知自己保研后，就有一种茫然感，觉着人生暂时地失去了一个清晰的追逐目标。所以大四上学期一直到开始做毕设之前，没事就一个人跑到图书馆里看闲书或者在广州城里闲逛拍照。（当时我居然没出去旅游？突然想起来了，当时大家的时间都不太同步，就我比较闲）大四下学期开始后，就和大家一直在打LOL。LOL打的不少，但是发现自己确实没天赋，依旧那么菜。然后，就按部就班的做毕设，拍毕业照，毕业。没有大家那种离开校园的特别伤感。一是觉得自己还要待在校园三年时光，二是觉得现在交通这么发达，想见面还是挺容易的，关键是你有心。</p>
<p>2015年下半年：毕业到研究生正式入学之间还有将近一个半月假期，没有响应导师的搬砖号召，在家里瘫了一个多月。接着九月份就开学了，来到了上海，一座我很有好感的城市，虽然父辈们总是黑它排外等。在交大，开学头一个月倒是一门课都没有，留给学生和老师处理各种杂事，对，这个月就是各种杂事，我也不想絮叨了，主要说两个事。首先，导师之前分配了一个科研任务，要在十月底交paper，大四倒是写了个初稿，但集群上的大实验还没有做，但那时候我连<code>Linux</code>都没用过😓。其次，上了一门坑爹课——<code>高级软件工程</code>，在这门课上接了一个坑爹的项目<code>Gogou</code>（这个项目就是开发一个同时支持<code>Android</code>和<code>iOS</code>的代购平台，我主要负责<code>iOS</code>前端设计）。这两个事情可谓是我研一一年的主旋律。结果是，前者，paper被拒了一年（其实也就是被拒稿三次）。后者，这个项目写了我整整一年时间。不过，忙归忙，坑归坑，我的coding能力和团队协作能力确实有很大提高，毕竟本科没写过这么大项目，掌握了一些程序猿必须掌握的工具（<code>github</code>,<code>Linux Shell</code>）以及一些<code>iOS</code>开发知识。其次，英语水平也有了一定的提高，一年多下来读了不少paper。</p>
<p>其实这一年，我的“转变”很是被动，主要是因为大四那段时间太过放松，没有及时做好规划。导致在新环境中有点措手不及。所以，开始慢慢培养自己未雨绸缪的意识。首先说说城市的转变。从广州到上海，一线城市在很多方面都具有工业时代的标准化气息，二者有很多地方极其相似，上海比广州可能更加现代化一些，不多说了。但是，在我眼中，两个城市最大的差别就是生活节奏了。广州，虽然也是一线大城市，但是其骨子里有一种享受生活的慢节奏，从其早茶文化中可见一斑。而上海，节奏明显快了很多。虽然，还没上班，但是在校园里，在地铁站中，总是感受到大家匆忙的脚步。其余的方面，还有待我慢慢体会。再说说思维的转变，从理科思维转变到工科思维。记得大一第一次上数学分析课时，刘老师就讲过：“我们数学系的学生，学四年下来，学会的最有价值的就是数学思维，这个东西可以应用到生活中各个方面去，所以我们数学系的学生活跃在各行各业……” 当时，我就不以为然，尤其是数学思维这个东西，我是一点都不信的。但是当我在数学系浸淫了四年，从数学系转到了软件工程这个工科专业后，我从与工科科班出身的人的共事中发现：人和人的思维方式确实差别很大。比如去解决一个从未遇到的问题时，以前的我（理科思维）：<code>我会从头开始去了解这个问题</code>-&gt;<code>查找类似问题的解决方式</code>-&gt;<code>比较和学习所有的方式方法</code>-&gt;<code>着手解决问题本身</code>-&gt;<code>done</code>。而现在的我（工科思维）:<code>了解问题本身</code>-&gt;<code>找到一种解决类似问题的方法</code>-&gt;<code>学习并掌握这种方法，应用它来解决问题</code>-&gt;<code>如果问题没有得到很好的解决，再回到第二步，寻找其他的方法</code>-&gt;<code>不断修正方法，直到解决问题</code>。</p>
<h2 id="2016：变强"><a href="#2016：变强" class="headerlink" title="2016：变强"></a>2016：变强</h2><p>虽然说是顺带总结一下2015，但是转变的过程让我思考了很多，所以“顺带”写得有点多了。经过一学期的转变和适应后，科研和项目也开始轻车熟路，做得越来越得心应手了。我由衷地觉得在适应了环境后，做很多事情都更有效率了，因此我给2016这一年总结为“变强”。下面就以流水账的形式盘点一下我的2016。</p>
<h3 id="日常"><a href="#日常" class="headerlink" title="日常"></a>日常</h3><p>1月，研一上学期学期末。高级软件工程课程答辩，谢沈阿姨手下留情，让我们项目组顺利通过。这门课程占据了我整个研一上学期60%可能还多的时间，从一个从未接触过<code>iOS</code>开发的小白到能写出一个还像样子的APP（尽管离投入市场有很大距离），我觉着我还是学到不少东西。虽说只是门硕士课程，但是软件开发的基本流程大概是走了一遍，最大收获就是让我明白：我以后肯定不会从事软件开发的工作（其实是不想做纯coding这种重复劳动，而是想做偏分析和市场的数据挖掘工作）。原本，我以为课程项目的代码可以直接当作最后项目的代码交给甲方了事，但是导师跟我们说不行，需要两套代码分开。但是，当时我工程经验不足，很多代码写的可移植性太差。于是，我们相当于需要再从头开始写，还好已经有经验了，但是很多都是重复性工作，让我没有了先前学习的快感。</p>
<p>2月，回家。照常的聚会、吃饭、走亲戚、过年，在家稍微看了下鸟叔的Linux入门书籍，同时还在继续写<code>Gogou</code>的项目代码。</p>
<p>3月，返校，开始研一下学期。照例，开学头一个月都是用来处理选课等杂事。继续写项目代码。</p>
<p>4月，开始应付各种课程。第一次参加志愿者活动，和室友一起去为上海半程国际马拉松发海绵和冰块。哦对了，一个很重要的变化是从这个月开始了规律的健身。（研一上学期忙的飞起，连打球的次数都屈指可数。虽然这个学期仍然要写项目代码，但很多东西都轻车熟路，就没那么大压力了。在Coach Hong的带领下，开始了健身事业。）继续写项目代码。</p>
<p>5月，论文第二次被拒稿，根据review修改论文，投下一个会议。完成第一个专利的撰写。应付各种课程及其作业。继续写项目代码。</p>
<p>6月，应付各种期末考试，全部都顺利通过，毕业的两座大山翻过一座。成功搭建起<code>Hadoop</code>集群。跑到五角场见高中老友星哥哥（他从长沙到上海出差），虽一年难得见一次，但每次见面都能聊地很开心。继续写项目代码。</p>
<p>7月，开始自学经济学知识。和本科同学们跑去舟山旅游，虽然说是去旅游，但不幸那几天刚好刮台风，再加上妹子们对于<code>Airbnb</code>上租到的房子的一脸花痴样，于是一行七人在舟山的房子里宅了3天。开始构思第二篇论文的思路以及实验。继续写项目代码。</p>
<p>8月，做论文的实验。继续写项目代码。中间回家了两周，参加了高中好友斓哥的婚礼。话说，他是我们同龄人第一个结婚的男人，也是我第一次成为婚礼摄像大哥担当。很开心，见到了很多高中同学。</p>
<p>9月，学习<code>sklearn</code>。第一篇论文又被拒稿，根据review修改论文，投下一个期刊。啊，<code>Gogou</code>项目终于结束了，有一种阶段性胜利的错觉。</p>
<p>10月，十一，罗威林跑来上海玩，因为没买到五月天演唱会的票，于是去隔壁听了Ke$ha的演唱会，很嗨。带着罗威林和五爷大萱面基。继续写项目代码。继续做第二篇论文的实验。</p>
<p>11月，完成第二篇专利的撰写。思考论文思路，开始撰写第二篇论文。在做第二篇论文的过程中，开始思忖到底要不要继续读博。跟着实验室到江西婺源旅游。</p>
<p>12月，完成第二篇论文的撰写，投稿<code>ICDCS</code>。投完论文后，开始划水了。复习机器学习知识。博客迁移到<code>Octopress</code>（该版本的前身）。开始看auction理论，为第三篇论文做准备。</p>
<p>1月，和罗威林跑到杭州找中哥玩耍。去江苏靖江，参加徐宇婚礼，第二次婚礼摄像大哥担当。实验室年会，年会摄像大哥担当。这个月就比较划水了，因为后半个月回家了😓。</p>
<h3 id="娱乐消遣"><a href="#娱乐消遣" class="headerlink" title="娱乐消遣"></a>娱乐消遣</h3><p>“一个脱离了高级趣味的无聊男人”，这是目前我对自己的定位。我在学校生活的主旋律就是paper和项目，周末也不大想出门，因为我在闵行，进个城花在路上的时间就有两三个小时😂。出门玩一趟（除开吃吃吃），我还是觉得宅在屋子里看书和运动最舒服。业余时间的消遣主要就是健身、篮球和电影，偶尔拍拍照和游泳。下图是我这一年娱乐消遣的频次统计。</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/2016nianduzongjie/%E5%A8%B1%E4%B9%90%E6%B6%88%E9%81%A3%E7%BB%9F%E8%AE%A1.png">
<p>健身，现在确实成了业余时间的最大爱好。其实去健身房还是蛮枯燥的，但幸好有一批志同道合的肌友陪着我，没有他们的督促和激励，我想我也坚持不下来。同时，也跟他们学到不少科学健身的知识。但是，仍然觉得自己的肌肉长得很慢，特别是胸肌长得没有咬肌快。从上图可以看到，刚开始时我健身热情很高，几乎一周去个三四次，后面的次数就没那么多了，特别回家的两个月（回家就是过猪一般的生活）。到了下半年，进入写paper的攻坚期，去健身房的次数也少了，因为觉得写论文太累，不想分散精力去健身了。事后，我觉得不要给自己找借口，很多事情不是你做不到，而是内心怠惰或害怕困难而不去做，希望2017年能将每月健身次数保持在12次以上。</p>
<p>篮球，其实每周最开心的就是能打一到两次篮球，这个真的是从小学一直玩到现在的运动。科比退役了，NBA看得没有以前多了，但是打球的热情和那种快乐还是和以前一样。或许，篮球是我最不需要坚持的运动，因为热爱就会自发地去玩。健身也给打球带了额外的好处，比如核心力量和上肢力量的提高，现在做很多动作都更加游刃有余，同时肌肉的增强也降低了受伤的风险。希望2017年，非惯用手能更加熟练。</p>
<p>电影，看得越来越少，特别是来上海后。感觉现在过了看特效电影的年纪，记得看《神奇动物在哪里》、《奇异博士》、《星战》我都睡着了，因为剧情太简单了，全都是一个套路。现在更喜欢看剧情复杂或者讽刺电影，《驴得水》、《比利林恩的中场故事》就给我留下很深的印象。多说一句，过去一年闲暇时间还补或追了几部电视剧，题材广泛，如《来自星星的你》、《琅琊榜》、《余罪》、《行尸走肉》、《权力的游戏》、《西部世界》、《好先生》、《黑镜》、《逃避虽可耻但有用》、《Legal High》（我居然看了这么多……）。再多说一句，现在收听或收看的知识性节目，从《罗辑思维》《晓松奇谈（2017停播）》增加了《锵锵三人行》，很喜欢窦文涛这种揣着明白装糊涂的风骚中年大叔。</p>
<h3 id="阅读"><a href="#阅读" class="headerlink" title="阅读"></a>阅读</h3><p>本科时期，阅读量仅限于专业书籍，因为觉得看闲书浪费时间，保研了后才开始看闲书。其实，这又是给自己找理由。平时，一个人安静下来会胡思乱想，有时候会搞到心情抑郁。后面把这些时间都拿来看书，就立马治好了这种中二病。统计了下最近一年半看过的纸质书和Kindle电纸书（除掉专业书籍）：</p>
<blockquote>
<p>《浪潮之巅》（上下册）、《数学之美》、《三体》（1，2，3）、《单恋》、《解忧杂货店》、《历史的教训》、《美国种族简史》、《欧洲极简史》、《枪炮、病菌与钢铁》、《为奴十二年》、《嫌疑人X的献身》、《中国震撼》、《微观经济学原理》</p>
</blockquote>
<p>总共读了才16本书，月均读书量不超过一本……从上可看出，我一如既往地喜欢读历史类书籍。现在开始涉猎经济学知识，尝试着以经济学思维来看待很多事物，讲究回报率。希望2017年每个月至少读完一本书，涉猎更加广泛。</p>
<h3 id="图说2015-amp-2016"><a href="#图说2015-amp-2016" class="headerlink" title="图说2015&amp;2016"></a>图说2015&amp;2016</h3><p>一张图结束流水账盘点：</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/2016nianduzongjie/20162015.jpg">
<h2 id="2017：期望"><a href="#2017：期望" class="headerlink" title="2017：期望"></a>2017：期望</h2><p>2015和2016都过去了，之前总认为计划赶不上变化，所以从来没有对未来一年的规划。但是规划并不是都要实现，只是让人能保持一个大方向不至于偏离太多。那么，我就给自己的2017许下那么些期待：</p>
<ol>
<li>只求中一篇paper（同时也是毕业要求）</li>
<li>每周去健身房三次或以上（希望我的胸从a cup涨到b cup）</li>
<li>每月至少阅读一本书</li>
<li>能找到一份好实习（数据挖掘相关）</li>
<li>找到女朋友（现在爸妈居然在催了，其实我也想啊，但是找到那么个合适的不是这么容易）</li>
<li>左手能熟练运球，能上篮</li>
<li>去霓虹国旅游</li>
<li>世界和平</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h2&gt;&lt;p&gt;本来该篇应该在&lt;code&gt;2017-1-1&lt;/code&gt;写出来的，但那时和高中老友在杭州玩😂，回上海后也忘了这茬，所以拖到了现在。虽然现在已经公历&lt;code&gt;2017-1-24&lt;/code&gt;，但是标题还是取成“2016年度总结”，因为从农历看的话，现在还没有到2017嘛。之前还从未写过年度总结，所以这篇2016年度总结顺带也总结一下2015。之所以想写年度总结，其实也是受到师兄师姐的启发，梳理和盘点一下，发现一年下来还真是没做什么事情，以此激励自己明年好好把握时间。&lt;/p&gt;
    
    </summary>
    
    
      <category term="dairy" scheme="https://xijunlee.github.io/tags/dairy/"/>
    
  </entry>
  
  <entry>
    <title>又从octopress迁移到hexo了……</title>
    <link href="https://xijunlee.github.io/2017/01/15/%E5%8F%88%E4%BB%8Eoctopress%E8%BF%81%E7%A7%BB%E5%88%B0hexo%E4%BA%86%E2%80%A6%E2%80%A6/"/>
    <id>https://xijunlee.github.io/2017/01/15/又从octopress迁移到hexo了……/</id>
    <published>2017-01-15T08:59:32.000Z</published>
    <updated>2017-01-17T01:52:41.000Z</updated>
    
    <content type="html"><![CDATA[<p>之前说好的迁移到<code>octopress</code>后就再也不折腾了，才不到一个月，又被打脸了。这次迁移的目的主要是<code>octopress</code>中的一些bug实在是fix不了（本来就不熟悉前端，也不喜欢写前端）。于是，在上次心动后花了一个下午来把整个博客迁移到<code>hexo</code>框架下。<code>hexo</code>较之<code>octopress</code>更新，而后者现在已经没人维护了，并且<code>hexo</code>是台湾人写的，有大量国人在维护和设计主题，对中文的支持更好。推荐以后想入坑（并且不熟悉前端的），就直接上<code>hexo</code>吧。</p>
<a id="more"></a>
<h3 id="已解决的问题"><a href="#已解决的问题" class="headerlink" title="已解决的问题"></a>已解决的问题</h3><p>目前，在<code>hexo</code>框架下，已经fix的bug有：</p>
<ol>
<li><p>日志分享</p>
</li>
<li><p>翻页功能</p>
</li>
</ol>
<h3 id="仍存在的问题"><a href="#仍存在的问题" class="headerlink" title="仍存在的问题"></a>仍存在的问题</h3><ol>
<li>但是<code>mathjax</code>的公式渲染还是有些问题，不知道是不是文档中公式太多问题造成的。留待日后慢慢解决。</li>
</ol>
<h3 id="关于主题和界面"><a href="#关于主题和界面" class="headerlink" title="关于主题和界面"></a>关于主题和界面</h3><p>首先，我对前端那一套不熟也不感兴趣。其次，我写博客的目的就是想总结学习知识的思路以及记录些生活琐事。基于以上两点，我不想花太多时间自己diy主题。找了一堆主题试，最后还是采用了<code>yilia</code>这个主题，主要是其提供的功能很健全（比如分享，评论等），并且也比较符合我的审美（但是我最想要的还是一款全黑的）。</p>
<p>希望以后坚持下来！</p>
<p>以上</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前说好的迁移到&lt;code&gt;octopress&lt;/code&gt;后就再也不折腾了，才不到一个月，又被打脸了。这次迁移的目的主要是&lt;code&gt;octopress&lt;/code&gt;中的一些bug实在是fix不了（本来就不熟悉前端，也不喜欢写前端）。于是，在上次心动后花了一个下午来把整个博客迁移到&lt;code&gt;hexo&lt;/code&gt;框架下。&lt;code&gt;hexo&lt;/code&gt;较之&lt;code&gt;octopress&lt;/code&gt;更新，而后者现在已经没人维护了，并且&lt;code&gt;hexo&lt;/code&gt;是台湾人写的，有大量国人在维护和设计主题，对中文的支持更好。推荐以后想入坑（并且不熟悉前端的），就直接上&lt;code&gt;hexo&lt;/code&gt;吧。&lt;/p&gt;
    
    </summary>
    
    
      <category term="dairy" scheme="https://xijunlee.github.io/tags/dairy/"/>
    
  </entry>
  
  <entry>
    <title>常见拍卖机制与模型总结</title>
    <link href="https://xijunlee.github.io/2017/01/03/2017-01-03-chang-jian-pai-mai-ji-zhi-yu-mo-xing-zong-jie/"/>
    <id>https://xijunlee.github.io/2017/01/03/2017-01-03-chang-jian-pai-mai-ji-zhi-yu-mo-xing-zong-jie/</id>
    <published>2017-01-03T08:33:34.000Z</published>
    <updated>2017-01-20T14:26:15.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="写在前面的话"><a href="#写在前面的话" class="headerlink" title="写在前面的话"></a>写在前面的话</h2><p>最近在为下一篇论文做背景知识的调研，两周以来都在读auction的基本理论和概念，本篇就用来总结一下常见的拍卖机制和模型。关于拍卖的理论研究着实复杂，本文只是做一个简单的总结，不涉及过多的数学证明及讨论。</p>
<a id="more"></a>
<h2 id="四种基本的拍卖机制"><a href="#四种基本的拍卖机制" class="headerlink" title="四种基本的拍卖机制"></a>四种基本的拍卖机制</h2><h3 id="增加拍卖（英国式）"><a href="#增加拍卖（英国式）" class="headerlink" title="增加拍卖（英国式）"></a>增加拍卖（英国式）</h3><p>为简单起见，先考虑拍卖一件物品。在增价拍卖机制下，价格不断上升，直到只剩下一个竞标者为止。一般是由专业拍卖人员叫价，竞标者举手应价，因此也被称为无声拍卖;也可以由竞标 者自己口头提出愿意接受的价格，这叫做有声拍卖;或是大家通过个人电脑输入价格(历史报价都是公开的)。这是用得最多的一种拍卖机制，特别是专业拍卖行均采用这种方式。世界上最古老，最大的两家专业拍卖行，索士比(Sotheby’s)和克里斯蒂(Christie’s)，都起源于英国伦敦，因此，这种增价拍卖方式常被称为英国式拍卖。</p>
<h3 id="减价拍卖（荷兰式）"><a href="#减价拍卖（荷兰式）" class="headerlink" title="减价拍卖（荷兰式）"></a>减价拍卖（荷兰式）</h3><p>减价拍卖刚好相反，卖家首先从很高的价格开始叫卖，如果没有人愿意出价，卖家由此价格按照事先规定的速度连续减价，直到有第一个人站出来接受卖家的报价。那么该该买家获得拍品。虽然是减价叫卖，但仍然是价高者得。在荷兰，人们常用这种机制来拍卖鲜花，因此称之为荷兰式叫卖。</p>
<h3 id="第一价格拍卖"><a href="#第一价格拍卖" class="headerlink" title="第一价格拍卖"></a>第一价格拍卖</h3><p>每个竞标者在规定时间内，独立地向拍卖人提交标书，标明自己愿意出的价格，因此看不到其他竞标者的出价，再由拍卖人在约定的时间，邀请所有竞标者到场当众开标，出价最高者赢得物品，并付他自己的报价，因此第一价格拍卖也被称为高价拍卖，亦称招标拍卖或邮递拍卖。</p>
<h3 id="第二价格拍卖"><a href="#第二价格拍卖" class="headerlink" title="第二价格拍卖"></a>第二价格拍卖</h3><p>与第一价格拍卖类似，在第二价格拍卖机制下，拍品仍然是归报价最高者，但成交价等于各买家中出的第二高报价。此方式在实际中用得不多，但有很好的理论性质。这一机制最先由经济学家维克瑞(William Vickrey)在1961年提出。</p>
<p>在每一种拍卖中，如出现几个人同时报得最高价，那么卖家就会在他们中随机挑选一个人作为赢家。此外，卖家通常还会增加两种限制。一种设定保留价（底价），另一种是收取参加拍卖的费用。在第一价格或第二价格拍卖机制下，竞标者的出价必须高于或等于保留价，否则不能成交。值得注意的是，在第二价格拍卖中，如果只有一个竞标者出价，而且高于保留价，那么他赢得并且支付保留价即可。在增价和减价拍卖中，保留价有着同样的作用。卖方在拍卖开始之前公开保留价，或者密封保留价。此外，卖方通常会要求感兴趣参加竞标的买方支付一定的费用才可以参与竞标。</p>
<h2 id="三种拍卖的基本经济模型"><a href="#三种拍卖的基本经济模型" class="headerlink" title="三种拍卖的基本经济模型"></a>三种拍卖的基本经济模型</h2><h3 id="独立私有价值模型"><a href="#独立私有价值模型" class="headerlink" title="独立私有价值模型"></a>独立私有价值模型</h3><p>假设此时有一个卖家，他想卖掉一件物品，他对此物品的估价为$v_0$,这是公开的信息。有$n$个买方对此物品感兴趣，让$v_i$表示第i个买家对该物品的估价。现在作如下假定：</p>
<p>1.(私有价值)：对买方$i$来说，只有他自己知道$v_i$的大小，卖方及其他卖方不知道$v_i$的大小。但是他们会认为$v_i$是分布在$[a,z]$区间上的一个随机变量，并知道其概率分布函数$F_i(v_i)$和密度函数$f_i(v_i)$，其中$0 \leq a &lt; z$。</p>
<p>2.(独立性)：总体来说，买家们的估价$v_1,v_2,…,v_n$是独立的。即它们的联合分布函数为:</p>
<p>$$F(v_1,v_2,…,v_n)=F_1(v_1)F_2(V_2)…F_n(v_n)$$</p>
<p>3.(对称性)：这些概率分布函数完全相同，即$\forall i,j=1,2,…,n$和$\forall v\in[a,z]$:</p>
<p>$$F_i(v)=F_j(v)=F(v)$$</p>
<p>4.(风险中性)：每个买方的目标是最大化他的期望收益。</p>
<p>5.(非合作行为)：所有买方独立决定自己的竞价策略，不存在任何具有约束力的合作性协议。</p>
<p>所有这些假定中描述的知识，对买卖双方均属共同知识(common knowledge)。比如说，对于任意一个买家$i$，其他人猜测i的估价$v_i$是分布在$[a,z]$区间上的随机变量，并服从概率分布$F_i(v_i)$等等。对这种环境的描述称为对称独立私有价值(Symmetric Independent Private Value)模型，简称为SIPV模型。如果对称性假设不满足时，即各买家的估价分布函数不一致时，此时模型退化为更一般的独立私有价值(Independent Private Value)模型，简称为IPV模型。IPV模型描述了另外一种情况，即当每个买家对拍品有不同的偏好，而且不受别人偏好影响。</p>
<h3 id="共同价值模型"><a href="#共同价值模型" class="headerlink" title="共同价值模型"></a>共同价值模型</h3><p>另一种极端情况可以用共同价值(Common Value)模型来描述，简称CV模型。对每个人来说，拍品都会有一个共同价值$v$，但卖家和买家都不知道$v$的大小，但他们每个人都有自己的估价$x<em>i$。现作如下假定：共同价值$v$是一个服从概率分布$G(v)$和密度函数$g(v)$的随机变量，$v\in [v</em>{min},v_{max}]$。每个人的私人估价$x_i$服从$[a,z]$上的条件分布$H_i(x_i|v)$。</p>
<p>在最简单的情况下，我们可以将买家报价$x_i$表示成：</p>
<p>$$ x_i=v+\varepsilon_i $$</p>
<p>其中$\varepsilon_i$表示第i个人估价过程中的误差，假定其平均误差为零。</p>
<h3 id="关联价值模型"><a href="#关联价值模型" class="headerlink" title="关联价值模型"></a>关联价值模型</h3><p>上述两种模型是理想的极端情况，但在现实生活中往往不会出现。有一种更具一般性的模型，能更适当地描述拍卖时间中参与人所处的环境，称为关联价值(Affiliated Value)模型。</p>
<p>第i个买方对拍品的真实价值$v_i$可能取决于所有买方的私人信息$x=(x_1,x_2,…,x_n)$以及其他共同的不确定因素$s=(s_1,s_2,…,s_k)$:</p>
<p>$$ v_i=u(s,x<em>i,x</em>{-i}) $$</p>
<p>其中向量$x_{-i}$表示$(x_1,x_2,…,x_n)$中去掉$x_i$。随机变量$x$和$s$呈现某种关联性，而且每个竞标者的真实价值$v_i$随$(s,x<em>i,x</em>{-i})$中的任何一个变量的增加而增加。</p>
<p>比较而言，关联价值模型对现实更有指导意义，而独立价值模型和共同价值模型是其的特殊情况。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;写在前面的话&quot;&gt;&lt;a href=&quot;#写在前面的话&quot; class=&quot;headerlink&quot; title=&quot;写在前面的话&quot;&gt;&lt;/a&gt;写在前面的话&lt;/h2&gt;&lt;p&gt;最近在为下一篇论文做背景知识的调研，两周以来都在读auction的基本理论和概念，本篇就用来总结一下常见的拍卖机制和模型。关于拍卖的理论研究着实复杂，本文只是做一个简单的总结，不涉及过多的数学证明及讨论。&lt;/p&gt;
    
    </summary>
    
    
      <category term="auction" scheme="https://xijunlee.github.io/tags/auction/"/>
    
  </entry>
  
  <entry>
    <title>泊松分布与指数分布的重新理解</title>
    <link href="https://xijunlee.github.io/2016/12/28/2016-12-28-bo-song-fen-bu-yu-zhi-shu-fen-bu-de-zhong-xin-li-jie/"/>
    <id>https://xijunlee.github.io/2016/12/28/2016-12-28-bo-song-fen-bu-yu-zhi-shu-fen-bu-de-zhong-xin-li-jie/</id>
    <published>2016-12-28T03:01:20.000Z</published>
    <updated>2017-06-06T03:03:44.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="写在前面的话"><a href="#写在前面的话" class="headerlink" title="写在前面的话"></a>写在前面的话</h2><p>组会上有人提到了几种概率分布，当时我听到的感觉就是“啊，我每一个都听过，也学过，但是都忘记了细节😭”。于是，会后又跑去wiki了一番，回忆了以前概率课上学的东西。记得当时学概率分布时，有几种分布是真的无法理解（至少在当时的思维下，我感觉是没有理解的），而且做题时常常陷入一种局部思维，把几种分布搞混淆。过了一两年，重新来看以前学过的东西，发现顿时有了更深的理解（我也不知道为什么，可能这就是所谓的“书读百遍其义自见”，但是也不是读一百遍就一定能懂，我觉得当时我把概念背了很熟，但有些还是不能很好地理解。</p>
<p>所以，现在重新整理下以前似懂非懂或者没注意的概念。</p>
<hr>
<a id="more"></a>
<h3 id="随机变量"><a href="#随机变量" class="headerlink" title="随机变量"></a>随机变量</h3><p>如果说要举出在概率论中出现频次最高的术语，随机变量绝对是位列三甲的。但是一个出现频次这么高的术语，而且也是概率论这门课一上来老师就强调的概念，我对其的理解却是很肤浅的。</p>
<p>从初等概率论出发。</p>
<blockquote>
<p>如果$X$指定概率空间$S$中每一个事件$e$都有一个实数$X(e)$，同时针对每一个实数$r$都有一个事件集合$A_r$与其相对应，其中$A_r={e:X(e)\leq r}$，那么$X$被称为随机变量。 – wikipedia</p>
</blockquote>
<p>从上面的定义可以看到，随机变量其实不是一个变量，而是一个函数，是将概率空间$S$中每一个事件$e$映射到一个实数$r$上的函数。如下图所示：</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/Zufall.png">
<h4 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h4><p>随机投掷两个骰子，那么整个样本空间可以由36个元素组成：</p>
<p>$$S={(i,j)|i=1,…,6;j=1,…,6}$$</p>
<p>很明显这里可以构成多个随机变量。比如随机变量$X$（投掷后两个骰子的点数之和）或者$Y$（投掷后两个骰子的点数之差），随机变量$X$可以有11个整数值，而随机变量$Y$只有6个。</p>
<p>$$X(i,j):=i+j,x=2,3,…,12$$</p>
<p>$$Y(i,j):=|i-j|,y=0,1,2,3,4,5.$$</p>
<p>从上面的这个例子可以看到，随机变量们将原样本空间中的事件映射到了整数空间。</p>
<p>下面就正式进入正题来讲下我对泊松分布和指数分布的重新理解。因为其他几个分布还比较简单易懂，而泊松分布和指数分布不好懂而且它们也相似，故单独挑这两个出来。</p>
<h3 id="泊松分布"><a href="#泊松分布" class="headerlink" title="泊松分布"></a>泊松分布</h3><blockquote>
<p>Poisson分布，是一种统计与概率论中常见的<strong>离散</strong>概率分布，由法国数学家Siméon-Denis Poisson在1838年发表。其适合于描述<strong>单位时间内随机事件发生的次数</strong>的概率分布。如某一服务设施在一定时间内受到的服务请求的次数，电话交换机接到呼叫的次数、汽车站台的候客人数、机器出现的故障数、自然灾害发生的次数、DNA序列的变异数、放射性原子核的衰变数、激光的光子数分布等等。 –wikipedia</p>
</blockquote>
<p>泊松分布的概率质量函数：</p>
<p>$$P(X=k)=\frac{e^{-\lambda}\lambda^k}{k!}$$</p>
<p>泊松分布的参数$\lambda$是<strong>单位时间（或单位面积）内随机事件的平均发生率</strong>。</p>
<blockquote>
<p>在概率论中，概率质量函数（probability mass function，简写为pmf）是离散随机变量在各特定取值上的概率。概率质量函数和概率密度函数不同之处在于：概率质量函数是对离散随机变量定义的，本身代表该值的概率；概率密度函数是对连续随机变量定义的，本身不是概率，只有对连续随机变量的概率密度函数在某区间内进行积分后才是概率。</p>
</blockquote>
<p>泊松分布的累积分布函数:</p>
<p>$$P(X\leq k)=e^{-\lambda}\sum_{i=0}^{k}\frac{\lambda_i}{i!}$$</p>
<p>下面分别给出其概率质量函数和累积分布函数的图像：</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/Poisson_pmf.png">
<p>对着上述图像解释，每个点的意义就是单位时间或面积内随机事件发生k次的概率。</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/Poisson_cdf.png">
<p>对着上述图像解释，每个点的意义就是单位时间或面积内随机事件发生次数小于等于k次的概率。</p>
<h3 id="指数分布"><a href="#指数分布" class="headerlink" title="指数分布"></a>指数分布</h3><p>泊松分布，我觉得相对来说还好理解一些。而指数分布就有点那么绕了，不过我觉得结合其概率密度函数图和累积分布函数图来看，就好理解一些了。</p>
<blockquote>
<p>在概率论和统计学中，指数分配（Exponential distribution）是一种<strong>连续概率分布</strong>。指数分配可以用来表示独立随机事件发生的时间间隔，比如旅客进入机场的时间间隔、打进客服中心电话的时间间隔、中文维基百科新条目出现的时间间隔等等。  –wikipedia</p>
</blockquote>
<p>首先注意到，与泊松分布相比，其最大的差异就是指数分布是针对连续随机变量定义，即时间这个变量。时间必须是连续的。而泊松分布是针对随机事件发生次数定义的，发生次数是离散的。粗略地可以认为这两个分布之间有一种“倒数”的关系。</p>
<p>指数函数的概率密度函数:</p>
<p>$$p(x;\lambda)=\lambda e^{-\lambda x},x \in [0,+\infty)$$</p>
<p>其中，$\lambda &gt; 0$是该分布的一个参数，称为率参数(rate parameter)。即每单位时间内发生该事件的次数。读到这里，可能因为这个率参数被搞得一头雾水，容易跟泊松分布混淆。</p>
<p>指数分布的累积分布函数：</p>
<p>$$p(x;\lambda)=1- e^{-\lambda x},x \in [0,+\infty)$$</p>
<p>估计还是一头雾水😓，下面结合指数分布的概率密度曲线和累积分布曲线图，就稍微能理解下了（至少我是这么认为：</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/650px-Exponential_distribution_pdf.png">
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/650px-Exponential_distribution_cdf.png">
<p>上述第二幅图像正是指数分布的累积分布函数图，对着图来看能更好的理解指数分布。</p>
<p>1.先看$\lambda=1.0$这条曲线。关注到这条曲线上横坐标为1的点，其意义是1个单位时间该事件发生1次的概率。如果是横坐标为2的点，则其意义便是2个单位时间内该事件发生1次的概率。换个方法说，就是第k次该事件发生后隔2个单位时间发生第k+1次该事件的概率。</p>
<p>2.再看$\lambda=1.5$这条曲线。与上述描述类似，先关注到这曲线上横坐标为1的点，其意义是1个单位时间内该事件发生1.5次的概率（次数居然是1.5次？？？理论上确实可以这么说，只是不好理解，如果换成整数次就可能更好理解）。如果是横坐标为2的点，其意义便是2个单位时间内该事件发生1.5次的概率。同样地，换个说法，也就是第k次该事件发生后隔2个单位时间该事件发生第k+1.5次的概率。</p>
<p>我觉得通过上述对图的表述，能进一步加深对指数分布的理解了。</p>
<hr>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>首先，这两个分布最大的不同是，泊松分布是针对随机事件发生次数的定义的<strong>离散随机变量</strong>，而指数分布是针对随机事件发生的间隔时间定义的<strong>连续随机变量</strong>，这是二者最大的区别。切莫因为参数$\lambda$把二者混淆了。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;写在前面的话&quot;&gt;&lt;a href=&quot;#写在前面的话&quot; class=&quot;headerlink&quot; title=&quot;写在前面的话&quot;&gt;&lt;/a&gt;写在前面的话&lt;/h2&gt;&lt;p&gt;组会上有人提到了几种概率分布，当时我听到的感觉就是“啊，我每一个都听过，也学过，但是都忘记了细节😭”。于是，会后又跑去wiki了一番，回忆了以前概率课上学的东西。记得当时学概率分布时，有几种分布是真的无法理解（至少在当时的思维下，我感觉是没有理解的），而且做题时常常陷入一种局部思维，把几种分布搞混淆。过了一两年，重新来看以前学过的东西，发现顿时有了更深的理解（我也不知道为什么，可能这就是所谓的“书读百遍其义自见”，但是也不是读一百遍就一定能懂，我觉得当时我把概念背了很熟，但有些还是不能很好地理解。&lt;/p&gt;
&lt;p&gt;所以，现在重新整理下以前似懂非懂或者没注意的概念。&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
    
      <category term="probability theory" scheme="https://xijunlee.github.io/tags/probability-theory/"/>
    
  </entry>
  
  <entry>
    <title>有逼格的画图从gnuplot说起</title>
    <link href="https://xijunlee.github.io/2016/12/24/2016-12-24-you-bi-ge-de-hua-tu-cong-gnuplotshuo-qi/"/>
    <id>https://xijunlee.github.io/2016/12/24/2016-12-24-you-bi-ge-de-hua-tu-cong-gnuplotshuo-qi/</id>
    <published>2016-12-24T12:29:04.000Z</published>
    <updated>2017-01-16T10:42:30.000Z</updated>
    
    <content type="html"><![CDATA[<p>有写论文需求的伙伴们，画图的时候肯定会被导师吐槽过“你这图画的真难看……”。如果不是在写学术论文，<code>Excel</code>就能解决大部分需求。但是，如果想画出印刷出版物品质的插图，还是得用到额外的工具。最常见的无非是用<code>Matlab</code>来画论文插图。但是，我还是有点嫌弃<code>Matlab</code>做出图片的配色和线条粗细（当然，这个可以调整，但每个人审美确实不同）。如果想画出大部分人都觉得精致的插图，该用什么好呢？其实，我之前一段时间是用的<code>Python</code>的一个库<code>matlibplot</code>,挺方便也挺好看的。但是后来，拜读隔壁大牛实验室<a href="http://ipads.se.sjtu.edu.cn" target="_blank" rel="external">IPADS</a>的paper时，总觉得他们的插图很有逼格。这么一打听，才知道是用<code>gnuplot</code>画的。于是，我最近的一篇论文就开始全部用<code>gnuplot</code>作图了。以后应该是全面倒向<code>gnuplot</code>的怀抱。</p>
<a id="more"></a>
<p>此篇文章就简单记录下我使用<code>gnuplot</code>的过程，以后边学边update。首先，什么是<code>gnuplot</code>？</p>
<blockquote>
<p>Gnuplot is a portable command-line driven graphing utility for Linux, OS/2, MS Windows, OSX, VMS, and many other platforms. The source code is copyrighted but freely distributed (i.e., you don’t have to pay for it). It was originally created to allow scientists and students to visualize mathematical functions and data interactively, but has grown to support many non-interactive uses such as web scripting. It is also used as a plotting engine by third-party applications like Octave. Gnuplot has been supported and under active development since 1986.</p>
</blockquote>
<p>简单了说<code>gnuplot</code>就是一款跨多平台的，支持交互式的，开源的脚本画图语言。如果之前有过<code>Python</code>或<code>Matlab</code>经验的话，<code>gnuplot</code>上手就更快了。下面，给出一些<code>gnuplot</code>画图的demo。</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/barchart_art.1.png">
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/gaussians.png">
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p><code>gnuplot</code>支持多平台，因此安装也是多种多样的，具体参见其<a href="http://www.gnuplot.info/download.html" target="_blank" rel="external">下载页面</a>，应当是比较简单的，尤其是在<code>Windows</code>下，其安装就是一路点到底。</p>
<h2 id="一个demo-for-Windows"><a href="#一个demo-for-Windows" class="headerlink" title="一个demo for Windows"></a>一个demo for <code>Windows</code></h2><p>因为我论文是在实验室的台式机(<code>Windows</code>)上写的。所以，下面的例子就以<code>Windows</code>下的<code>gnuplot</code>来讲解。</p>
<p>在我论文中，有个需求就是，将折线图和柱状图画在一个坐标系中，二者共用一个横坐标，而左边的纵坐标为柱状图的度量单位，右边的纵坐标为折线图的度量单位，如下图所示:</p>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/letter.png">
<p>那么，该如何画这样的图呢？</p>
<h3 id="1-准备好你的数据集"><a href="#1-准备好你的数据集" class="headerlink" title="1. 准备好你的数据集"></a>1. 准备好你的数据集</h3><p><code>gnuplot</code>支持从<code>.txt</code>,<code>.csv</code>等诸多文件中读取数据。我推荐的方式是用额外的文件保存数据，画图的脚本从该文件中读取数据来进行画图。在我的实践中，我是用<code>.txt</code>来保存数据的，如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">letter.txt</div><div class="line"></div><div class="line"><span class="number">1</span>    <span class="number">2.978431</span>    <span class="number">35.85</span>    <span class="number">35.95</span>    <span class="number">35.3</span></div><div class="line"><span class="number">2</span>    <span class="number">5.886818</span>    <span class="number">35.95</span>    <span class="number">36.55</span>    <span class="number">34.9</span></div><div class="line"><span class="number">3</span>    <span class="number">7.494</span>    <span class="number">38.9</span>    <span class="number">39.85</span>    <span class="number">36.45</span></div><div class="line"><span class="number">4</span>    <span class="number">8.354836</span>    <span class="number">39.5</span>    <span class="number">41.65</span>    <span class="number">36.2</span></div><div class="line"><span class="number">5</span>    <span class="number">9.533521</span>    <span class="number">41.9</span>    <span class="number">44.95</span>    <span class="number">36.65</span></div><div class="line"><span class="number">6</span>    <span class="number">10.488704</span>    <span class="number">46</span>    <span class="number">48.1</span>    <span class="number">38.95</span></div><div class="line"><span class="number">7</span>    <span class="number">10.809368</span>    <span class="number">52.9</span>    <span class="number">56.55</span>    <span class="number">42.7</span></div><div class="line"><span class="number">8</span>    <span class="number">10.902275</span>    <span class="number">59.75</span>    <span class="number">66.9</span>    <span class="number">47</span></div><div class="line"><span class="number">9</span>    <span class="number">10.927407</span>    <span class="number">67.95</span>    <span class="number">75.05</span>    <span class="number">50.95</span></div><div class="line"><span class="number">10</span>    <span class="number">10.933407</span>    <span class="number">72.05</span>    <span class="number">80.1</span>    <span class="number">51.45</span></div><div class="line"><span class="number">11</span>    <span class="number">10.936407</span>    <span class="number">75.25</span>    <span class="number">82.8</span>    <span class="number">54.7</span></div><div class="line"><span class="number">12</span>    <span class="number">10.940407</span>    <span class="number">78.65</span>    <span class="number">84.7</span>    <span class="number">56.65</span></div><div class="line"><span class="number">13</span>    <span class="number">10.940407</span>    <span class="number">82</span>    <span class="number">89.45</span>    <span class="number">59.35</span></div><div class="line"><span class="number">14</span>    <span class="number">10.942407</span>    <span class="number">83.5</span>    <span class="number">89.45</span>    <span class="number">64.7</span></div><div class="line"><span class="number">15</span>    <span class="number">10.942407</span>    <span class="number">88</span>    <span class="number">93.5</span>    <span class="number">69.7</span></div><div class="line"><span class="number">16</span>    <span class="number">10.942407</span>    <span class="number">86.65</span>    <span class="number">95.35</span>    <span class="number">69.75</span></div></pre></td></tr></table></figure>
<p>其中，第一列是横坐标数，第二列是Entropy，第三到第五列是三个分类器的分类正确率。</p>
<h3 id="2-一个脚本demo"><a href="#2-一个脚本demo" class="headerlink" title="2. 一个脚本demo"></a>2. 一个脚本demo</h3><p>我觉得学习写代码最快的方式就是直接读别人的代码，懂了后，然后就根据自己的需求改。那么下面，我就直接上绘图脚本的代码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div></pre></td><td class="code"><pre><div class="line">set size ratio <span class="number">0.8</span></div><div class="line">%设置输出图像的长宽比为<span class="number">0.8</span></div><div class="line"></div><div class="line">aqua = <span class="string">"#00FFFF"</span>; azure = <span class="string">"#F0FFFF"</span>;</div><div class="line">aliceblue = <span class="string">"#F0F8FF"</span></div><div class="line">%这是我预设的三种颜色，根据rgb色彩原理</div><div class="line"></div><div class="line">set style fill solid <span class="number">1.00</span> border <span class="number">0</span></div><div class="line"></div><div class="line">set boxwidth <span class="number">0.4</span> relative</div><div class="line">%设置柱状图中每条柱子的相对宽度</div><div class="line"></div><div class="line">set xlabel <span class="string">"Attribute number"</span> font <span class="string">"Verdana,15"</span></div><div class="line">%设置x轴标签为<span class="string">"Attribute number"</span> 字体和大小分别为<span class="string">"Verdana"</span> <span class="number">15</span></div><div class="line"></div><div class="line">set autoscale</div><div class="line"></div><div class="line">set yrange [<span class="number">2</span>:<span class="number">12</span>];</div><div class="line">%设置左纵坐标轴取值范围为[<span class="number">2</span>,<span class="number">12</span>]</div><div class="line"></div><div class="line">set ylabel <span class="string">"Entropy (/bit)"</span> font <span class="string">"Verdana,15"</span>;</div><div class="line">%设置左纵坐标轴标签为<span class="string">"Entropy (/bit)"</span></div><div class="line"></div><div class="line">set ytics <span class="number">2</span> nomirror;</div><div class="line">%设置左纵坐标轴的刻度为<span class="number">2</span>，并且不镜像复制到右边的纵坐标轴，默认情况下是左右纵坐标轴是一样的，但是我们这里的需求是两个纵坐标轴不一样</div><div class="line"></div><div class="line">set y2range [<span class="number">30</span>:<span class="number">100</span>];</div><div class="line">%设置右纵坐标轴的取值范围为[<span class="number">30</span>,<span class="number">100</span>]</div><div class="line"></div><div class="line">set y2label <span class="string">"Accuracy (%)"</span> font <span class="string">"Verdana,15"</span></div><div class="line">%设置右纵坐标轴的标签为<span class="string">"Accuracy (%)"</span></div><div class="line"></div><div class="line">set y2tics <span class="number">10</span> nomirror;</div><div class="line">%设置右纵坐标轴的刻度为<span class="number">10</span></div><div class="line"></div><div class="line">set key font <span class="string">"Verdana,15"</span></div><div class="line">%设置图例的字体和大小</div><div class="line"></div><div class="line">set key out horiz</div><div class="line">%设置图例在图像的外边，并且呈水平分布</div><div class="line"></div><div class="line">set key center top</div><div class="line">%设置图例拜访的位置</div><div class="line"></div><div class="line">set grid ytics</div><div class="line">%显示网格</div><div class="line"></div><div class="line">plot <span class="string">"letter.txt"</span> using <span class="number">2</span>:xtic(<span class="number">1</span>) title <span class="string">"Entropy"</span> <span class="keyword">with</span> boxes fs pattern <span class="number">3</span> lc rgb aliceblue,\           </div><div class="line">                          <span class="string">''</span> using <span class="number">3</span> title <span class="string">"SVM"</span> w lp  lw <span class="number">1.7</span> pt <span class="number">2</span> ps <span class="number">1.3</span>  axes x1y2, \</div><div class="line">                          <span class="string">''</span> using <span class="number">4</span> title <span class="string">"DT"</span> w lp  lw <span class="number">1.7</span> pt <span class="number">8</span> ps <span class="number">1.3</span>  axes x1y2, \</div><div class="line">                          <span class="string">''</span> using <span class="number">5</span> title <span class="string">"LDA"</span> w lp lw <span class="number">1.7</span> pt <span class="number">12</span> ps <span class="number">1.3</span>  axes x1y2</div><div class="line"></div><div class="line">%第<span class="number">48</span>行代码的意思是：从letter.txt读取数据，使用第一列数据作为横坐标，坐标轴名为Entropy,并且柱状图，后面的参数是设置柱状图形状颜色等</div><div class="line">%而第<span class="number">49</span>到第<span class="number">51</span>行代码是来画折线图。这里我们以第<span class="number">49</span>行的代码为例子来讲解：使用letter.txt中第三列数据绘制SVM正确率折线图，后面的参数是来设置折线的粗细和点的大小。注意到axes x1y2是指的是该折线图对应的坐标系是共用的横坐标轴和右纵坐标轴。</div></pre></td></tr></table></figure>
<p>以上便是实现我画图需求的脚本。上述代码中，<code>%</code>之后的代码是注释，参照注释应该能明白每一步都是在做什么了吧。具体的参数细节，以后有空补上，或者读者们可以自行Google弄懂之~ 写完脚本后，保存为<code>letter.plt</code>文件即可。</p>
<h3 id="3-运行-plt脚本"><a href="#3-运行-plt脚本" class="headerlink" title="3. 运行.plt脚本"></a>3. 运行.plt脚本</h3><p>保存好后<code>.plt</code>脚本后，可以打开<code>gnuplot</code>交互命令窗口。点击<code>change dir</code>，切换到保存你当前脚本的那个文件夹，当然你也可以不切换，但在运行脚本时，就得写上脚本的<code>绝对路径</code>。切换好后，运行下面的代码:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">load <span class="string">'letter.plt'</span></div></pre></td></tr></table></figure>
<p>然后，你就能生成到一副看上去颇有逼格的图了。最后，你可以选择导出图片，<code>gnuplot</code>支持多种格式的图片输出，比如我就选择导出成<code>.pdf</code>。</p>
<hr>
<p>好了，以上就是对<code>gnuplot</code>的一个简单粗暴的介绍，我也只是刚入门呐。在我个人看来，上述我提及的画图工具，他们制图精美程度的排序是<code>gnuplot</code>&gt;<code>matlibplot</code>=<code>Matlab</code>&gt;<code>Excel</code>。当然了，有的大神用<code>Excel</code>也能画出很高大上的图，但是前提是要花很多心思和时间在配色上。而<code>gnuplot</code>默认的配色和图像设置就能输出令大多数人赏心悦目的图片了。</p>
<p>当然了，最后还得补一句：插图的逼格是次要的，关键还得你paper确实有水平啊~</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;有写论文需求的伙伴们，画图的时候肯定会被导师吐槽过“你这图画的真难看……”。如果不是在写学术论文，&lt;code&gt;Excel&lt;/code&gt;就能解决大部分需求。但是，如果想画出印刷出版物品质的插图，还是得用到额外的工具。最常见的无非是用&lt;code&gt;Matlab&lt;/code&gt;来画论文插图。但是，我还是有点嫌弃&lt;code&gt;Matlab&lt;/code&gt;做出图片的配色和线条粗细（当然，这个可以调整，但每个人审美确实不同）。如果想画出大部分人都觉得精致的插图，该用什么好呢？其实，我之前一段时间是用的&lt;code&gt;Python&lt;/code&gt;的一个库&lt;code&gt;matlibplot&lt;/code&gt;,挺方便也挺好看的。但是后来，拜读隔壁大牛实验室&lt;a href=&quot;http://ipads.se.sjtu.edu.cn&quot;&gt;IPADS&lt;/a&gt;的paper时，总觉得他们的插图很有逼格。这么一打听，才知道是用&lt;code&gt;gnuplot&lt;/code&gt;画的。于是，我最近的一篇论文就开始全部用&lt;code&gt;gnuplot&lt;/code&gt;作图了。以后应该是全面倒向&lt;code&gt;gnuplot&lt;/code&gt;的怀抱。&lt;/p&gt;
    
    </summary>
    
    
      <category term="academic plotting" scheme="https://xijunlee.github.io/tags/academic-plotting/"/>
    
  </entry>
  
  <entry>
    <title>漫谈高维数据聚类(2):子空间聚类</title>
    <link href="https://xijunlee.github.io/2016/12/22/2016-12-22-man-tan-gao-wei-shu-ju-ju-lei-2-zi-kong-jian-ju-lei/"/>
    <id>https://xijunlee.github.io/2016/12/22/2016-12-22-man-tan-gao-wei-shu-ju-ju-lei-2-zi-kong-jian-ju-lei/</id>
    <published>2016-12-22T01:46:37.000Z</published>
    <updated>2017-01-16T10:42:24.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>如今处理高维数据的问题往往会有两座“大山”，分别是存储成本高和计算时间过长。显然，这是因为数据的高维数造成的。面对大规模的高维数据的聚类任务，传统的聚类算法有点hold不住了，正因此，子空间分割算法应运而生。</p>
<p>前面的一篇文章应该是解释清楚了啥是聚类，也安利了一个经典的聚类算法——K均值聚类。本篇开始正式介绍一些子空间聚类算法，以及这些聚类算法的应用实例。</p>
<a id="more"></a>
<h2 id="1-什么是子空间聚类"><a href="#1-什么是子空间聚类" class="headerlink" title="1.什么是子空间聚类"></a>1.什么是子空间聚类</h2><blockquote>
<p>给定一个n个样本构成的矩阵$X=[x_1, x_2, …, x_n]\in R^{m*n},x_i \in  R^m$，并且已知这n个样本是分别来自k个子空间${S_i},i=1, …, k$。令${d_i&lt;m,i=1,…,k}$表示k个子空间的维度（其中$d_i$是未知的）。子空间聚类的目的是将这个n个样本正确地划归到各自所属的子空间中去，即将n个样本聚成k类，每一个类就是一个子空间。</p>
</blockquote>
<img src="http://xijun-album.oss-cn-hangzhou.aliyuncs.com/C83B7ACE-76BC-4D9C-A24B-DFA41C1244D1.png">
<p>从上图可以看到，总共有三个子空间，每个子空间上都有一些样本，位于同一个子空间内的样本就可以说是同一类的。每一个子空间有其相应的维数d,和一组基$[b_1,b_2,…,b_d]$，由这组基可以表示该子空间中任意一个向量。</p>
<h2 id="2-稀疏表示模型和低秩表示模型"><a href="#2-稀疏表示模型和低秩表示模型" class="headerlink" title="2.稀疏表示模型和低秩表示模型"></a>2.稀疏表示模型和低秩表示模型</h2><p>目前，有四大类主流的求解子空间聚类问题的算法，分别是：</p>
<p>（1）基于统计的方法：混合数据假设是从服从某一概率分布（如混合高斯分布）中抽取出的独立样本集，于是数据的分割问题就转化为一模型估计问题。代表性的工作有凝聚有损压缩[2]和随机抽样一致[1]；</p>
<p>（2）基于矩阵分解的方法：将数据矩阵分解为一正交基矩阵和一低秩矩阵的乘积，从分解结果的结构来揭示聚类的特性。当子空间含有噪声和奇异值，或者独立子空间的假设不成立时，此类方法的效果不尽人意。代表性的工作有K子空间分割[4]；</p>
<p>（3）基于代数的方法：可以处理子空间不是相互独立的情况，但计算量大，且对噪声和奇异值敏感。代表性的工作有Generalized PCA(GPCA)[3]；</p>
<p>（4）基于谱聚类的方法：谱聚类算法是一种对高维数据进行聚类的技术。基于谱聚类的子空间分割算法先根据观测样本求得一个相似矩阵，然后对这个相似矩阵进行谱聚类获得最终的聚类结果。代表性的工作有稀疏子空间聚类[5]和低秩表示子空间聚类[6][7]。</p>
<p>而我要安利的是基于谱聚类的两个算法：稀疏表示子空间聚类算法和低秩表示子空间聚类算法，这两个算法都是比较简单和直观的，是子空间聚类研究这一块的基石性的算法，很多新算法都是在这两个算法的基础上加以改进而提出来的。当然，想要弄清楚这两个算法，还是需要一些简单的线性代数知识的。</p>
<h3 id="稀疏表示-Sparse-Representation"><a href="#稀疏表示-Sparse-Representation" class="headerlink" title="稀疏表示(Sparse Representation)"></a>稀疏表示(Sparse Representation)</h3><p>稀疏表示这一概念的提出，说到底还是受到压缩感知理论[8][9]的启发。该理论认为很多高维数据是冗余的，如果其具有可压缩性，那么可以只需要通过少量的采样便可恢复原始高维数据。更简单地说就是，许多高维数据是存在其低维表示的。</p>
<p>学过线性代数的都应该知道线性相关这一概念，即向量组$X=[x_1,x_2,…,x_n]$,其中$x_i$是$X$的列向量，若存在不全为0 的系数$a_1,a_2,…,a_n$，使得$a_1<em>x_1+a_2</em>x_2+…+a_n<em>x_n=0$成立，则说$x_1,x_2,…,x_n$是线性相关的，如若$a_i$不等于零，那$x_i$就可以被其余向量线性表示，即$x_i=-(a_1</em>x_1+a_2<em>x<em>2+…a</em>{i-1}</em>x<em>{i-1}+a</em>{i+1}<em>x_{i+1}+…+a_n</em>x_n)/a_i$。</p>
<p>有了以上两个认知，就可以理解稀疏表示了。在前面提到过位于同一个子空间中的样本，如果样本数足够多，那么某一个样本$x_i$是可以被与它位于同一个子空间中的其他样本线性表示的，而我们希望用尽量少的样本来表示$x_i$$，这就是稀疏表示的简单理解，用数学语言描述该模型如下：</p>
<p>给定一个n个样本构成的矩阵$X=[x_1,x_2,…,x_n]\in R^{m<em>n},x<em>i\in R^m$,其中每一列是一个样本，由$X$中d个样本构成一个“字典”$D=[x</em>{i1},x<em>{i2},…,x</em>{id}]\in R^{m</em>d}$,$D$中每一列成为原子。那么，每一个样本都可以表示成“字典”中原子的线性组合：</p>
<p>$$X=DZ$$</p>
<p>其中,$Z=[z_1,z_2,…,z_n]$是系数矩阵，$z_i$是样本$x_i$的“表示”。而字典$D$通常是过完备的，因为经常是选取全部样本作为字典，即$d=n$。因此，上市会有多个解。但是如给系数矩阵加上约束，则会有唯一解。稀疏表示即是要求系数矩阵$Z$是最稀疏的，即</p>
<p>$$\min \Arrowvert Z \Arrowvert_1$$</p>
<p>$$s.t.\quad X=DZ$$</p>
<p>其中，$\Arrowvert \cdot\Arrowvert_1$是求矩阵所有元素的绝对值的和。进一步，这个模型还可以加上噪声，即</p>
<p>$$\min \Arrowvert Z \Arrowvert_1+\lambda\Arrowvert E\Arrowvert_F$$</p>
<p>$$s.t.\quad X=DZ+E$$</p>
<h3 id="低秩表示-Low-rank-Representation"><a href="#低秩表示-Low-rank-Representation" class="headerlink" title="低秩表示(Low-rank Representation)"></a>低秩表示(Low-rank Representation)</h3><p>低秩表示模型和稀疏表示模型几乎一样，区别仅在于对系数矩阵的约束不同，在低秩表示中，它期望系数表示矩阵Z尽可能的低秩，用数学语言描述如下:</p>
<p>$$ \min rank(Z)$$</p>
<p>$$s.t.\quad X=DZ$$</p>
<p>其中,$rank(Z)$表示矩阵$Z$的秩。与$\ell _0$范数一样，秩函数也具有离散组合性质，因此求解上式是一个NP难得。但是如果上式存在一个较低秩的解的话，秩优化问题可以被松弛为核范数最小化问题，即:</p>
<p>$$\min \Arrowvert Z \Arrowvert_*$$</p>
<p>$$s.t.\quad X=DZ$$</p>
<p>其中，$\Arrowvert \cdot \Arrowvert_*$是矩阵的核范数。松弛的原理可以这么理解，一个矩阵的秩等于其非零奇异值的个数。那么矩阵的秩最小化等价于矩阵的奇异值非零个数尽量少，进一步可以松弛为矩阵的所有奇异值的和尽量小。</p>
<p>低秩表示模型是在稀疏表示模型之后提出来的，当然它比稀疏表示模型的性能更好，这是因为低秩表示模型中的核函数自带聚集属性，具体的原因我推荐论文[10]中的讲解（在其第五章中）。</p>
<p>##上述两个模型的求解</p>
<p>求解这两个模型的方法有很多，有兴趣的朋友可以参阅论文[11]。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1]Fischler M., Bolles R. RANSAC random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography. Journal of ACM, 1981, 24(6): 381–395.</p>
<p>[2]Ma Y., Derksen H., Hong W., Wright J. Segmentation of multivariate mixed data via lossy coding and compression. IEEE Trans. Pattern Analysis and Machine Intelligence, 2007, 29(9): 1546–1562.</p>
<p>[3]Vidal R., Ma Y., Sastry S. Generalized principal component analysis (GPCA). IEEE Trans. Pattern Analysis and Machine Intelligence, 2005, 27(12): 1–15.</p>
<p>[4]Lu L., Vidal R. Combined central and subspace clustering on computer vision applications. In: Proc. 23rd Int’l Conf. Machine Learning (ICML), 2006, pp.593–600.</p>
<p>[5] Elhamifar E, Vidal R. Sparse subspace clustering[J]. IEEE Conference on Computer Vision and Pattern Recognition, Cvpr, 2009:2790 - 2797.</p>
<p>[6]G L, Z L, S Y, et al. Robust Recovery of Subspace Structures by LowRank Representation[J]. Pattern Analysis &amp; Machine Intelligence IEEE Transactions on, 2010, 35(1):171 - 184.</p>
<p>[7]X G, K Z, D T, et al. Image SuperResolution With Sparse Neighbor Embedding[J]. IEEE Transactions on Image Processing, 2012, 21(7):3194 - 3205.</p>
<p>[8]Donoho D L． Compressed sensing． IEEE Transactions on Information Theory,2006 52(4)：1289-1306．</p>
<p>[9]Cand6s E．Compressive sampling．Proceedings of Proceedings of Inter-national Congress of Mathematicians，2006．1433-1452．</p>
<p>[10] 卢参义. 基于稀疏表示的人脸分类与聚类[D]. 中国科学技术大学, 2012. DOI:10.7666/d.y2126052.</p>
<p>[11]Lin Z, Chen M, Ma Y. The Augmented Lagrange Multiplier Method for Exact Recovery of Corrupted Low-Rank Matrices[J]. Eprint Arxiv, 2010.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;摘要&lt;/h2&gt;&lt;p&gt;如今处理高维数据的问题往往会有两座“大山”，分别是存储成本高和计算时间过长。显然，这是因为数据的高维数造成的。面对大规模的高维数据的聚类任务，传统的聚类算法有点hold不住了，正因此，子空间分割算法应运而生。&lt;/p&gt;
&lt;p&gt;前面的一篇文章应该是解释清楚了啥是聚类，也安利了一个经典的聚类算法——K均值聚类。本篇开始正式介绍一些子空间聚类算法，以及这些聚类算法的应用实例。&lt;/p&gt;
    
    </summary>
    
    
      <category term="machine learning" scheme="https://xijunlee.github.io/tags/machine-learning/"/>
    
  </entry>
  
</feed>
